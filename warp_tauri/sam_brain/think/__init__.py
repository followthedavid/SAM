"""
think/ - LLM Inference
======================
Local MLX inference, model selection, and Claude escalation.

Usage:
    from sam.think import mlx
    response = mlx.generate("Explain this code")
"""

__version__ = "0.1.0"

__all__ = []
