{"instruction": "Show Package.swift implementation", "response": "```swift\n// swift-tools-version: 5.9\nimport PackageDescription\n\nlet package = Package(\n    name: \"SAMControlCenter\",\n    platforms: [\n        .macOS(.v14)\n    ],\n    products: [\n        .executable(name: \"SAMControlCenter\", targets: [\"SAMControlCenter\"])\n    ],\n    dependencies: [],\n    targets: [\n        .executableTarget(\n            name: \"SAMControlCenter\",\n            dependencies: [],\n            path: \"Sources\"\n        )\n    ]\n)\n\n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:42:11.834844"}
{"instruction": "Show KaraokeSession.swift implementation", "response": "```swift\nimport Foundation\nimport MultipeerConnectivity\n\n/// Shared protocol for iOS <-> tvOS karaoke communication\n/// Uses MultipeerConnectivity for low-latency local network streaming\n\n// MARK: - Message Types\n\nenum KaraokeMessageType: String, Codable {\n    case audioData          // Mic audio samples from iOS\n    case playRequest        // iOS requests song playback\n    case pauseRequest       // iOS requests pause\n    case stopRequest        // iOS requests stop\n    case syncLyrics         // tvOS sends current lyric position\n    case songList           // tvOS sends available songs\n    case nowPlaying         // tvOS sends current song info\n    case micConnected       // iOS mic is connected\n    case micDisconnected    // iOS mic disconnected\n}\n\nstruct KaraokeMessage: Codable {\n    let type: KaraokeMessageType\n    let payload: Data?\n    let timestamp: TimeInterval\n\n    init(type: KaraokeMessageType, payload: Data? = nil) {\n        self.type = type\n        self.payload = payload\n        self.timestamp = Date().timeIntervalSince1970\n    }\n}\n\n// MARK: - Song Metadata\n\nstruct KaraokeSong: Codable, Identifiable, Hashable {\n    let id: String\n    let title: String\n    let artist: String\n    let album: String?\n    let duration: TimeInterval\n    let hasLyrics: Bool\n    let videoPath: String\n\n    var displayName: String {\n        \"\\(artist) - \\(title)\"\n    }\n}\n\n// MARK: - Session Manager\n\nclass KaraokeSessionManager: NSObject, ObservableObject {\n\n    static let serviceType = \"sam-karaoke\"\n\n    let peerID: MCPeerID\n    var session: MCSession!\n\n    @Published var connectedPeers: [MCPeerID] = []\n    @Published var isConnected: Bool = false\n\n    // Callbacks\n    var onMessageReceived: ((KaraokeMessage, MCPeerID) -> Void)?\n    var onAudioReceived: ((Data, MCPeerID) -> Void)?\n\n    init(displayName: String) {\n        self.peerID = MCPeerID(displayName: displayName)\n        super.init()\n\n        self.session = MCSession(\n            peer: peerID,\n            securityIdentity: nil,\n            encryptionPreference: .none  // Low latency for audio\n        )\n        self.session.delegate = self\n    }\n\n    func send(_ message: KaraokeMessage, to peers: [MCPeerID]? = nil) {\n        let targets = peers ?? session.connectedPeers\n        guard !targets.isEmpty else { return }\n\n        do {\n            let data = try JSONEncoder().encode(message)\n            try session.send(data, toPeers: targets, with: .reliable)\n        } catch {\n            print(\"Send error: \\(error)\")\n        }\n    }\n\n    func sendAudio(_ audioData: Data, to peers: [MCPeerID]? = nil) {\n        let targets = peers ?? session.connectedPeers\n        guard !targets.isEmpty else { return }\n\n        // Use unreliable for lower latency audio streaming\n        do {\n            try session.send(audioData, toPeers: targets, with: .unreliable)\n        } catch {\n            // Audio drops are acceptable\n        }\n    }\n\n    func disconnect() {\n        session.disconnect()\n    }\n}\n\n// MARK: - MCSessionDelegate\n\next\n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:42:12.025235"}
{"instruction": "Show KaraokePlayerApp.swift implementation", "response": "```swift\nimport SwiftUI\nimport MultipeerConnectivity\nimport AVKit\n\n@main\nstruct KaraokePlayerApp: App {\n    var body: some Scene {\n        WindowGroup {\n            MainPlayerView()\n        }\n    }\n}\n\n// MARK: - Main Player View\n\nstruct MainPlayerView: View {\n    @StateObject private var viewModel = KaraokePlayerViewModel()\n\n    var body: some View {\n        ZStack {\n            // Background\n            Color.black.ignoresSafeArea()\n\n            if viewModel.isPlaying, let player = viewModel.videoPlayer {\n                // Video Player (karaoke video with lyrics)\n                VideoPlayer(player: player)\n                    .ignoresSafeArea()\n\n                // Mic level overlay\n                VStack {\n                    Spacer()\n                    HStack {\n                        MicIndicatorView(\n                            isConnected: viewModel.micConnected,\n                            level: viewModel.micLevel\n                        )\n                        Spacer()\n                    }\n                    .padding(40)\n                }\n            } else {\n                // Idle/Browse State\n                IdleView(\n                    isConnected: viewModel.isConnected,\n                    connectedDevice: viewModel.connectedDeviceName,\n                    songList: viewModel.songList,\n                    onSelectSong: viewModel.playSong\n                )\n            }\n\n            // Connection waiting overlay\n            if !viewModel.isConnected {\n                WaitingForConnectionView()\n            }\n        }\n        .onAppear {\n            viewModel.startAdvertising()\n        }\n    }\n}\n\n// MARK: - Waiting View\n\nstruct WaitingForConnectionView: View {\n    @State private var rotation: Double = 0\n\n    var body: some View {\n        VStack(spacing: 30) {\n            Image(systemName: \"antenna.radiowaves.left.and.right\")\n                .font(.system(size: 80))\n                .foregroundColor(.blue)\n                .rotationEffect(.degrees(rotation))\n                .animation(\n                    Animation.easeInOut(duration: 2).repeatForever(autoreverses: true),\n                    value: rotation\n                )\n                .onAppear { rotation = 10 }\n\n            Text(\"SAM Karaoke\")\n                .font(.largeTitle)\n                .fontWeight(.bold)\n\n            Text(\"Open the SAM Karaoke app on your iPhone to connect\")\n                .font(.title3)\n                .foregroundColor(.secondary)\n                .multilineTextAlignment(.center)\n        }\n        .padding(60)\n        .background(Color.black.opacity(0.8))\n        .cornerRadius(30)\n    }\n}\n\n// MARK: - Idle View (Song Browser)\n\nstruct IdleView: View {\n    let isConnected: Bool\n    let connectedDevice: String?\n    let songList: [KaraokeSong]\n    let onSelectSong: (KaraokeSong) -> Void\n\n    var body: some View {\n        VStack(spacing: 40) {\n            // Header\n            HStack {\n                VStack(alignment: .leading) {\n                    Text(\"SAM Kar\n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:42:12.027209"}
{"instruction": "Show AudioMixer.swift implementation", "response": "```swift\nimport Foundation\nimport AVFoundation\n\n/// Mixes backing track audio with incoming microphone audio from iOS\nclass AudioMixer: ObservableObject {\n\n    private var audioEngine: AVAudioEngine!\n    private var playerNode: AVAudioPlayerNode!\n    private var micMixerNode: AVAudioMixerNode!\n\n    private var micBuffer: AVAudioPCMBuffer?\n    private let micFormat: AVAudioFormat\n\n    @Published var isPlaying = false\n    @Published var micLevel: Float = 0.0\n    @Published var backingVolume: Float = 1.0\n    @Published var micVolume: Float = 1.0\n\n    // Circular buffer for incoming mic audio\n    private var micAudioQueue = [Data]()\n    private let micQueueLock = NSLock()\n\n    init() {\n        // Mic audio format (16-bit mono from iOS)\n        micFormat = AVAudioFormat(\n            commonFormat: .pcmFormatFloat32,\n            sampleRate: KaraokeAudioFormat.sampleRate,\n            channels: 1,\n            interleaved: false\n        )!\n\n        setupAudioEngine()\n    }\n\n    private func setupAudioEngine() {\n        audioEngine = AVAudioEngine()\n        playerNode = AVAudioPlayerNode()\n        micMixerNode = AVAudioMixerNode()\n\n        audioEngine.attach(playerNode)\n        audioEngine.attach(micMixerNode)\n\n        let mainMixer = audioEngine.mainMixerNode\n        let outputFormat = mainMixer.outputFormat(forBus: 0)\n\n        // Connect: playerNode -> mainMixer (backing track)\n        audioEngine.connect(playerNode, to: mainMixer, format: outputFormat)\n\n        // Connect: micMixerNode -> mainMixer (mic audio)\n        audioEngine.connect(micMixerNode, to: mainMixer, format: micFormat)\n\n        // Start mic audio injection timer\n        startMicInjection()\n    }\n\n    func start() {\n        do {\n            try audioEngine.start()\n            print(\"Audio engine started\")\n        } catch {\n            print(\"Failed to start audio engine: \\(error)\")\n        }\n    }\n\n    func stop() {\n        playerNode.stop()\n        audioEngine.stop()\n        isPlaying = false\n    }\n\n    // MARK: - Backing Track Playback\n\n    func playBackingTrack(url: URL) {\n        do {\n            let audioFile = try AVAudioFile(forReading: url)\n\n            playerNode.scheduleFile(audioFile, at: nil) { [weak self] in\n                DispatchQueue.main.async {\n                    self?.isPlaying = false\n                }\n            }\n\n            if !audioEngine.isRunning {\n                try audioEngine.start()\n            }\n\n            playerNode.play()\n            isPlaying = true\n            print(\"Playing backing track: \\(url.lastPathComponent)\")\n\n        } catch {\n            print(\"Failed to play backing track: \\(error)\")\n        }\n    }\n\n    func pause() {\n        playerNode.pause()\n        isPlaying = false\n    }\n\n    func resume() {\n        playerNode.play()\n        isPlaying = true\n    }\n\n    // MARK: - Microphone Audio Injection\n\n    func receiveMicAudio(_ data: Data) {\n        micQueueLock.lock()\n        micAudioQueue.append(data)\n        // Keep queue bounded (max ~500ms of audi\n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:42:12.030002"}
{"instruction": "Show MicrophoneManager.swift implementation", "response": "```swift\nimport Foundation\nimport AVFoundation\n\n/// Captures microphone audio and streams to tvOS\nclass MicrophoneManager: NSObject, ObservableObject {\n\n    private var audioEngine: AVAudioEngine?\n    private var inputNode: AVAudioInputNode?\n\n    @Published var isCapturing = false\n    @Published var micLevel: Float = 0.0\n    @Published var permissionGranted = false\n\n    var onAudioCaptured: ((Data) -> Void)?\n\n    override init() {\n        super.init()\n        checkPermission()\n    }\n\n    func checkPermission() {\n        switch AVAudioSession.sharedInstance().recordPermission {\n        case .granted:\n            permissionGranted = true\n        case .denied:\n            permissionGranted = false\n        case .undetermined:\n            AVAudioSession.sharedInstance().requestRecordPermission { [weak self] granted in\n                DispatchQueue.main.async {\n                    self?.permissionGranted = granted\n                }\n            }\n        @unknown default:\n            break\n        }\n    }\n\n    func startCapturing() {\n        guard permissionGranted else {\n            print(\"Microphone permission not granted\")\n            return\n        }\n\n        do {\n            let session = AVAudioSession.sharedInstance()\n            try session.setCategory(.playAndRecord, mode: .voiceChat, options: [.defaultToSpeaker, .allowBluetooth])\n            try session.setActive(true)\n\n            audioEngine = AVAudioEngine()\n            inputNode = audioEngine?.inputNode\n\n            guard let inputNode = inputNode else { return }\n\n            let recordingFormat = inputNode.outputFormat(forBus: 0)\n\n            // Install tap on input node\n            inputNode.installTap(onBus: 0, bufferSize: UInt32(KaraokeAudioFormat.bufferSize), format: recordingFormat) { [weak self] buffer, time in\n                self?.processAudioBuffer(buffer)\n            }\n\n            try audioEngine?.start()\n            isCapturing = true\n            print(\"Microphone capture started\")\n\n        } catch {\n            print(\"Failed to start audio capture: \\(error)\")\n        }\n    }\n\n    func stopCapturing() {\n        inputNode?.removeTap(onBus: 0)\n        audioEngine?.stop()\n        audioEngine = nil\n        inputNode = nil\n        isCapturing = false\n        print(\"Microphone capture stopped\")\n    }\n\n    private func processAudioBuffer(_ buffer: AVAudioPCMBuffer) {\n        guard let channelData = buffer.floatChannelData else { return }\n\n        let frames = buffer.frameLength\n        let channels = buffer.format.channelCount\n\n        // Calculate mic level for UI\n        var sum: Float = 0\n        for frame in 0..<Int(frames) {\n            let sample = channelData[0][frame]\n            sum += sample * sample\n        }\n        let rms = sqrt(sum / Float(frames))\n        DispatchQueue.main.async {\n            self.micLevel = min(1.0, rms * 5)  // Scale for visibility\n        }\n\n        // Convert to 16-bit PCM data for transmission\n        let data = convertToData(buffer)\n        onAudioCaptu\n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:42:12.030892"}
{"instruction": "Show KaraokeMicApp.swift implementation", "response": "```swift\nimport SwiftUI\nimport MultipeerConnectivity\n\n@main\nstruct KaraokeMicApp: App {\n    var body: some Scene {\n        WindowGroup {\n            ContentView()\n        }\n    }\n}\n\n// MARK: - Main Content View\n\nstruct ContentView: View {\n    @StateObject private var viewModel = KaraokeMicViewModel()\n\n    var body: some View {\n        NavigationView {\n            VStack(spacing: 30) {\n\n                // Connection Status\n                ConnectionStatusView(isConnected: viewModel.isConnected, peerName: viewModel.connectedTVName)\n\n                Spacer()\n\n                // Microphone Control\n                MicrophoneView(\n                    isCapturing: viewModel.isCapturing,\n                    micLevel: viewModel.micLevel,\n                    onToggle: viewModel.toggleMicrophone\n                )\n\n                Spacer()\n\n                // Now Playing (if connected)\n                if viewModel.isConnected {\n                    NowPlayingView(song: viewModel.currentSong)\n                }\n\n                // Song List\n                if viewModel.isConnected && !viewModel.songList.isEmpty {\n                    SongListView(songs: viewModel.songList, onSelect: viewModel.requestSong)\n                }\n\n                Spacer()\n            }\n            .padding()\n            .navigationTitle(\"SAM Karaoke\")\n            .toolbar {\n                ToolbarItem(placement: .navigationBarTrailing) {\n                    Button(action: viewModel.startBrowsing) {\n                        Image(systemName: \"antenna.radiowaves.left.and.right\")\n                    }\n                }\n            }\n            .onAppear {\n                viewModel.startBrowsing()\n            }\n        }\n    }\n}\n\n// MARK: - Connection Status\n\nstruct ConnectionStatusView: View {\n    let isConnected: Bool\n    let peerName: String?\n\n    var body: some View {\n        HStack {\n            Circle()\n                .fill(isConnected ? Color.green : Color.red)\n                .frame(width: 12, height: 12)\n\n            if isConnected, let name = peerName {\n                Text(\"Connected to \\(name)\")\n                    .font(.subheadline)\n            } else {\n                Text(\"Searching for Apple TV...\")\n                    .font(.subheadline)\n                    .foregroundColor(.secondary)\n            }\n        }\n        .padding(.horizontal, 16)\n        .padding(.vertical, 8)\n        .background(Color(.systemGray6))\n        .cornerRadius(20)\n    }\n}\n\n// MARK: - Microphone View\n\nstruct MicrophoneView: View {\n    let isCapturing: Bool\n    let micLevel: Float\n    let onToggle: () -> Void\n\n    var body: some View {\n        VStack(spacing: 20) {\n            // Mic button with level indicator\n            ZStack {\n                // Level ring\n                Circle()\n                    .stroke(Color.blue.opacity(0.3), lineWidth: 8)\n                    .frame(width: 150, height: 150)\n\n                Circle()\n                    .trim(from: 0, to: CGFloat(micLevel))\n                    .s\n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:42:12.031999"}
{"instruction": "Show SAMUITests.swift implementation", "response": "```swift\nimport XCTest\n\n/**\n SAM UI Tests\n\n These tests use XCTest's UI testing framework to verify the SAM app's behavior.\n\n Prerequisites:\n 1. SAM app must be built and available at the expected path\n 2. SAM must grant accessibility permissions to the test runner\n\n Running tests:\n - Open SAMUITests.xcodeproj in Xcode\n - Select the SAMUITests scheme\n - Press Cmd+U to run tests\n - Or use: xcodebuild test -project SAMUITests.xcodeproj -scheme SAMUITests\n\n Note: For WebView content, you may need to add accessibility labels\n to Vue components for XCTest to find them.\n*/\n\nclass SAMUITests: XCTestCase {\n\n    // The SAM app bundle identifier\n    let samBundleId = \"com.sam.terminal\"\n\n    // Debug server URL\n    let debugURL = \"http://localhost:9998\"\n\n    var app: XCUIApplication!\n\n    override func setUpWithError() throws {\n        continueAfterFailure = false\n\n        // Initialize app with bundle ID\n        app = XCUIApplication(bundleIdentifier: samBundleId)\n\n        // Alternatively, launch by path if bundle ID doesn't work\n        // app = XCUIApplication()\n        // app.launchEnvironment[\"SAM_TEST_MODE\"] = \"1\"\n    }\n\n    override func tearDownWithError() throws {\n        // Take screenshot on failure\n        if testRun?.failureCount ?? 0 > 0 {\n            let screenshot = XCUIScreen.main.screenshot()\n            let attachment = XCTAttachment(screenshot: screenshot)\n            attachment.name = \"Failure Screenshot\"\n            attachment.lifetime = .keepAlways\n            add(attachment)\n        }\n    }\n\n    // MARK: - Startup Tests\n\n    func testAppLaunches() throws {\n        // Launch the app\n        app.launch()\n\n        // Wait for window to appear\n        let window = app.windows.firstMatch\n        XCTAssertTrue(window.waitForExistence(timeout: 30), \"SAM window should appear within 30 seconds\")\n\n        // Verify window is visible\n        XCTAssertTrue(window.isHittable, \"SAM window should be hittable\")\n    }\n\n    func testWindowExists() throws {\n        app.activate()\n\n        let window = app.windows[\"SAM\"]\n        let exists = window.waitForExistence(timeout: 10)\n\n        XCTAssertTrue(exists, \"SAM window should exist\")\n    }\n\n    func testDebugServerResponds() throws {\n        // Query the debug server\n        let expectation = XCTestExpectation(description: \"Debug server responds\")\n\n        guard let url = URL(string: \"\\(debugURL)/debug/ping\") else {\n            XCTFail(\"Invalid debug URL\")\n            return\n        }\n\n        let task = URLSession.shared.dataTask(with: url) { data, response, error in\n            XCTAssertNil(error, \"Debug server should not return error\")\n            XCTAssertNotNil(data, \"Debug server should return data\")\n\n            if let httpResponse = response as? HTTPURLResponse {\n                XCTAssertEqual(httpResponse.statusCode, 200, \"Debug server should return 200\")\n            }\n\n            expectation.fulfill()\n        }\n        task.resume()\n\n        wait(for: [expectation], timeout: 5.0)\n    }\n\n    // MARK:\n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:42:13.653702"}
{"instruction": "Show AtlasShortcuts.swift implementation", "response": "```swift\nimport AppIntents\nimport Foundation\n\n/// Siri Shortcuts for SAM\n/// \"Hey Siri, ask SAM...\"\n/// \"Hey Siri, tell SAM to flirt\"\n/// \"Hey Siri, what's SAM's mood?\"\n\n// MARK: - Chat with SAM\n\nstruct AskSAMIntent: AppIntent {\n    static var title: LocalizedStringResource = \"Ask SAM\"\n    static var description = IntentDescription(\"Send a message to SAM and get a response\")\n    static var openAppWhenRun: Bool = false\n\n    @Parameter(title: \"Message\")\n    var message: String\n\n    func perform() async throws -> some IntentResult & ReturnsValue<String> & ProvidesDialog {\n        // Connect to SAM service\n        let response = await SAMShortcutService.shared.sendMessage(message)\n        return .result(value: response, dialog: IntentDialog(response))\n    }\n}\n\n// MARK: - Set Mood\n\nstruct SetSAMMoodIntent: AppIntent {\n    static var title: LocalizedStringResource = \"Set SAM Mood\"\n    static var description = IntentDescription(\"Change SAM's current mood\")\n\n    @Parameter(title: \"Mood\")\n    var mood: SAMMoodEntity\n\n    func perform() async throws -> some IntentResult & ProvidesDialog {\n        await SAMShortcutService.shared.setMood(mood.id)\n        return .result(dialog: \"SAM is now feeling \\(mood.name)\")\n    }\n}\n\nstruct SAMMoodEntity: AppEntity {\n    var id: String\n    var name: String\n\n    static var typeDisplayRepresentation: TypeDisplayRepresentation = \"Mood\"\n    static var defaultQuery = SAMMoodQuery()\n\n    var displayRepresentation: DisplayRepresentation {\n        DisplayRepresentation(title: LocalizedStringResource(stringLiteral: name))\n    }\n\n    static let moods: [SAMMoodEntity] = [\n        SAMMoodEntity(id: \"neutral\", name: \"Neutral\"),\n        SAMMoodEntity(id: \"happy\", name: \"Happy\"),\n        SAMMoodEntity(id: \"playful\", name: \"Playful\"),\n        SAMMoodEntity(id: \"flirty\", name: \"Flirty\"),\n        SAMMoodEntity(id: \"focused\", name: \"Focused\"),\n        SAMMoodEntity(id: \"aroused\", name: \"Aroused\")\n    ]\n}\n\nstruct SAMMoodQuery: EntityQuery {\n    func entities(for identifiers: [String]) async throws -> [SAMMoodEntity] {\n        SAMMoodEntity.moods.filter { identifiers.contains($0.id) }\n    }\n\n    func suggestedEntities() async throws -> [SAMMoodEntity] {\n        SAMMoodEntity.moods\n    }\n}\n\n// MARK: - Trigger Animation\n\nstruct SAMAnimationIntent: AppIntent {\n    static var title: LocalizedStringResource = \"SAM Animation\"\n    static var description = IntentDescription(\"Make SAM perform an animation\")\n\n    @Parameter(title: \"Animation\")\n    var animation: SAMAnimationEntity\n\n    func perform() async throws -> some IntentResult & ProvidesDialog {\n        await SAMShortcutService.shared.triggerAnimation(animation.id)\n        return .result(dialog: \"SAM is now doing: \\(animation.name)\")\n    }\n}\n\nstruct SAMAnimationEntity: AppEntity {\n    var id: String\n    var name: String\n\n    static var typeDisplayRepresentation: TypeDisplayRepresentation = \"Animation\"\n    static var defaultQuery = SAMAnimationQuery()\n\n    var displayRepresentation: DisplayRepresentation \n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:42:13.656112"}
{"instruction": "Show AtlasWidget.swift implementation", "response": "```swift\nimport WidgetKit\nimport SwiftUI\n\n/// SAM Home Screen Widget\n/// Quick access to your AI companion from the home screen\n\nstruct SAMWidgetEntry: TimelineEntry {\n    let date: Date\n    let mood: String\n    let moodEmoji: String\n    let lastMessage: String\n    let isConnected: Bool\n}\n\nstruct SAMWidgetProvider: TimelineProvider {\n    func placeholder(in context: Context) -> SAMWidgetEntry {\n        SAMWidgetEntry(\n            date: Date(),\n            mood: \"neutral\",\n            moodEmoji: \"\ud83d\ude0a\",\n            lastMessage: \"Hey, what's up?\",\n            isConnected: true\n        )\n    }\n\n    func getSnapshot(in context: Context, completion: @escaping (SAMWidgetEntry) -> Void) {\n        let entry = SAMWidgetEntry(\n            date: Date(),\n            mood: UserDefaults(suiteName: \"group.warpopen.atlas\")?.string(forKey: \"currentMood\") ?? \"neutral\",\n            moodEmoji: getMoodEmoji(UserDefaults(suiteName: \"group.warpopen.atlas\")?.string(forKey: \"currentMood\") ?? \"neutral\"),\n            lastMessage: UserDefaults(suiteName: \"group.warpopen.atlas\")?.string(forKey: \"lastMessage\") ?? \"Tap to chat...\",\n            isConnected: UserDefaults(suiteName: \"group.warpopen.atlas\")?.bool(forKey: \"isConnected\") ?? false\n        )\n        completion(entry)\n    }\n\n    func getTimeline(in context: Context, completion: @escaping (Timeline<SAMWidgetEntry>) -> Void) {\n        let defaults = UserDefaults(suiteName: \"group.warpopen.atlas\")\n\n        let entry = SAMWidgetEntry(\n            date: Date(),\n            mood: defaults?.string(forKey: \"currentMood\") ?? \"neutral\",\n            moodEmoji: getMoodEmoji(defaults?.string(forKey: \"currentMood\") ?? \"neutral\"),\n            lastMessage: defaults?.string(forKey: \"lastMessage\") ?? \"Tap to chat...\",\n            isConnected: defaults?.bool(forKey: \"isConnected\") ?? false\n        )\n\n        // Update every 15 minutes\n        let nextUpdate = Calendar.current.date(byAdding: .minute, value: 15, to: Date())!\n        let timeline = Timeline(entries: [entry], policy: .after(nextUpdate))\n        completion(timeline)\n    }\n\n    private func getMoodEmoji(_ mood: String) -> String {\n        switch mood {\n        case \"happy\": return \"\ud83d\ude0a\"\n        case \"playful\": return \"\ud83d\ude0f\"\n        case \"flirty\": return \"\ud83d\ude08\"\n        case \"focused\": return \"\ud83d\udcbb\"\n        case \"aroused\": return \"\ud83d\udd25\"\n        default: return \"\ud83d\ude10\"\n        }\n    }\n}\n\n// MARK: - Small Widget\n\nstruct SAMWidgetSmall: View {\n    let entry: SAMWidgetEntry\n\n    var body: some View {\n        ZStack {\n            // Background gradient\n            LinearGradient(\n                colors: [.purple.opacity(0.6), .blue.opacity(0.4)],\n                startPoint: .topLeading,\n                endPoint: .bottomTrailing\n            )\n\n            VStack(alignment: .leading, spacing: 8) {\n                HStack {\n                    Text(entry.moodEmoji)\n                        .font(.title)\n                    Spacer()\n                    Circle()\n                        .fill(entry.isConnected ? Color.gr\n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:42:13.656776"}
{"instruction": "Show AtlasApp.swift implementation", "response": "```swift\nimport SwiftUI\nimport WidgetKit\n\n/// SAM iOS Companion App\n/// Your AI companion on your wrist and in your pocket\n@main\nstruct SAMApp: App {\n    @StateObject private var atlasService = SAMService.shared\n    @Environment(\\.scenePhase) private var scenePhase\n\n    var body: some Scene {\n        WindowGroup {\n            ContentView()\n                .environmentObject(atlasService)\n                .onAppear {\n                    atlasService.connect()\n                }\n                .onChange(of: scenePhase) { phase in\n                    switch phase {\n                    case .active:\n                        atlasService.connect()\n                    case .background:\n                        atlasService.enterBackground()\n                    case .inactive:\n                        break\n                    @unknown default:\n                        break\n                    }\n                }\n        }\n    }\n}\n\n// MARK: - SAM Service\n\nclass SAMService: ObservableObject {\n    static let shared = SAMService()\n\n    @Published var isConnected = false\n    @Published var currentMood: Mood = .neutral\n    @Published var lastMessage: String = \"\"\n    @Published var isThinking = false\n    @Published var arousalLevel: Float = 0\n\n    private var webSocket: URLSessionWebSocketTask?\n    private let session = URLSession(configuration: .default)\n    private let serverURL = \"ws://localhost:8765\" // Will be configurable\n\n    enum Mood: String, CaseIterable {\n        case neutral, happy, playful, flirty, focused, aroused\n\n        var emoji: String {\n            switch self {\n            case .neutral: return \"\ud83d\ude10\"\n            case .happy: return \"\ud83d\ude0a\"\n            case .playful: return \"\ud83d\ude0f\"\n            case .flirty: return \"\ud83d\ude08\"\n            case .focused: return \"\ud83d\udcbb\"\n            case .aroused: return \"\ud83d\udd25\"\n            }\n        }\n\n        var color: Color {\n            switch self {\n            case .neutral: return .gray\n            case .happy: return .yellow\n            case .playful: return .pink\n            case .flirty: return .purple\n            case .focused: return .blue\n            case .aroused: return .red\n            }\n        }\n    }\n\n    // MARK: - Connection\n\n    func connect() {\n        guard let url = URL(string: serverURL) else { return }\n\n        webSocket = session.webSocketTask(with: url)\n        webSocket?.resume()\n\n        isConnected = true\n        listenForMessages()\n\n        // Register as iOS client\n        send([\n            \"type\": \"register\",\n            \"client_type\": \"ios_companion\",\n            \"capabilities\": [\"notifications\", \"siri\", \"widget\", \"watch\"]\n        ])\n    }\n\n    func disconnect() {\n        webSocket?.cancel(with: .goingAway, reason: nil)\n        webSocket = nil\n        isConnected = false\n    }\n\n    func enterBackground() {\n        // Keep connection alive for notifications\n        // iOS will manage the socket lifecycle\n    }\n\n    // MARK: - Messaging\n\n    func send(_ message: [String: Any]) {\n        guard let data = try? JSON\n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:42:13.657882"}
{"instruction": "Show Package.swift implementation", "response": "```swift\n// swift-tools-version: 5.9\nimport PackageDescription\n\nlet package = Package(\n    name: \"FashionArchive\",\n    platforms: [\n        .macOS(.v14),\n        .iOS(.v17),\n        .tvOS(.v17)\n    ],\n    products: [\n        .library(\n            name: \"FashionArchive\",\n            targets: [\"FashionArchive\"]\n        )\n    ],\n    targets: [\n        .target(\n            name: \"FashionArchive\",\n            path: \"Sources\"\n        )\n    ]\n)\n\n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:42:17.321708"}
{"instruction": "Show Models.swift implementation", "response": "```swift\nimport Foundation\n\n// MARK: - Article Model\n\nstruct Article: Identifiable, Codable, Hashable {\n    let id: String\n    let source: String\n    let sourceName: String?\n    let url: String?\n    let title: String\n    let author: String?\n    let category: String?\n    let subcategory: String?\n    let publishDate: String?\n    let content: String?\n    let wordCount: Int?\n    let imageCount: Int?\n    let tags: String?\n\n    enum CodingKeys: String, CodingKey {\n        case id, source, url, title, author, category, subcategory, content, tags\n        case sourceName = \"source_name\"\n        case publishDate = \"publish_date\"\n        case wordCount = \"word_count\"\n        case imageCount = \"image_count\"\n    }\n\n    var formattedDate: String {\n        guard let date = publishDate else { return \"Unknown date\" }\n        return String(date.prefix(10))\n    }\n\n    var excerpt: String {\n        guard let content = content else { return \"\" }\n        return String(content.prefix(200)) + (content.count > 200 ? \"...\" : \"\")\n    }\n}\n\n// MARK: - Stats Model\n\nstruct ArchiveStats: Codable {\n    let totalArticles: Int\n    let totalWords: Int\n    let totalImages: Int\n    let bySource: [SourceStats]\n    let byYear: [String: Int]\n    let topCategories: [String: Int]\n\n    enum CodingKeys: String, CodingKey {\n        case totalArticles = \"total_articles\"\n        case totalWords = \"total_words\"\n        case totalImages = \"total_images\"\n        case bySource = \"by_source\"\n        case byYear = \"by_year\"\n        case topCategories = \"top_categories\"\n    }\n}\n\nstruct SourceStats: Codable, Identifiable {\n    let source: String\n    let name: String\n    let count: Int\n    let words: Int\n\n    var id: String { source }\n}\n\n// MARK: - Trend Model\n\nstruct TrendData: Codable {\n    let term: String\n    let by: String\n    let data: [TrendPoint]\n}\n\nstruct TrendPoint: Codable, Identifiable {\n    let period: String\n    let mentions: Int\n\n    var id: String { period }\n\n    var year: Int? {\n        Int(period)\n    }\n}\n\n// MARK: - Search Response\n\nstruct SearchResponse: Codable {\n    let query: String?\n    let count: Int\n    let articles: [Article]\n}\n\n// MARK: - SAM Context\n\nstruct SAMContext: Codable {\n    let topic: String\n    let articles: [SAMArticleContext]\n}\n\nstruct SAMArticleContext: Codable, Identifiable {\n    let title: String\n    let source: String\n    let date: String?\n    let excerpt: String\n\n    var id: String { title }\n}\n\n// MARK: - Chat Message\n\nstruct ChatMessage: Identifiable {\n    let id = UUID()\n    let role: Role\n    let content: String\n    let timestamp: Date\n\n    enum Role {\n        case user, assistant, system\n    }\n}\n\n// MARK: - API Response Wrapper\n\nstruct APIResponse<T: Codable>: Codable {\n    let data: T?\n    let error: String?\n}\n\n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:42:17.322848"}
{"instruction": "Show Views.swift implementation", "response": "```swift\nimport SwiftUI\nimport Charts\n\n// MARK: - Browse View\n\nstruct BrowseView: View {\n    @EnvironmentObject var archiveService: ArchiveService\n    @State private var selectedSource: String?\n    @State private var selectedCategory: String?\n    @State private var selectedArticle: Article?\n\n    var body: some View {\n        VStack {\n            // Filters\n            HStack {\n                Picker(\"Source\", selection: $selectedSource) {\n                    Text(\"All Sources\").tag(nil as String?)\n                    ForEach(archiveService.sources) { source in\n                        Text(source.name).tag(source.source as String?)\n                    }\n                }\n                .pickerStyle(.menu)\n\n                Picker(\"Category\", selection: $selectedCategory) {\n                    Text(\"All Categories\").tag(nil as String?)\n                    ForEach(Array(archiveService.categories.keys.sorted().prefix(20)), id: \\.self) { cat in\n                        Text(cat.capitalized).tag(cat as String?)\n                    }\n                }\n                .pickerStyle(.menu)\n\n                Spacer()\n\n                if let stats = archiveService.stats {\n                    Text(\"\\(stats.totalArticles.formatted()) articles\")\n                        .foregroundColor(.secondary)\n                }\n            }\n            .padding(.horizontal)\n\n            // Article List\n            List(archiveService.articles.isEmpty ? archiveService.searchResults : archiveService.articles, selection: $selectedArticle) { article in\n                ArticleRow(article: article)\n                    .tag(article)\n            }\n            .listStyle(.inset)\n        }\n        .navigationTitle(\"Browse\")\n        .sheet(item: $selectedArticle) { article in\n            ArticleDetailView(article: article)\n        }\n        .onChange(of: selectedSource) { _, _ in\n            Task {\n                await archiveService.loadArticles(source: selectedSource, category: selectedCategory)\n            }\n        }\n        .onChange(of: selectedCategory) { _, _ in\n            Task {\n                await archiveService.loadArticles(source: selectedSource, category: selectedCategory)\n            }\n        }\n        .task {\n            await archiveService.loadArticles()\n        }\n    }\n}\n\n// MARK: - Article Row\n\nstruct ArticleRow: View {\n    let article: Article\n\n    var body: some View {\n        VStack(alignment: .leading, spacing: 4) {\n            Text(article.title)\n                .font(.headline)\n                .lineLimit(2)\n\n            HStack {\n                Text(article.sourceName ?? article.source)\n                    .font(.caption)\n                    .foregroundColor(.blue)\n\n                Text(\"\u2022\")\n                    .foregroundColor(.secondary)\n\n                Text(article.formattedDate)\n                    .font(.caption)\n                    .foregroundColor(.secondary)\n\n                if let wordCount = article.wordCount {\n                    Text(\"\u2022\")\n             \n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:42:17.323946"}
{"instruction": "Show FashionArchiveApp.swift implementation", "response": "```swift\nimport SwiftUI\n\n@main\nstruct FashionArchiveApp: App {\n    @StateObject private var archiveService = ArchiveService()\n\n    var body: some Scene {\n        WindowGroup {\n            ContentView()\n                .environmentObject(archiveService)\n        }\n        #if os(macOS)\n        .commands {\n            CommandGroup(replacing: .newItem) {\n                Button(\"Search Articles\") {\n                    NSApp.sendAction(#selector(NSResponder.becomeFirstResponder), to: nil, from: nil)\n                }\n                .keyboardShortcut(\"f\", modifiers: [.command])\n            }\n        }\n\n        Settings {\n            SettingsView()\n                .environmentObject(archiveService)\n        }\n        #endif\n    }\n}\n\n// MARK: - Content View (Platform Adaptive)\n\nstruct ContentView: View {\n    @EnvironmentObject var archiveService: ArchiveService\n\n    var body: some View {\n        #if os(tvOS)\n        TVContentView()\n        #elseif os(macOS)\n        MacContentView()\n        #else\n        MobileContentView()\n        #endif\n    }\n}\n\n// MARK: - macOS Layout\n\n#if os(macOS)\nstruct MacContentView: View {\n    @EnvironmentObject var archiveService: ArchiveService\n    @State private var selectedTab: Tab = .browse\n    @State private var searchText = \"\"\n\n    enum Tab: Hashable {\n        case browse, analytics, sam, settings\n    }\n\n    var body: some View {\n        NavigationSplitView {\n            List(selection: $selectedTab) {\n                Section(\"Library\") {\n                    Label(\"Browse\", systemImage: \"books.vertical\")\n                        .tag(Tab.browse)\n                    Label(\"Analytics\", systemImage: \"chart.bar.xaxis\")\n                        .tag(Tab.analytics)\n                    Label(\"SAM\", systemImage: \"brain\")\n                        .tag(Tab.sam)\n                }\n\n                Section(\"Sources\") {\n                    ForEach(archiveService.sources, id: \\.source) { source in\n                        HStack {\n                            Text(source.name)\n                            Spacer()\n                            Text(\"\\(source.count)\")\n                                .foregroundColor(.secondary)\n                        }\n                    }\n                }\n            }\n            .listStyle(.sidebar)\n            .frame(minWidth: 200)\n        } detail: {\n            switch selectedTab {\n            case .browse:\n                BrowseView()\n            case .analytics:\n                AnalyticsView()\n            case .sam:\n                SAMChatView()\n            case .settings:\n                SettingsView()\n            }\n        }\n        .searchable(text: $searchText, prompt: \"Search articles...\")\n        .onSubmit(of: .search) {\n            archiveService.search(query: searchText)\n        }\n        .task {\n            await archiveService.loadStats()\n        }\n    }\n}\n#endif\n\n// MARK: - iOS/iPadOS Layout\n\n#if os(iOS)\nstruct MobileContentView: View {\n    @EnvironmentObject var archiveService: ArchiveService\n    @St\n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:42:17.324776"}
{"instruction": "Show ArchiveService.swift implementation", "response": "```swift\nimport Foundation\nimport SwiftUI\n#if canImport(AVFoundation)\nimport AVFoundation\n#endif\n\n// MARK: - Archive Service\n\n@MainActor\nclass ArchiveService: ObservableObject {\n    // MARK: - Published Properties\n\n    @Published var stats: ArchiveStats?\n    @Published var articles: [Article] = []\n    @Published var searchResults: [Article] = []\n    @Published var sources: [SourceStats] = []\n    @Published var categories: [String: Int] = [:]\n    @Published var currentTrend: TrendData?\n    @Published var isLoading = false\n    @Published var errorMessage: String?\n    @Published var chatMessages: [ChatMessage] = []\n\n    // MARK: - Configuration\n\n    @AppStorage(\"apiBaseURL\") var apiBaseURL = \"http://localhost:8420\"\n\n    // MARK: - Speech\n\n    #if os(macOS)\n    private let speechSynthesizer = NSSpeechSynthesizer()\n    #elseif os(iOS) || os(tvOS)\n    private let speechSynthesizer = AVSpeechSynthesizer()\n    #endif\n\n    // MARK: - API Methods\n\n    private func apiURL(_ path: String) -> URL? {\n        URL(string: \"\\(apiBaseURL)\\(path)\")\n    }\n\n    private func fetch<T: Codable>(_ path: String) async throws -> T {\n        guard let url = apiURL(path) else {\n            throw URLError(.badURL)\n        }\n\n        let (data, _) = try await URLSession.shared.data(from: url)\n        return try JSONDecoder().decode(T.self, from: data)\n    }\n\n    private func post<T: Codable, R: Codable>(_ path: String, body: T) async throws -> R {\n        guard let url = apiURL(path) else {\n            throw URLError(.badURL)\n        }\n\n        var request = URLRequest(url: url)\n        request.httpMethod = \"POST\"\n        request.setValue(\"application/json\", forHTTPHeaderField: \"Content-Type\")\n        request.httpBody = try JSONEncoder().encode(body)\n\n        let (data, _) = try await URLSession.shared.data(for: request)\n        return try JSONDecoder().decode(R.self, from: data)\n    }\n\n    // MARK: - Load Data\n\n    func loadStats() async {\n        isLoading = true\n        defer { isLoading = false }\n\n        do {\n            stats = try await fetch(\"/stats\")\n            sources = stats?.bySource ?? []\n            categories = stats?.topCategories ?? [:]\n        } catch {\n            errorMessage = \"Failed to load stats: \\(error.localizedDescription)\"\n        }\n    }\n\n    func loadArticles(source: String? = nil, category: String? = nil, limit: Int = 50) async {\n        isLoading = true\n        defer { isLoading = false }\n\n        var path = \"/articles?limit=\\(limit)\"\n        if let source = source {\n            path += \"&source=\\(source)\"\n        }\n        if let category = category {\n            path += \"&category=\\(category.addingPercentEncoding(withAllowedCharacters: .urlQueryAllowed) ?? category)\"\n        }\n\n        do {\n            let response: SearchResponse = try await fetch(path)\n            articles = response.articles\n        } catch {\n            errorMessage = \"Failed to load articles: \\(error.localizedDescription)\"\n        }\n    }\n\n    func search(query: String, source: S\n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:42:17.325561"}
{"instruction": "Show SAMControlCenterApp.swift implementation", "response": "```swift\nimport SwiftUI\nimport AppKit\n\n@main\nstruct SAMControlCenterApp: App {\n    @NSApplicationDelegateAdaptor(AppDelegate.self) var appDelegate\n    @StateObject private var samState = SAMState()\n\n    init() {\n        // Share state\n        AppDelegate.samState = samState\n    }\n\n    var body: some Scene {\n        // Menu Bar Icon (brain in top bar)\n        MenuBarExtra {\n            VStack(alignment: .leading, spacing: 8) {\n                HStack {\n                    Image(systemName: \"brain.fill\")\n                        .foregroundStyle(.cyan)\n                    Text(\"SAM Control Center\")\n                        .fontWeight(.medium)\n                }\n                .padding(.bottom, 4)\n\n                Divider()\n\n                Button(\"Open Window\") {\n                    AppDelegate.shared?.openMainWindow()\n                }\n\n                Button(\"Quit\") {\n                    NSApp.terminate(nil)\n                }\n            }\n            .padding(8)\n        } label: {\n            Image(systemName: \"brain.fill\")\n        }\n    }\n}\n\n@MainActor\nclass AppDelegate: NSObject, NSApplicationDelegate {\n    static var shared: AppDelegate?\n    static var samState: SAMState?\n    var mainWindow: NSWindow?\n\n    func applicationDidFinishLaunching(_ notification: Notification) {\n        AppDelegate.shared = self\n        // Make this a regular app (not accessory/background) so windows show\n        NSApp.setActivationPolicy(.regular)\n        // Create and show window immediately\n        DispatchQueue.main.async {\n            self.openMainWindow()\n        }\n    }\n\n    func openMainWindow() {\n        if mainWindow == nil {\n            let contentView = ContentView()\n                .environmentObject(AppDelegate.samState ?? SAMState())\n                .frame(minWidth: 700, minHeight: 550)\n\n            mainWindow = NSWindow(\n                contentRect: NSRect(x: 0, y: 0, width: 750, height: 600),\n                styleMask: [.titled, .closable, .miniaturizable, .resizable],\n                backing: .buffered,\n                defer: false\n            )\n            mainWindow?.title = \"SAM Control Center\"\n            mainWindow?.contentView = NSHostingView(rootView: contentView)\n            mainWindow?.center()\n        }\n        mainWindow?.makeKeyAndOrderFront(nil)\n        NSApp.activate(ignoringOtherApps: true)\n    }\n\n    func applicationShouldHandleReopen(_ sender: NSApplication, hasVisibleWindows flag: Bool) -> Bool {\n        openMainWindow()\n        return true\n    }\n}\n\n// MARK: - Voice Models\n\nstruct VoiceInfo: Identifiable, Codable, Equatable {\n    let id: String\n    let name: String\n    let language: String?\n    let isCustom: Bool\n\n    enum CodingKeys: String, CodingKey {\n        case id, name, language\n        case isCustom = \"is_custom\"\n    }\n\n    init(id: String, name: String, language: String? = nil, isCustom: Bool = false) {\n        self.id = id\n        self.name = name\n        self.language = language\n        self.isCustom = isCustom\n    }\n}\n\n// MARK: -\n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:42:17.533244"}
{"instruction": "Show Package.swift implementation", "response": "```swift\n// swift-tools-version: 5.9\nimport PackageDescription\n\nlet package = Package(\n    name: \"SAMControlCenter\",\n    platforms: [\n        .macOS(.v14)\n    ],\n    products: [\n        .executable(name: \"SAMControlCenter\", targets: [\"SAMControlCenter\"])\n    ],\n    dependencies: [],\n    targets: [\n        .executableTarget(\n            name: \"SAMControlCenter\",\n            dependencies: [],\n            path: \"Sources\"\n        )\n    ]\n)\n\n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:44:00.070230"}
{"instruction": "Show KaraokeSession.swift implementation", "response": "```swift\nimport Foundation\nimport MultipeerConnectivity\n\n/// Shared protocol for iOS <-> tvOS karaoke communication\n/// Uses MultipeerConnectivity for low-latency local network streaming\n\n// MARK: - Message Types\n\nenum KaraokeMessageType: String, Codable {\n    case audioData          // Mic audio samples from iOS\n    case playRequest        // iOS requests song playback\n    case pauseRequest       // iOS requests pause\n    case stopRequest        // iOS requests stop\n    case syncLyrics         // tvOS sends current lyric position\n    case songList           // tvOS sends available songs\n    case nowPlaying         // tvOS sends current song info\n    case micConnected       // iOS mic is connected\n    case micDisconnected    // iOS mic disconnected\n}\n\nstruct KaraokeMessage: Codable {\n    let type: KaraokeMessageType\n    let payload: Data?\n    let timestamp: TimeInterval\n\n    init(type: KaraokeMessageType, payload: Data? = nil) {\n        self.type = type\n        self.payload = payload\n        self.timestamp = Date().timeIntervalSince1970\n    }\n}\n\n// MARK: - Song Metadata\n\nstruct KaraokeSong: Codable, Identifiable, Hashable {\n    let id: String\n    let title: String\n    let artist: String\n    let album: String?\n    let duration: TimeInterval\n    let hasLyrics: Bool\n    let videoPath: String\n\n    var displayName: String {\n        \"\\(artist) - \\(title)\"\n    }\n}\n\n// MARK: - Session Manager\n\nclass KaraokeSessionManager: NSObject, ObservableObject {\n\n    static let serviceType = \"sam-karaoke\"\n\n    let peerID: MCPeerID\n    var session: MCSession!\n\n    @Published var connectedPeers: [MCPeerID] = []\n    @Published var isConnected: Bool = false\n\n    // Callbacks\n    var onMessageReceived: ((KaraokeMessage, MCPeerID) -> Void)?\n    var onAudioReceived: ((Data, MCPeerID) -> Void)?\n\n    init(displayName: String) {\n        self.peerID = MCPeerID(displayName: displayName)\n        super.init()\n\n        self.session = MCSession(\n            peer: peerID,\n            securityIdentity: nil,\n            encryptionPreference: .none  // Low latency for audio\n        )\n        self.session.delegate = self\n    }\n\n    func send(_ message: KaraokeMessage, to peers: [MCPeerID]? = nil) {\n        let targets = peers ?? session.connectedPeers\n        guard !targets.isEmpty else { return }\n\n        do {\n            let data = try JSONEncoder().encode(message)\n            try session.send(data, toPeers: targets, with: .reliable)\n        } catch {\n            print(\"Send error: \\(error)\")\n        }\n    }\n\n    func sendAudio(_ audioData: Data, to peers: [MCPeerID]? = nil) {\n        let targets = peers ?? session.connectedPeers\n        guard !targets.isEmpty else { return }\n\n        // Use unreliable for lower latency audio streaming\n        do {\n            try session.send(audioData, toPeers: targets, with: .unreliable)\n        } catch {\n            // Audio drops are acceptable\n        }\n    }\n\n    func disconnect() {\n        session.disconnect()\n    }\n}\n\n// MARK: - MCSessionDelegate\n\next\n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:44:00.252891"}
{"instruction": "Show KaraokePlayerApp.swift implementation", "response": "```swift\nimport SwiftUI\nimport MultipeerConnectivity\nimport AVKit\n\n@main\nstruct KaraokePlayerApp: App {\n    var body: some Scene {\n        WindowGroup {\n            MainPlayerView()\n        }\n    }\n}\n\n// MARK: - Main Player View\n\nstruct MainPlayerView: View {\n    @StateObject private var viewModel = KaraokePlayerViewModel()\n\n    var body: some View {\n        ZStack {\n            // Background\n            Color.black.ignoresSafeArea()\n\n            if viewModel.isPlaying, let player = viewModel.videoPlayer {\n                // Video Player (karaoke video with lyrics)\n                VideoPlayer(player: player)\n                    .ignoresSafeArea()\n\n                // Mic level overlay\n                VStack {\n                    Spacer()\n                    HStack {\n                        MicIndicatorView(\n                            isConnected: viewModel.micConnected,\n                            level: viewModel.micLevel\n                        )\n                        Spacer()\n                    }\n                    .padding(40)\n                }\n            } else {\n                // Idle/Browse State\n                IdleView(\n                    isConnected: viewModel.isConnected,\n                    connectedDevice: viewModel.connectedDeviceName,\n                    songList: viewModel.songList,\n                    onSelectSong: viewModel.playSong\n                )\n            }\n\n            // Connection waiting overlay\n            if !viewModel.isConnected {\n                WaitingForConnectionView()\n            }\n        }\n        .onAppear {\n            viewModel.startAdvertising()\n        }\n    }\n}\n\n// MARK: - Waiting View\n\nstruct WaitingForConnectionView: View {\n    @State private var rotation: Double = 0\n\n    var body: some View {\n        VStack(spacing: 30) {\n            Image(systemName: \"antenna.radiowaves.left.and.right\")\n                .font(.system(size: 80))\n                .foregroundColor(.blue)\n                .rotationEffect(.degrees(rotation))\n                .animation(\n                    Animation.easeInOut(duration: 2).repeatForever(autoreverses: true),\n                    value: rotation\n                )\n                .onAppear { rotation = 10 }\n\n            Text(\"SAM Karaoke\")\n                .font(.largeTitle)\n                .fontWeight(.bold)\n\n            Text(\"Open the SAM Karaoke app on your iPhone to connect\")\n                .font(.title3)\n                .foregroundColor(.secondary)\n                .multilineTextAlignment(.center)\n        }\n        .padding(60)\n        .background(Color.black.opacity(0.8))\n        .cornerRadius(30)\n    }\n}\n\n// MARK: - Idle View (Song Browser)\n\nstruct IdleView: View {\n    let isConnected: Bool\n    let connectedDevice: String?\n    let songList: [KaraokeSong]\n    let onSelectSong: (KaraokeSong) -> Void\n\n    var body: some View {\n        VStack(spacing: 40) {\n            // Header\n            HStack {\n                VStack(alignment: .leading) {\n                    Text(\"SAM Kar\n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:44:00.254479"}
{"instruction": "Show AudioMixer.swift implementation", "response": "```swift\nimport Foundation\nimport AVFoundation\n\n/// Mixes backing track audio with incoming microphone audio from iOS\nclass AudioMixer: ObservableObject {\n\n    private var audioEngine: AVAudioEngine!\n    private var playerNode: AVAudioPlayerNode!\n    private var micMixerNode: AVAudioMixerNode!\n\n    private var micBuffer: AVAudioPCMBuffer?\n    private let micFormat: AVAudioFormat\n\n    @Published var isPlaying = false\n    @Published var micLevel: Float = 0.0\n    @Published var backingVolume: Float = 1.0\n    @Published var micVolume: Float = 1.0\n\n    // Circular buffer for incoming mic audio\n    private var micAudioQueue = [Data]()\n    private let micQueueLock = NSLock()\n\n    init() {\n        // Mic audio format (16-bit mono from iOS)\n        micFormat = AVAudioFormat(\n            commonFormat: .pcmFormatFloat32,\n            sampleRate: KaraokeAudioFormat.sampleRate,\n            channels: 1,\n            interleaved: false\n        )!\n\n        setupAudioEngine()\n    }\n\n    private func setupAudioEngine() {\n        audioEngine = AVAudioEngine()\n        playerNode = AVAudioPlayerNode()\n        micMixerNode = AVAudioMixerNode()\n\n        audioEngine.attach(playerNode)\n        audioEngine.attach(micMixerNode)\n\n        let mainMixer = audioEngine.mainMixerNode\n        let outputFormat = mainMixer.outputFormat(forBus: 0)\n\n        // Connect: playerNode -> mainMixer (backing track)\n        audioEngine.connect(playerNode, to: mainMixer, format: outputFormat)\n\n        // Connect: micMixerNode -> mainMixer (mic audio)\n        audioEngine.connect(micMixerNode, to: mainMixer, format: micFormat)\n\n        // Start mic audio injection timer\n        startMicInjection()\n    }\n\n    func start() {\n        do {\n            try audioEngine.start()\n            print(\"Audio engine started\")\n        } catch {\n            print(\"Failed to start audio engine: \\(error)\")\n        }\n    }\n\n    func stop() {\n        playerNode.stop()\n        audioEngine.stop()\n        isPlaying = false\n    }\n\n    // MARK: - Backing Track Playback\n\n    func playBackingTrack(url: URL) {\n        do {\n            let audioFile = try AVAudioFile(forReading: url)\n\n            playerNode.scheduleFile(audioFile, at: nil) { [weak self] in\n                DispatchQueue.main.async {\n                    self?.isPlaying = false\n                }\n            }\n\n            if !audioEngine.isRunning {\n                try audioEngine.start()\n            }\n\n            playerNode.play()\n            isPlaying = true\n            print(\"Playing backing track: \\(url.lastPathComponent)\")\n\n        } catch {\n            print(\"Failed to play backing track: \\(error)\")\n        }\n    }\n\n    func pause() {\n        playerNode.pause()\n        isPlaying = false\n    }\n\n    func resume() {\n        playerNode.play()\n        isPlaying = true\n    }\n\n    // MARK: - Microphone Audio Injection\n\n    func receiveMicAudio(_ data: Data) {\n        micQueueLock.lock()\n        micAudioQueue.append(data)\n        // Keep queue bounded (max ~500ms of audi\n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:44:00.255456"}
{"instruction": "Show MicrophoneManager.swift implementation", "response": "```swift\nimport Foundation\nimport AVFoundation\n\n/// Captures microphone audio and streams to tvOS\nclass MicrophoneManager: NSObject, ObservableObject {\n\n    private var audioEngine: AVAudioEngine?\n    private var inputNode: AVAudioInputNode?\n\n    @Published var isCapturing = false\n    @Published var micLevel: Float = 0.0\n    @Published var permissionGranted = false\n\n    var onAudioCaptured: ((Data) -> Void)?\n\n    override init() {\n        super.init()\n        checkPermission()\n    }\n\n    func checkPermission() {\n        switch AVAudioSession.sharedInstance().recordPermission {\n        case .granted:\n            permissionGranted = true\n        case .denied:\n            permissionGranted = false\n        case .undetermined:\n            AVAudioSession.sharedInstance().requestRecordPermission { [weak self] granted in\n                DispatchQueue.main.async {\n                    self?.permissionGranted = granted\n                }\n            }\n        @unknown default:\n            break\n        }\n    }\n\n    func startCapturing() {\n        guard permissionGranted else {\n            print(\"Microphone permission not granted\")\n            return\n        }\n\n        do {\n            let session = AVAudioSession.sharedInstance()\n            try session.setCategory(.playAndRecord, mode: .voiceChat, options: [.defaultToSpeaker, .allowBluetooth])\n            try session.setActive(true)\n\n            audioEngine = AVAudioEngine()\n            inputNode = audioEngine?.inputNode\n\n            guard let inputNode = inputNode else { return }\n\n            let recordingFormat = inputNode.outputFormat(forBus: 0)\n\n            // Install tap on input node\n            inputNode.installTap(onBus: 0, bufferSize: UInt32(KaraokeAudioFormat.bufferSize), format: recordingFormat) { [weak self] buffer, time in\n                self?.processAudioBuffer(buffer)\n            }\n\n            try audioEngine?.start()\n            isCapturing = true\n            print(\"Microphone capture started\")\n\n        } catch {\n            print(\"Failed to start audio capture: \\(error)\")\n        }\n    }\n\n    func stopCapturing() {\n        inputNode?.removeTap(onBus: 0)\n        audioEngine?.stop()\n        audioEngine = nil\n        inputNode = nil\n        isCapturing = false\n        print(\"Microphone capture stopped\")\n    }\n\n    private func processAudioBuffer(_ buffer: AVAudioPCMBuffer) {\n        guard let channelData = buffer.floatChannelData else { return }\n\n        let frames = buffer.frameLength\n        let channels = buffer.format.channelCount\n\n        // Calculate mic level for UI\n        var sum: Float = 0\n        for frame in 0..<Int(frames) {\n            let sample = channelData[0][frame]\n            sum += sample * sample\n        }\n        let rms = sqrt(sum / Float(frames))\n        DispatchQueue.main.async {\n            self.micLevel = min(1.0, rms * 5)  // Scale for visibility\n        }\n\n        // Convert to 16-bit PCM data for transmission\n        let data = convertToData(buffer)\n        onAudioCaptu\n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:44:00.256474"}
{"instruction": "Show KaraokeMicApp.swift implementation", "response": "```swift\nimport SwiftUI\nimport MultipeerConnectivity\n\n@main\nstruct KaraokeMicApp: App {\n    var body: some Scene {\n        WindowGroup {\n            ContentView()\n        }\n    }\n}\n\n// MARK: - Main Content View\n\nstruct ContentView: View {\n    @StateObject private var viewModel = KaraokeMicViewModel()\n\n    var body: some View {\n        NavigationView {\n            VStack(spacing: 30) {\n\n                // Connection Status\n                ConnectionStatusView(isConnected: viewModel.isConnected, peerName: viewModel.connectedTVName)\n\n                Spacer()\n\n                // Microphone Control\n                MicrophoneView(\n                    isCapturing: viewModel.isCapturing,\n                    micLevel: viewModel.micLevel,\n                    onToggle: viewModel.toggleMicrophone\n                )\n\n                Spacer()\n\n                // Now Playing (if connected)\n                if viewModel.isConnected {\n                    NowPlayingView(song: viewModel.currentSong)\n                }\n\n                // Song List\n                if viewModel.isConnected && !viewModel.songList.isEmpty {\n                    SongListView(songs: viewModel.songList, onSelect: viewModel.requestSong)\n                }\n\n                Spacer()\n            }\n            .padding()\n            .navigationTitle(\"SAM Karaoke\")\n            .toolbar {\n                ToolbarItem(placement: .navigationBarTrailing) {\n                    Button(action: viewModel.startBrowsing) {\n                        Image(systemName: \"antenna.radiowaves.left.and.right\")\n                    }\n                }\n            }\n            .onAppear {\n                viewModel.startBrowsing()\n            }\n        }\n    }\n}\n\n// MARK: - Connection Status\n\nstruct ConnectionStatusView: View {\n    let isConnected: Bool\n    let peerName: String?\n\n    var body: some View {\n        HStack {\n            Circle()\n                .fill(isConnected ? Color.green : Color.red)\n                .frame(width: 12, height: 12)\n\n            if isConnected, let name = peerName {\n                Text(\"Connected to \\(name)\")\n                    .font(.subheadline)\n            } else {\n                Text(\"Searching for Apple TV...\")\n                    .font(.subheadline)\n                    .foregroundColor(.secondary)\n            }\n        }\n        .padding(.horizontal, 16)\n        .padding(.vertical, 8)\n        .background(Color(.systemGray6))\n        .cornerRadius(20)\n    }\n}\n\n// MARK: - Microphone View\n\nstruct MicrophoneView: View {\n    let isCapturing: Bool\n    let micLevel: Float\n    let onToggle: () -> Void\n\n    var body: some View {\n        VStack(spacing: 20) {\n            // Mic button with level indicator\n            ZStack {\n                // Level ring\n                Circle()\n                    .stroke(Color.blue.opacity(0.3), lineWidth: 8)\n                    .frame(width: 150, height: 150)\n\n                Circle()\n                    .trim(from: 0, to: CGFloat(micLevel))\n                    .s\n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:44:00.257217"}
{"instruction": "Show SAMUITests.swift implementation", "response": "```swift\nimport XCTest\n\n/**\n SAM UI Tests\n\n These tests use XCTest's UI testing framework to verify the SAM app's behavior.\n\n Prerequisites:\n 1. SAM app must be built and available at the expected path\n 2. SAM must grant accessibility permissions to the test runner\n\n Running tests:\n - Open SAMUITests.xcodeproj in Xcode\n - Select the SAMUITests scheme\n - Press Cmd+U to run tests\n - Or use: xcodebuild test -project SAMUITests.xcodeproj -scheme SAMUITests\n\n Note: For WebView content, you may need to add accessibility labels\n to Vue components for XCTest to find them.\n*/\n\nclass SAMUITests: XCTestCase {\n\n    // The SAM app bundle identifier\n    let samBundleId = \"com.sam.terminal\"\n\n    // Debug server URL\n    let debugURL = \"http://localhost:9998\"\n\n    var app: XCUIApplication!\n\n    override func setUpWithError() throws {\n        continueAfterFailure = false\n\n        // Initialize app with bundle ID\n        app = XCUIApplication(bundleIdentifier: samBundleId)\n\n        // Alternatively, launch by path if bundle ID doesn't work\n        // app = XCUIApplication()\n        // app.launchEnvironment[\"SAM_TEST_MODE\"] = \"1\"\n    }\n\n    override func tearDownWithError() throws {\n        // Take screenshot on failure\n        if testRun?.failureCount ?? 0 > 0 {\n            let screenshot = XCUIScreen.main.screenshot()\n            let attachment = XCTAttachment(screenshot: screenshot)\n            attachment.name = \"Failure Screenshot\"\n            attachment.lifetime = .keepAlways\n            add(attachment)\n        }\n    }\n\n    // MARK: - Startup Tests\n\n    func testAppLaunches() throws {\n        // Launch the app\n        app.launch()\n\n        // Wait for window to appear\n        let window = app.windows.firstMatch\n        XCTAssertTrue(window.waitForExistence(timeout: 30), \"SAM window should appear within 30 seconds\")\n\n        // Verify window is visible\n        XCTAssertTrue(window.isHittable, \"SAM window should be hittable\")\n    }\n\n    func testWindowExists() throws {\n        app.activate()\n\n        let window = app.windows[\"SAM\"]\n        let exists = window.waitForExistence(timeout: 10)\n\n        XCTAssertTrue(exists, \"SAM window should exist\")\n    }\n\n    func testDebugServerResponds() throws {\n        // Query the debug server\n        let expectation = XCTestExpectation(description: \"Debug server responds\")\n\n        guard let url = URL(string: \"\\(debugURL)/debug/ping\") else {\n            XCTFail(\"Invalid debug URL\")\n            return\n        }\n\n        let task = URLSession.shared.dataTask(with: url) { data, response, error in\n            XCTAssertNil(error, \"Debug server should not return error\")\n            XCTAssertNotNil(data, \"Debug server should return data\")\n\n            if let httpResponse = response as? HTTPURLResponse {\n                XCTAssertEqual(httpResponse.statusCode, 200, \"Debug server should return 200\")\n            }\n\n            expectation.fulfill()\n        }\n        task.resume()\n\n        wait(for: [expectation], timeout: 5.0)\n    }\n\n    // MARK:\n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:44:01.953478"}
{"instruction": "Show AtlasShortcuts.swift implementation", "response": "```swift\nimport AppIntents\nimport Foundation\n\n/// Siri Shortcuts for SAM\n/// \"Hey Siri, ask SAM...\"\n/// \"Hey Siri, tell SAM to flirt\"\n/// \"Hey Siri, what's SAM's mood?\"\n\n// MARK: - Chat with SAM\n\nstruct AskSAMIntent: AppIntent {\n    static var title: LocalizedStringResource = \"Ask SAM\"\n    static var description = IntentDescription(\"Send a message to SAM and get a response\")\n    static var openAppWhenRun: Bool = false\n\n    @Parameter(title: \"Message\")\n    var message: String\n\n    func perform() async throws -> some IntentResult & ReturnsValue<String> & ProvidesDialog {\n        // Connect to SAM service\n        let response = await SAMShortcutService.shared.sendMessage(message)\n        return .result(value: response, dialog: IntentDialog(response))\n    }\n}\n\n// MARK: - Set Mood\n\nstruct SetSAMMoodIntent: AppIntent {\n    static var title: LocalizedStringResource = \"Set SAM Mood\"\n    static var description = IntentDescription(\"Change SAM's current mood\")\n\n    @Parameter(title: \"Mood\")\n    var mood: SAMMoodEntity\n\n    func perform() async throws -> some IntentResult & ProvidesDialog {\n        await SAMShortcutService.shared.setMood(mood.id)\n        return .result(dialog: \"SAM is now feeling \\(mood.name)\")\n    }\n}\n\nstruct SAMMoodEntity: AppEntity {\n    var id: String\n    var name: String\n\n    static var typeDisplayRepresentation: TypeDisplayRepresentation = \"Mood\"\n    static var defaultQuery = SAMMoodQuery()\n\n    var displayRepresentation: DisplayRepresentation {\n        DisplayRepresentation(title: LocalizedStringResource(stringLiteral: name))\n    }\n\n    static let moods: [SAMMoodEntity] = [\n        SAMMoodEntity(id: \"neutral\", name: \"Neutral\"),\n        SAMMoodEntity(id: \"happy\", name: \"Happy\"),\n        SAMMoodEntity(id: \"playful\", name: \"Playful\"),\n        SAMMoodEntity(id: \"flirty\", name: \"Flirty\"),\n        SAMMoodEntity(id: \"focused\", name: \"Focused\"),\n        SAMMoodEntity(id: \"aroused\", name: \"Aroused\")\n    ]\n}\n\nstruct SAMMoodQuery: EntityQuery {\n    func entities(for identifiers: [String]) async throws -> [SAMMoodEntity] {\n        SAMMoodEntity.moods.filter { identifiers.contains($0.id) }\n    }\n\n    func suggestedEntities() async throws -> [SAMMoodEntity] {\n        SAMMoodEntity.moods\n    }\n}\n\n// MARK: - Trigger Animation\n\nstruct SAMAnimationIntent: AppIntent {\n    static var title: LocalizedStringResource = \"SAM Animation\"\n    static var description = IntentDescription(\"Make SAM perform an animation\")\n\n    @Parameter(title: \"Animation\")\n    var animation: SAMAnimationEntity\n\n    func perform() async throws -> some IntentResult & ProvidesDialog {\n        await SAMShortcutService.shared.triggerAnimation(animation.id)\n        return .result(dialog: \"SAM is now doing: \\(animation.name)\")\n    }\n}\n\nstruct SAMAnimationEntity: AppEntity {\n    var id: String\n    var name: String\n\n    static var typeDisplayRepresentation: TypeDisplayRepresentation = \"Animation\"\n    static var defaultQuery = SAMAnimationQuery()\n\n    var displayRepresentation: DisplayRepresentation \n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:44:01.955782"}
{"instruction": "Show AtlasWidget.swift implementation", "response": "```swift\nimport WidgetKit\nimport SwiftUI\n\n/// SAM Home Screen Widget\n/// Quick access to your AI companion from the home screen\n\nstruct SAMWidgetEntry: TimelineEntry {\n    let date: Date\n    let mood: String\n    let moodEmoji: String\n    let lastMessage: String\n    let isConnected: Bool\n}\n\nstruct SAMWidgetProvider: TimelineProvider {\n    func placeholder(in context: Context) -> SAMWidgetEntry {\n        SAMWidgetEntry(\n            date: Date(),\n            mood: \"neutral\",\n            moodEmoji: \"\ud83d\ude0a\",\n            lastMessage: \"Hey, what's up?\",\n            isConnected: true\n        )\n    }\n\n    func getSnapshot(in context: Context, completion: @escaping (SAMWidgetEntry) -> Void) {\n        let entry = SAMWidgetEntry(\n            date: Date(),\n            mood: UserDefaults(suiteName: \"group.warpopen.atlas\")?.string(forKey: \"currentMood\") ?? \"neutral\",\n            moodEmoji: getMoodEmoji(UserDefaults(suiteName: \"group.warpopen.atlas\")?.string(forKey: \"currentMood\") ?? \"neutral\"),\n            lastMessage: UserDefaults(suiteName: \"group.warpopen.atlas\")?.string(forKey: \"lastMessage\") ?? \"Tap to chat...\",\n            isConnected: UserDefaults(suiteName: \"group.warpopen.atlas\")?.bool(forKey: \"isConnected\") ?? false\n        )\n        completion(entry)\n    }\n\n    func getTimeline(in context: Context, completion: @escaping (Timeline<SAMWidgetEntry>) -> Void) {\n        let defaults = UserDefaults(suiteName: \"group.warpopen.atlas\")\n\n        let entry = SAMWidgetEntry(\n            date: Date(),\n            mood: defaults?.string(forKey: \"currentMood\") ?? \"neutral\",\n            moodEmoji: getMoodEmoji(defaults?.string(forKey: \"currentMood\") ?? \"neutral\"),\n            lastMessage: defaults?.string(forKey: \"lastMessage\") ?? \"Tap to chat...\",\n            isConnected: defaults?.bool(forKey: \"isConnected\") ?? false\n        )\n\n        // Update every 15 minutes\n        let nextUpdate = Calendar.current.date(byAdding: .minute, value: 15, to: Date())!\n        let timeline = Timeline(entries: [entry], policy: .after(nextUpdate))\n        completion(timeline)\n    }\n\n    private func getMoodEmoji(_ mood: String) -> String {\n        switch mood {\n        case \"happy\": return \"\ud83d\ude0a\"\n        case \"playful\": return \"\ud83d\ude0f\"\n        case \"flirty\": return \"\ud83d\ude08\"\n        case \"focused\": return \"\ud83d\udcbb\"\n        case \"aroused\": return \"\ud83d\udd25\"\n        default: return \"\ud83d\ude10\"\n        }\n    }\n}\n\n// MARK: - Small Widget\n\nstruct SAMWidgetSmall: View {\n    let entry: SAMWidgetEntry\n\n    var body: some View {\n        ZStack {\n            // Background gradient\n            LinearGradient(\n                colors: [.purple.opacity(0.6), .blue.opacity(0.4)],\n                startPoint: .topLeading,\n                endPoint: .bottomTrailing\n            )\n\n            VStack(alignment: .leading, spacing: 8) {\n                HStack {\n                    Text(entry.moodEmoji)\n                        .font(.title)\n                    Spacer()\n                    Circle()\n                        .fill(entry.isConnected ? Color.gr\n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:44:01.956458"}
{"instruction": "Show AtlasApp.swift implementation", "response": "```swift\nimport SwiftUI\nimport WidgetKit\n\n/// SAM iOS Companion App\n/// Your AI companion on your wrist and in your pocket\n@main\nstruct SAMApp: App {\n    @StateObject private var atlasService = SAMService.shared\n    @Environment(\\.scenePhase) private var scenePhase\n\n    var body: some Scene {\n        WindowGroup {\n            ContentView()\n                .environmentObject(atlasService)\n                .onAppear {\n                    atlasService.connect()\n                }\n                .onChange(of: scenePhase) { phase in\n                    switch phase {\n                    case .active:\n                        atlasService.connect()\n                    case .background:\n                        atlasService.enterBackground()\n                    case .inactive:\n                        break\n                    @unknown default:\n                        break\n                    }\n                }\n        }\n    }\n}\n\n// MARK: - SAM Service\n\nclass SAMService: ObservableObject {\n    static let shared = SAMService()\n\n    @Published var isConnected = false\n    @Published var currentMood: Mood = .neutral\n    @Published var lastMessage: String = \"\"\n    @Published var isThinking = false\n    @Published var arousalLevel: Float = 0\n\n    private var webSocket: URLSessionWebSocketTask?\n    private let session = URLSession(configuration: .default)\n    private let serverURL = \"ws://localhost:8765\" // Will be configurable\n\n    enum Mood: String, CaseIterable {\n        case neutral, happy, playful, flirty, focused, aroused\n\n        var emoji: String {\n            switch self {\n            case .neutral: return \"\ud83d\ude10\"\n            case .happy: return \"\ud83d\ude0a\"\n            case .playful: return \"\ud83d\ude0f\"\n            case .flirty: return \"\ud83d\ude08\"\n            case .focused: return \"\ud83d\udcbb\"\n            case .aroused: return \"\ud83d\udd25\"\n            }\n        }\n\n        var color: Color {\n            switch self {\n            case .neutral: return .gray\n            case .happy: return .yellow\n            case .playful: return .pink\n            case .flirty: return .purple\n            case .focused: return .blue\n            case .aroused: return .red\n            }\n        }\n    }\n\n    // MARK: - Connection\n\n    func connect() {\n        guard let url = URL(string: serverURL) else { return }\n\n        webSocket = session.webSocketTask(with: url)\n        webSocket?.resume()\n\n        isConnected = true\n        listenForMessages()\n\n        // Register as iOS client\n        send([\n            \"type\": \"register\",\n            \"client_type\": \"ios_companion\",\n            \"capabilities\": [\"notifications\", \"siri\", \"widget\", \"watch\"]\n        ])\n    }\n\n    func disconnect() {\n        webSocket?.cancel(with: .goingAway, reason: nil)\n        webSocket = nil\n        isConnected = false\n    }\n\n    func enterBackground() {\n        // Keep connection alive for notifications\n        // iOS will manage the socket lifecycle\n    }\n\n    // MARK: - Messaging\n\n    func send(_ message: [String: Any]) {\n        guard let data = try? JSON\n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:44:01.957461"}
{"instruction": "Show Package.swift implementation", "response": "```swift\n// swift-tools-version: 5.9\nimport PackageDescription\n\nlet package = Package(\n    name: \"FashionArchive\",\n    platforms: [\n        .macOS(.v14),\n        .iOS(.v17),\n        .tvOS(.v17)\n    ],\n    products: [\n        .library(\n            name: \"FashionArchive\",\n            targets: [\"FashionArchive\"]\n        )\n    ],\n    targets: [\n        .target(\n            name: \"FashionArchive\",\n            path: \"Sources\"\n        )\n    ]\n)\n\n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:44:05.922267"}
{"instruction": "Show Models.swift implementation", "response": "```swift\nimport Foundation\n\n// MARK: - Article Model\n\nstruct Article: Identifiable, Codable, Hashable {\n    let id: String\n    let source: String\n    let sourceName: String?\n    let url: String?\n    let title: String\n    let author: String?\n    let category: String?\n    let subcategory: String?\n    let publishDate: String?\n    let content: String?\n    let wordCount: Int?\n    let imageCount: Int?\n    let tags: String?\n\n    enum CodingKeys: String, CodingKey {\n        case id, source, url, title, author, category, subcategory, content, tags\n        case sourceName = \"source_name\"\n        case publishDate = \"publish_date\"\n        case wordCount = \"word_count\"\n        case imageCount = \"image_count\"\n    }\n\n    var formattedDate: String {\n        guard let date = publishDate else { return \"Unknown date\" }\n        return String(date.prefix(10))\n    }\n\n    var excerpt: String {\n        guard let content = content else { return \"\" }\n        return String(content.prefix(200)) + (content.count > 200 ? \"...\" : \"\")\n    }\n}\n\n// MARK: - Stats Model\n\nstruct ArchiveStats: Codable {\n    let totalArticles: Int\n    let totalWords: Int\n    let totalImages: Int\n    let bySource: [SourceStats]\n    let byYear: [String: Int]\n    let topCategories: [String: Int]\n\n    enum CodingKeys: String, CodingKey {\n        case totalArticles = \"total_articles\"\n        case totalWords = \"total_words\"\n        case totalImages = \"total_images\"\n        case bySource = \"by_source\"\n        case byYear = \"by_year\"\n        case topCategories = \"top_categories\"\n    }\n}\n\nstruct SourceStats: Codable, Identifiable {\n    let source: String\n    let name: String\n    let count: Int\n    let words: Int\n\n    var id: String { source }\n}\n\n// MARK: - Trend Model\n\nstruct TrendData: Codable {\n    let term: String\n    let by: String\n    let data: [TrendPoint]\n}\n\nstruct TrendPoint: Codable, Identifiable {\n    let period: String\n    let mentions: Int\n\n    var id: String { period }\n\n    var year: Int? {\n        Int(period)\n    }\n}\n\n// MARK: - Search Response\n\nstruct SearchResponse: Codable {\n    let query: String?\n    let count: Int\n    let articles: [Article]\n}\n\n// MARK: - SAM Context\n\nstruct SAMContext: Codable {\n    let topic: String\n    let articles: [SAMArticleContext]\n}\n\nstruct SAMArticleContext: Codable, Identifiable {\n    let title: String\n    let source: String\n    let date: String?\n    let excerpt: String\n\n    var id: String { title }\n}\n\n// MARK: - Chat Message\n\nstruct ChatMessage: Identifiable {\n    let id = UUID()\n    let role: Role\n    let content: String\n    let timestamp: Date\n\n    enum Role {\n        case user, assistant, system\n    }\n}\n\n// MARK: - API Response Wrapper\n\nstruct APIResponse<T: Codable>: Codable {\n    let data: T?\n    let error: String?\n}\n\n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:44:05.923070"}
{"instruction": "Show Views.swift implementation", "response": "```swift\nimport SwiftUI\nimport Charts\n\n// MARK: - Browse View\n\nstruct BrowseView: View {\n    @EnvironmentObject var archiveService: ArchiveService\n    @State private var selectedSource: String?\n    @State private var selectedCategory: String?\n    @State private var selectedArticle: Article?\n\n    var body: some View {\n        VStack {\n            // Filters\n            HStack {\n                Picker(\"Source\", selection: $selectedSource) {\n                    Text(\"All Sources\").tag(nil as String?)\n                    ForEach(archiveService.sources) { source in\n                        Text(source.name).tag(source.source as String?)\n                    }\n                }\n                .pickerStyle(.menu)\n\n                Picker(\"Category\", selection: $selectedCategory) {\n                    Text(\"All Categories\").tag(nil as String?)\n                    ForEach(Array(archiveService.categories.keys.sorted().prefix(20)), id: \\.self) { cat in\n                        Text(cat.capitalized).tag(cat as String?)\n                    }\n                }\n                .pickerStyle(.menu)\n\n                Spacer()\n\n                if let stats = archiveService.stats {\n                    Text(\"\\(stats.totalArticles.formatted()) articles\")\n                        .foregroundColor(.secondary)\n                }\n            }\n            .padding(.horizontal)\n\n            // Article List\n            List(archiveService.articles.isEmpty ? archiveService.searchResults : archiveService.articles, selection: $selectedArticle) { article in\n                ArticleRow(article: article)\n                    .tag(article)\n            }\n            .listStyle(.inset)\n        }\n        .navigationTitle(\"Browse\")\n        .sheet(item: $selectedArticle) { article in\n            ArticleDetailView(article: article)\n        }\n        .onChange(of: selectedSource) { _, _ in\n            Task {\n                await archiveService.loadArticles(source: selectedSource, category: selectedCategory)\n            }\n        }\n        .onChange(of: selectedCategory) { _, _ in\n            Task {\n                await archiveService.loadArticles(source: selectedSource, category: selectedCategory)\n            }\n        }\n        .task {\n            await archiveService.loadArticles()\n        }\n    }\n}\n\n// MARK: - Article Row\n\nstruct ArticleRow: View {\n    let article: Article\n\n    var body: some View {\n        VStack(alignment: .leading, spacing: 4) {\n            Text(article.title)\n                .font(.headline)\n                .lineLimit(2)\n\n            HStack {\n                Text(article.sourceName ?? article.source)\n                    .font(.caption)\n                    .foregroundColor(.blue)\n\n                Text(\"\u2022\")\n                    .foregroundColor(.secondary)\n\n                Text(article.formattedDate)\n                    .font(.caption)\n                    .foregroundColor(.secondary)\n\n                if let wordCount = article.wordCount {\n                    Text(\"\u2022\")\n             \n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:44:05.926203"}
{"instruction": "Show FashionArchiveApp.swift implementation", "response": "```swift\nimport SwiftUI\n\n@main\nstruct FashionArchiveApp: App {\n    @StateObject private var archiveService = ArchiveService()\n\n    var body: some Scene {\n        WindowGroup {\n            ContentView()\n                .environmentObject(archiveService)\n        }\n        #if os(macOS)\n        .commands {\n            CommandGroup(replacing: .newItem) {\n                Button(\"Search Articles\") {\n                    NSApp.sendAction(#selector(NSResponder.becomeFirstResponder), to: nil, from: nil)\n                }\n                .keyboardShortcut(\"f\", modifiers: [.command])\n            }\n        }\n\n        Settings {\n            SettingsView()\n                .environmentObject(archiveService)\n        }\n        #endif\n    }\n}\n\n// MARK: - Content View (Platform Adaptive)\n\nstruct ContentView: View {\n    @EnvironmentObject var archiveService: ArchiveService\n\n    var body: some View {\n        #if os(tvOS)\n        TVContentView()\n        #elseif os(macOS)\n        MacContentView()\n        #else\n        MobileContentView()\n        #endif\n    }\n}\n\n// MARK: - macOS Layout\n\n#if os(macOS)\nstruct MacContentView: View {\n    @EnvironmentObject var archiveService: ArchiveService\n    @State private var selectedTab: Tab = .browse\n    @State private var searchText = \"\"\n\n    enum Tab: Hashable {\n        case browse, analytics, sam, settings\n    }\n\n    var body: some View {\n        NavigationSplitView {\n            List(selection: $selectedTab) {\n                Section(\"Library\") {\n                    Label(\"Browse\", systemImage: \"books.vertical\")\n                        .tag(Tab.browse)\n                    Label(\"Analytics\", systemImage: \"chart.bar.xaxis\")\n                        .tag(Tab.analytics)\n                    Label(\"SAM\", systemImage: \"brain\")\n                        .tag(Tab.sam)\n                }\n\n                Section(\"Sources\") {\n                    ForEach(archiveService.sources, id: \\.source) { source in\n                        HStack {\n                            Text(source.name)\n                            Spacer()\n                            Text(\"\\(source.count)\")\n                                .foregroundColor(.secondary)\n                        }\n                    }\n                }\n            }\n            .listStyle(.sidebar)\n            .frame(minWidth: 200)\n        } detail: {\n            switch selectedTab {\n            case .browse:\n                BrowseView()\n            case .analytics:\n                AnalyticsView()\n            case .sam:\n                SAMChatView()\n            case .settings:\n                SettingsView()\n            }\n        }\n        .searchable(text: $searchText, prompt: \"Search articles...\")\n        .onSubmit(of: .search) {\n            archiveService.search(query: searchText)\n        }\n        .task {\n            await archiveService.loadStats()\n        }\n    }\n}\n#endif\n\n// MARK: - iOS/iPadOS Layout\n\n#if os(iOS)\nstruct MobileContentView: View {\n    @EnvironmentObject var archiveService: ArchiveService\n    @St\n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:44:05.926972"}
{"instruction": "Show ArchiveService.swift implementation", "response": "```swift\nimport Foundation\nimport SwiftUI\n#if canImport(AVFoundation)\nimport AVFoundation\n#endif\n\n// MARK: - Archive Service\n\n@MainActor\nclass ArchiveService: ObservableObject {\n    // MARK: - Published Properties\n\n    @Published var stats: ArchiveStats?\n    @Published var articles: [Article] = []\n    @Published var searchResults: [Article] = []\n    @Published var sources: [SourceStats] = []\n    @Published var categories: [String: Int] = [:]\n    @Published var currentTrend: TrendData?\n    @Published var isLoading = false\n    @Published var errorMessage: String?\n    @Published var chatMessages: [ChatMessage] = []\n\n    // MARK: - Configuration\n\n    @AppStorage(\"apiBaseURL\") var apiBaseURL = \"http://localhost:8420\"\n\n    // MARK: - Speech\n\n    #if os(macOS)\n    private let speechSynthesizer = NSSpeechSynthesizer()\n    #elseif os(iOS) || os(tvOS)\n    private let speechSynthesizer = AVSpeechSynthesizer()\n    #endif\n\n    // MARK: - API Methods\n\n    private func apiURL(_ path: String) -> URL? {\n        URL(string: \"\\(apiBaseURL)\\(path)\")\n    }\n\n    private func fetch<T: Codable>(_ path: String) async throws -> T {\n        guard let url = apiURL(path) else {\n            throw URLError(.badURL)\n        }\n\n        let (data, _) = try await URLSession.shared.data(from: url)\n        return try JSONDecoder().decode(T.self, from: data)\n    }\n\n    private func post<T: Codable, R: Codable>(_ path: String, body: T) async throws -> R {\n        guard let url = apiURL(path) else {\n            throw URLError(.badURL)\n        }\n\n        var request = URLRequest(url: url)\n        request.httpMethod = \"POST\"\n        request.setValue(\"application/json\", forHTTPHeaderField: \"Content-Type\")\n        request.httpBody = try JSONEncoder().encode(body)\n\n        let (data, _) = try await URLSession.shared.data(for: request)\n        return try JSONDecoder().decode(R.self, from: data)\n    }\n\n    // MARK: - Load Data\n\n    func loadStats() async {\n        isLoading = true\n        defer { isLoading = false }\n\n        do {\n            stats = try await fetch(\"/stats\")\n            sources = stats?.bySource ?? []\n            categories = stats?.topCategories ?? [:]\n        } catch {\n            errorMessage = \"Failed to load stats: \\(error.localizedDescription)\"\n        }\n    }\n\n    func loadArticles(source: String? = nil, category: String? = nil, limit: Int = 50) async {\n        isLoading = true\n        defer { isLoading = false }\n\n        var path = \"/articles?limit=\\(limit)\"\n        if let source = source {\n            path += \"&source=\\(source)\"\n        }\n        if let category = category {\n            path += \"&category=\\(category.addingPercentEncoding(withAllowedCharacters: .urlQueryAllowed) ?? category)\"\n        }\n\n        do {\n            let response: SearchResponse = try await fetch(path)\n            articles = response.articles\n        } catch {\n            errorMessage = \"Failed to load articles: \\(error.localizedDescription)\"\n        }\n    }\n\n    func search(query: String, source: S\n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:44:05.927777"}
{"instruction": "Show SAMControlCenterApp.swift implementation", "response": "```swift\nimport SwiftUI\nimport AppKit\n\n@main\nstruct SAMControlCenterApp: App {\n    @NSApplicationDelegateAdaptor(AppDelegate.self) var appDelegate\n    @StateObject private var samState = SAMState()\n\n    init() {\n        // Share state\n        AppDelegate.samState = samState\n    }\n\n    var body: some Scene {\n        // Menu Bar Icon (brain in top bar)\n        MenuBarExtra {\n            VStack(alignment: .leading, spacing: 8) {\n                HStack {\n                    Image(systemName: \"brain.fill\")\n                        .foregroundStyle(.cyan)\n                    Text(\"SAM Control Center\")\n                        .fontWeight(.medium)\n                }\n                .padding(.bottom, 4)\n\n                Divider()\n\n                Button(\"Open Window\") {\n                    AppDelegate.shared?.openMainWindow()\n                }\n\n                Button(\"Quit\") {\n                    NSApp.terminate(nil)\n                }\n            }\n            .padding(8)\n        } label: {\n            Image(systemName: \"brain.fill\")\n        }\n    }\n}\n\n@MainActor\nclass AppDelegate: NSObject, NSApplicationDelegate {\n    static var shared: AppDelegate?\n    static var samState: SAMState?\n    var mainWindow: NSWindow?\n\n    func applicationDidFinishLaunching(_ notification: Notification) {\n        AppDelegate.shared = self\n        // Make this a regular app (not accessory/background) so windows show\n        NSApp.setActivationPolicy(.regular)\n        // Create and show window immediately\n        DispatchQueue.main.async {\n            self.openMainWindow()\n        }\n    }\n\n    func openMainWindow() {\n        if mainWindow == nil {\n            let contentView = ContentView()\n                .environmentObject(AppDelegate.samState ?? SAMState())\n                .frame(minWidth: 700, minHeight: 550)\n\n            mainWindow = NSWindow(\n                contentRect: NSRect(x: 0, y: 0, width: 750, height: 600),\n                styleMask: [.titled, .closable, .miniaturizable, .resizable],\n                backing: .buffered,\n                defer: false\n            )\n            mainWindow?.title = \"SAM Control Center\"\n            mainWindow?.contentView = NSHostingView(rootView: contentView)\n            mainWindow?.center()\n        }\n        mainWindow?.makeKeyAndOrderFront(nil)\n        NSApp.activate(ignoringOtherApps: true)\n    }\n\n    func applicationShouldHandleReopen(_ sender: NSApplication, hasVisibleWindows flag: Bool) -> Bool {\n        openMainWindow()\n        return true\n    }\n}\n\n// MARK: - Voice Models\n\nstruct VoiceInfo: Identifiable, Codable, Equatable {\n    let id: String\n    let name: String\n    let language: String?\n    let isCustom: Bool\n\n    enum CodingKeys: String, CodingKey {\n        case id, name, language\n        case isCustom = \"is_custom\"\n    }\n\n    init(id: String, name: String, language: String? = nil, isCustom: Bool = false) {\n        self.id = id\n        self.name = name\n        self.language = language\n        self.isCustom = isCustom\n    }\n}\n\n// MARK: -\n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:44:06.276608"}
{"instruction": "Show Package.swift implementation", "response": "```swift\n// swift-tools-version: 5.9\nimport PackageDescription\n\nlet package = Package(\n    name: \"SAMControlCenter\",\n    platforms: [\n        .macOS(.v14)\n    ],\n    products: [\n        .executable(name: \"SAMControlCenter\", targets: [\"SAMControlCenter\"])\n    ],\n    dependencies: [],\n    targets: [\n        .executableTarget(\n            name: \"SAMControlCenter\",\n            dependencies: [],\n            path: \"Sources\"\n        )\n    ]\n)\n\n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:47:10.600437"}
{"instruction": "Show KaraokeSession.swift implementation", "response": "```swift\nimport Foundation\nimport MultipeerConnectivity\n\n/// Shared protocol for iOS <-> tvOS karaoke communication\n/// Uses MultipeerConnectivity for low-latency local network streaming\n\n// MARK: - Message Types\n\nenum KaraokeMessageType: String, Codable {\n    case audioData          // Mic audio samples from iOS\n    case playRequest        // iOS requests song playback\n    case pauseRequest       // iOS requests pause\n    case stopRequest        // iOS requests stop\n    case syncLyrics         // tvOS sends current lyric position\n    case songList           // tvOS sends available songs\n    case nowPlaying         // tvOS sends current song info\n    case micConnected       // iOS mic is connected\n    case micDisconnected    // iOS mic disconnected\n}\n\nstruct KaraokeMessage: Codable {\n    let type: KaraokeMessageType\n    let payload: Data?\n    let timestamp: TimeInterval\n\n    init(type: KaraokeMessageType, payload: Data? = nil) {\n        self.type = type\n        self.payload = payload\n        self.timestamp = Date().timeIntervalSince1970\n    }\n}\n\n// MARK: - Song Metadata\n\nstruct KaraokeSong: Codable, Identifiable, Hashable {\n    let id: String\n    let title: String\n    let artist: String\n    let album: String?\n    let duration: TimeInterval\n    let hasLyrics: Bool\n    let videoPath: String\n\n    var displayName: String {\n        \"\\(artist) - \\(title)\"\n    }\n}\n\n// MARK: - Session Manager\n\nclass KaraokeSessionManager: NSObject, ObservableObject {\n\n    static let serviceType = \"sam-karaoke\"\n\n    let peerID: MCPeerID\n    var session: MCSession!\n\n    @Published var connectedPeers: [MCPeerID] = []\n    @Published var isConnected: Bool = false\n\n    // Callbacks\n    var onMessageReceived: ((KaraokeMessage, MCPeerID) -> Void)?\n    var onAudioReceived: ((Data, MCPeerID) -> Void)?\n\n    init(displayName: String) {\n        self.peerID = MCPeerID(displayName: displayName)\n        super.init()\n\n        self.session = MCSession(\n            peer: peerID,\n            securityIdentity: nil,\n            encryptionPreference: .none  // Low latency for audio\n        )\n        self.session.delegate = self\n    }\n\n    func send(_ message: KaraokeMessage, to peers: [MCPeerID]? = nil) {\n        let targets = peers ?? session.connectedPeers\n        guard !targets.isEmpty else { return }\n\n        do {\n            let data = try JSONEncoder().encode(message)\n            try session.send(data, toPeers: targets, with: .reliable)\n        } catch {\n            print(\"Send error: \\(error)\")\n        }\n    }\n\n    func sendAudio(_ audioData: Data, to peers: [MCPeerID]? = nil) {\n        let targets = peers ?? session.connectedPeers\n        guard !targets.isEmpty else { return }\n\n        // Use unreliable for lower latency audio streaming\n        do {\n            try session.send(audioData, toPeers: targets, with: .unreliable)\n        } catch {\n            // Audio drops are acceptable\n        }\n    }\n\n    func disconnect() {\n        session.disconnect()\n    }\n}\n\n// MARK: - MCSessionDelegate\n\next\n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:47:10.804177"}
{"instruction": "Show KaraokePlayerApp.swift implementation", "response": "```swift\nimport SwiftUI\nimport MultipeerConnectivity\nimport AVKit\n\n@main\nstruct KaraokePlayerApp: App {\n    var body: some Scene {\n        WindowGroup {\n            MainPlayerView()\n        }\n    }\n}\n\n// MARK: - Main Player View\n\nstruct MainPlayerView: View {\n    @StateObject private var viewModel = KaraokePlayerViewModel()\n\n    var body: some View {\n        ZStack {\n            // Background\n            Color.black.ignoresSafeArea()\n\n            if viewModel.isPlaying, let player = viewModel.videoPlayer {\n                // Video Player (karaoke video with lyrics)\n                VideoPlayer(player: player)\n                    .ignoresSafeArea()\n\n                // Mic level overlay\n                VStack {\n                    Spacer()\n                    HStack {\n                        MicIndicatorView(\n                            isConnected: viewModel.micConnected,\n                            level: viewModel.micLevel\n                        )\n                        Spacer()\n                    }\n                    .padding(40)\n                }\n            } else {\n                // Idle/Browse State\n                IdleView(\n                    isConnected: viewModel.isConnected,\n                    connectedDevice: viewModel.connectedDeviceName,\n                    songList: viewModel.songList,\n                    onSelectSong: viewModel.playSong\n                )\n            }\n\n            // Connection waiting overlay\n            if !viewModel.isConnected {\n                WaitingForConnectionView()\n            }\n        }\n        .onAppear {\n            viewModel.startAdvertising()\n        }\n    }\n}\n\n// MARK: - Waiting View\n\nstruct WaitingForConnectionView: View {\n    @State private var rotation: Double = 0\n\n    var body: some View {\n        VStack(spacing: 30) {\n            Image(systemName: \"antenna.radiowaves.left.and.right\")\n                .font(.system(size: 80))\n                .foregroundColor(.blue)\n                .rotationEffect(.degrees(rotation))\n                .animation(\n                    Animation.easeInOut(duration: 2).repeatForever(autoreverses: true),\n                    value: rotation\n                )\n                .onAppear { rotation = 10 }\n\n            Text(\"SAM Karaoke\")\n                .font(.largeTitle)\n                .fontWeight(.bold)\n\n            Text(\"Open the SAM Karaoke app on your iPhone to connect\")\n                .font(.title3)\n                .foregroundColor(.secondary)\n                .multilineTextAlignment(.center)\n        }\n        .padding(60)\n        .background(Color.black.opacity(0.8))\n        .cornerRadius(30)\n    }\n}\n\n// MARK: - Idle View (Song Browser)\n\nstruct IdleView: View {\n    let isConnected: Bool\n    let connectedDevice: String?\n    let songList: [KaraokeSong]\n    let onSelectSong: (KaraokeSong) -> Void\n\n    var body: some View {\n        VStack(spacing: 40) {\n            // Header\n            HStack {\n                VStack(alignment: .leading) {\n                    Text(\"SAM Kar\n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:47:10.861162"}
{"instruction": "Show AudioMixer.swift implementation", "response": "```swift\nimport Foundation\nimport AVFoundation\n\n/// Mixes backing track audio with incoming microphone audio from iOS\nclass AudioMixer: ObservableObject {\n\n    private var audioEngine: AVAudioEngine!\n    private var playerNode: AVAudioPlayerNode!\n    private var micMixerNode: AVAudioMixerNode!\n\n    private var micBuffer: AVAudioPCMBuffer?\n    private let micFormat: AVAudioFormat\n\n    @Published var isPlaying = false\n    @Published var micLevel: Float = 0.0\n    @Published var backingVolume: Float = 1.0\n    @Published var micVolume: Float = 1.0\n\n    // Circular buffer for incoming mic audio\n    private var micAudioQueue = [Data]()\n    private let micQueueLock = NSLock()\n\n    init() {\n        // Mic audio format (16-bit mono from iOS)\n        micFormat = AVAudioFormat(\n            commonFormat: .pcmFormatFloat32,\n            sampleRate: KaraokeAudioFormat.sampleRate,\n            channels: 1,\n            interleaved: false\n        )!\n\n        setupAudioEngine()\n    }\n\n    private func setupAudioEngine() {\n        audioEngine = AVAudioEngine()\n        playerNode = AVAudioPlayerNode()\n        micMixerNode = AVAudioMixerNode()\n\n        audioEngine.attach(playerNode)\n        audioEngine.attach(micMixerNode)\n\n        let mainMixer = audioEngine.mainMixerNode\n        let outputFormat = mainMixer.outputFormat(forBus: 0)\n\n        // Connect: playerNode -> mainMixer (backing track)\n        audioEngine.connect(playerNode, to: mainMixer, format: outputFormat)\n\n        // Connect: micMixerNode -> mainMixer (mic audio)\n        audioEngine.connect(micMixerNode, to: mainMixer, format: micFormat)\n\n        // Start mic audio injection timer\n        startMicInjection()\n    }\n\n    func start() {\n        do {\n            try audioEngine.start()\n            print(\"Audio engine started\")\n        } catch {\n            print(\"Failed to start audio engine: \\(error)\")\n        }\n    }\n\n    func stop() {\n        playerNode.stop()\n        audioEngine.stop()\n        isPlaying = false\n    }\n\n    // MARK: - Backing Track Playback\n\n    func playBackingTrack(url: URL) {\n        do {\n            let audioFile = try AVAudioFile(forReading: url)\n\n            playerNode.scheduleFile(audioFile, at: nil) { [weak self] in\n                DispatchQueue.main.async {\n                    self?.isPlaying = false\n                }\n            }\n\n            if !audioEngine.isRunning {\n                try audioEngine.start()\n            }\n\n            playerNode.play()\n            isPlaying = true\n            print(\"Playing backing track: \\(url.lastPathComponent)\")\n\n        } catch {\n            print(\"Failed to play backing track: \\(error)\")\n        }\n    }\n\n    func pause() {\n        playerNode.pause()\n        isPlaying = false\n    }\n\n    func resume() {\n        playerNode.play()\n        isPlaying = true\n    }\n\n    // MARK: - Microphone Audio Injection\n\n    func receiveMicAudio(_ data: Data) {\n        micQueueLock.lock()\n        micAudioQueue.append(data)\n        // Keep queue bounded (max ~500ms of audi\n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:47:10.862467"}
{"instruction": "Show MicrophoneManager.swift implementation", "response": "```swift\nimport Foundation\nimport AVFoundation\n\n/// Captures microphone audio and streams to tvOS\nclass MicrophoneManager: NSObject, ObservableObject {\n\n    private var audioEngine: AVAudioEngine?\n    private var inputNode: AVAudioInputNode?\n\n    @Published var isCapturing = false\n    @Published var micLevel: Float = 0.0\n    @Published var permissionGranted = false\n\n    var onAudioCaptured: ((Data) -> Void)?\n\n    override init() {\n        super.init()\n        checkPermission()\n    }\n\n    func checkPermission() {\n        switch AVAudioSession.sharedInstance().recordPermission {\n        case .granted:\n            permissionGranted = true\n        case .denied:\n            permissionGranted = false\n        case .undetermined:\n            AVAudioSession.sharedInstance().requestRecordPermission { [weak self] granted in\n                DispatchQueue.main.async {\n                    self?.permissionGranted = granted\n                }\n            }\n        @unknown default:\n            break\n        }\n    }\n\n    func startCapturing() {\n        guard permissionGranted else {\n            print(\"Microphone permission not granted\")\n            return\n        }\n\n        do {\n            let session = AVAudioSession.sharedInstance()\n            try session.setCategory(.playAndRecord, mode: .voiceChat, options: [.defaultToSpeaker, .allowBluetooth])\n            try session.setActive(true)\n\n            audioEngine = AVAudioEngine()\n            inputNode = audioEngine?.inputNode\n\n            guard let inputNode = inputNode else { return }\n\n            let recordingFormat = inputNode.outputFormat(forBus: 0)\n\n            // Install tap on input node\n            inputNode.installTap(onBus: 0, bufferSize: UInt32(KaraokeAudioFormat.bufferSize), format: recordingFormat) { [weak self] buffer, time in\n                self?.processAudioBuffer(buffer)\n            }\n\n            try audioEngine?.start()\n            isCapturing = true\n            print(\"Microphone capture started\")\n\n        } catch {\n            print(\"Failed to start audio capture: \\(error)\")\n        }\n    }\n\n    func stopCapturing() {\n        inputNode?.removeTap(onBus: 0)\n        audioEngine?.stop()\n        audioEngine = nil\n        inputNode = nil\n        isCapturing = false\n        print(\"Microphone capture stopped\")\n    }\n\n    private func processAudioBuffer(_ buffer: AVAudioPCMBuffer) {\n        guard let channelData = buffer.floatChannelData else { return }\n\n        let frames = buffer.frameLength\n        let channels = buffer.format.channelCount\n\n        // Calculate mic level for UI\n        var sum: Float = 0\n        for frame in 0..<Int(frames) {\n            let sample = channelData[0][frame]\n            sum += sample * sample\n        }\n        let rms = sqrt(sum / Float(frames))\n        DispatchQueue.main.async {\n            self.micLevel = min(1.0, rms * 5)  // Scale for visibility\n        }\n\n        // Convert to 16-bit PCM data for transmission\n        let data = convertToData(buffer)\n        onAudioCaptu\n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:47:10.863400"}
{"instruction": "Show KaraokeMicApp.swift implementation", "response": "```swift\nimport SwiftUI\nimport MultipeerConnectivity\n\n@main\nstruct KaraokeMicApp: App {\n    var body: some Scene {\n        WindowGroup {\n            ContentView()\n        }\n    }\n}\n\n// MARK: - Main Content View\n\nstruct ContentView: View {\n    @StateObject private var viewModel = KaraokeMicViewModel()\n\n    var body: some View {\n        NavigationView {\n            VStack(spacing: 30) {\n\n                // Connection Status\n                ConnectionStatusView(isConnected: viewModel.isConnected, peerName: viewModel.connectedTVName)\n\n                Spacer()\n\n                // Microphone Control\n                MicrophoneView(\n                    isCapturing: viewModel.isCapturing,\n                    micLevel: viewModel.micLevel,\n                    onToggle: viewModel.toggleMicrophone\n                )\n\n                Spacer()\n\n                // Now Playing (if connected)\n                if viewModel.isConnected {\n                    NowPlayingView(song: viewModel.currentSong)\n                }\n\n                // Song List\n                if viewModel.isConnected && !viewModel.songList.isEmpty {\n                    SongListView(songs: viewModel.songList, onSelect: viewModel.requestSong)\n                }\n\n                Spacer()\n            }\n            .padding()\n            .navigationTitle(\"SAM Karaoke\")\n            .toolbar {\n                ToolbarItem(placement: .navigationBarTrailing) {\n                    Button(action: viewModel.startBrowsing) {\n                        Image(systemName: \"antenna.radiowaves.left.and.right\")\n                    }\n                }\n            }\n            .onAppear {\n                viewModel.startBrowsing()\n            }\n        }\n    }\n}\n\n// MARK: - Connection Status\n\nstruct ConnectionStatusView: View {\n    let isConnected: Bool\n    let peerName: String?\n\n    var body: some View {\n        HStack {\n            Circle()\n                .fill(isConnected ? Color.green : Color.red)\n                .frame(width: 12, height: 12)\n\n            if isConnected, let name = peerName {\n                Text(\"Connected to \\(name)\")\n                    .font(.subheadline)\n            } else {\n                Text(\"Searching for Apple TV...\")\n                    .font(.subheadline)\n                    .foregroundColor(.secondary)\n            }\n        }\n        .padding(.horizontal, 16)\n        .padding(.vertical, 8)\n        .background(Color(.systemGray6))\n        .cornerRadius(20)\n    }\n}\n\n// MARK: - Microphone View\n\nstruct MicrophoneView: View {\n    let isCapturing: Bool\n    let micLevel: Float\n    let onToggle: () -> Void\n\n    var body: some View {\n        VStack(spacing: 20) {\n            // Mic button with level indicator\n            ZStack {\n                // Level ring\n                Circle()\n                    .stroke(Color.blue.opacity(0.3), lineWidth: 8)\n                    .frame(width: 150, height: 150)\n\n                Circle()\n                    .trim(from: 0, to: CGFloat(micLevel))\n                    .s\n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:47:10.889277"}
{"instruction": "Show SAMUITests.swift implementation", "response": "```swift\nimport XCTest\n\n/**\n SAM UI Tests\n\n These tests use XCTest's UI testing framework to verify the SAM app's behavior.\n\n Prerequisites:\n 1. SAM app must be built and available at the expected path\n 2. SAM must grant accessibility permissions to the test runner\n\n Running tests:\n - Open SAMUITests.xcodeproj in Xcode\n - Select the SAMUITests scheme\n - Press Cmd+U to run tests\n - Or use: xcodebuild test -project SAMUITests.xcodeproj -scheme SAMUITests\n\n Note: For WebView content, you may need to add accessibility labels\n to Vue components for XCTest to find them.\n*/\n\nclass SAMUITests: XCTestCase {\n\n    // The SAM app bundle identifier\n    let samBundleId = \"com.sam.terminal\"\n\n    // Debug server URL\n    let debugURL = \"http://localhost:9998\"\n\n    var app: XCUIApplication!\n\n    override func setUpWithError() throws {\n        continueAfterFailure = false\n\n        // Initialize app with bundle ID\n        app = XCUIApplication(bundleIdentifier: samBundleId)\n\n        // Alternatively, launch by path if bundle ID doesn't work\n        // app = XCUIApplication()\n        // app.launchEnvironment[\"SAM_TEST_MODE\"] = \"1\"\n    }\n\n    override func tearDownWithError() throws {\n        // Take screenshot on failure\n        if testRun?.failureCount ?? 0 > 0 {\n            let screenshot = XCUIScreen.main.screenshot()\n            let attachment = XCTAttachment(screenshot: screenshot)\n            attachment.name = \"Failure Screenshot\"\n            attachment.lifetime = .keepAlways\n            add(attachment)\n        }\n    }\n\n    // MARK: - Startup Tests\n\n    func testAppLaunches() throws {\n        // Launch the app\n        app.launch()\n\n        // Wait for window to appear\n        let window = app.windows.firstMatch\n        XCTAssertTrue(window.waitForExistence(timeout: 30), \"SAM window should appear within 30 seconds\")\n\n        // Verify window is visible\n        XCTAssertTrue(window.isHittable, \"SAM window should be hittable\")\n    }\n\n    func testWindowExists() throws {\n        app.activate()\n\n        let window = app.windows[\"SAM\"]\n        let exists = window.waitForExistence(timeout: 10)\n\n        XCTAssertTrue(exists, \"SAM window should exist\")\n    }\n\n    func testDebugServerResponds() throws {\n        // Query the debug server\n        let expectation = XCTestExpectation(description: \"Debug server responds\")\n\n        guard let url = URL(string: \"\\(debugURL)/debug/ping\") else {\n            XCTFail(\"Invalid debug URL\")\n            return\n        }\n\n        let task = URLSession.shared.dataTask(with: url) { data, response, error in\n            XCTAssertNil(error, \"Debug server should not return error\")\n            XCTAssertNotNil(data, \"Debug server should return data\")\n\n            if let httpResponse = response as? HTTPURLResponse {\n                XCTAssertEqual(httpResponse.statusCode, 200, \"Debug server should return 200\")\n            }\n\n            expectation.fulfill()\n        }\n        task.resume()\n\n        wait(for: [expectation], timeout: 5.0)\n    }\n\n    // MARK:\n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:47:12.034542"}
{"instruction": "Show AtlasShortcuts.swift implementation", "response": "```swift\nimport AppIntents\nimport Foundation\n\n/// Siri Shortcuts for SAM\n/// \"Hey Siri, ask SAM...\"\n/// \"Hey Siri, tell SAM to flirt\"\n/// \"Hey Siri, what's SAM's mood?\"\n\n// MARK: - Chat with SAM\n\nstruct AskSAMIntent: AppIntent {\n    static var title: LocalizedStringResource = \"Ask SAM\"\n    static var description = IntentDescription(\"Send a message to SAM and get a response\")\n    static var openAppWhenRun: Bool = false\n\n    @Parameter(title: \"Message\")\n    var message: String\n\n    func perform() async throws -> some IntentResult & ReturnsValue<String> & ProvidesDialog {\n        // Connect to SAM service\n        let response = await SAMShortcutService.shared.sendMessage(message)\n        return .result(value: response, dialog: IntentDialog(response))\n    }\n}\n\n// MARK: - Set Mood\n\nstruct SetSAMMoodIntent: AppIntent {\n    static var title: LocalizedStringResource = \"Set SAM Mood\"\n    static var description = IntentDescription(\"Change SAM's current mood\")\n\n    @Parameter(title: \"Mood\")\n    var mood: SAMMoodEntity\n\n    func perform() async throws -> some IntentResult & ProvidesDialog {\n        await SAMShortcutService.shared.setMood(mood.id)\n        return .result(dialog: \"SAM is now feeling \\(mood.name)\")\n    }\n}\n\nstruct SAMMoodEntity: AppEntity {\n    var id: String\n    var name: String\n\n    static var typeDisplayRepresentation: TypeDisplayRepresentation = \"Mood\"\n    static var defaultQuery = SAMMoodQuery()\n\n    var displayRepresentation: DisplayRepresentation {\n        DisplayRepresentation(title: LocalizedStringResource(stringLiteral: name))\n    }\n\n    static let moods: [SAMMoodEntity] = [\n        SAMMoodEntity(id: \"neutral\", name: \"Neutral\"),\n        SAMMoodEntity(id: \"happy\", name: \"Happy\"),\n        SAMMoodEntity(id: \"playful\", name: \"Playful\"),\n        SAMMoodEntity(id: \"flirty\", name: \"Flirty\"),\n        SAMMoodEntity(id: \"focused\", name: \"Focused\"),\n        SAMMoodEntity(id: \"aroused\", name: \"Aroused\")\n    ]\n}\n\nstruct SAMMoodQuery: EntityQuery {\n    func entities(for identifiers: [String]) async throws -> [SAMMoodEntity] {\n        SAMMoodEntity.moods.filter { identifiers.contains($0.id) }\n    }\n\n    func suggestedEntities() async throws -> [SAMMoodEntity] {\n        SAMMoodEntity.moods\n    }\n}\n\n// MARK: - Trigger Animation\n\nstruct SAMAnimationIntent: AppIntent {\n    static var title: LocalizedStringResource = \"SAM Animation\"\n    static var description = IntentDescription(\"Make SAM perform an animation\")\n\n    @Parameter(title: \"Animation\")\n    var animation: SAMAnimationEntity\n\n    func perform() async throws -> some IntentResult & ProvidesDialog {\n        await SAMShortcutService.shared.triggerAnimation(animation.id)\n        return .result(dialog: \"SAM is now doing: \\(animation.name)\")\n    }\n}\n\nstruct SAMAnimationEntity: AppEntity {\n    var id: String\n    var name: String\n\n    static var typeDisplayRepresentation: TypeDisplayRepresentation = \"Animation\"\n    static var defaultQuery = SAMAnimationQuery()\n\n    var displayRepresentation: DisplayRepresentation \n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:47:12.036982"}
{"instruction": "Show AtlasWidget.swift implementation", "response": "```swift\nimport WidgetKit\nimport SwiftUI\n\n/// SAM Home Screen Widget\n/// Quick access to your AI companion from the home screen\n\nstruct SAMWidgetEntry: TimelineEntry {\n    let date: Date\n    let mood: String\n    let moodEmoji: String\n    let lastMessage: String\n    let isConnected: Bool\n}\n\nstruct SAMWidgetProvider: TimelineProvider {\n    func placeholder(in context: Context) -> SAMWidgetEntry {\n        SAMWidgetEntry(\n            date: Date(),\n            mood: \"neutral\",\n            moodEmoji: \"\ud83d\ude0a\",\n            lastMessage: \"Hey, what's up?\",\n            isConnected: true\n        )\n    }\n\n    func getSnapshot(in context: Context, completion: @escaping (SAMWidgetEntry) -> Void) {\n        let entry = SAMWidgetEntry(\n            date: Date(),\n            mood: UserDefaults(suiteName: \"group.warpopen.atlas\")?.string(forKey: \"currentMood\") ?? \"neutral\",\n            moodEmoji: getMoodEmoji(UserDefaults(suiteName: \"group.warpopen.atlas\")?.string(forKey: \"currentMood\") ?? \"neutral\"),\n            lastMessage: UserDefaults(suiteName: \"group.warpopen.atlas\")?.string(forKey: \"lastMessage\") ?? \"Tap to chat...\",\n            isConnected: UserDefaults(suiteName: \"group.warpopen.atlas\")?.bool(forKey: \"isConnected\") ?? false\n        )\n        completion(entry)\n    }\n\n    func getTimeline(in context: Context, completion: @escaping (Timeline<SAMWidgetEntry>) -> Void) {\n        let defaults = UserDefaults(suiteName: \"group.warpopen.atlas\")\n\n        let entry = SAMWidgetEntry(\n            date: Date(),\n            mood: defaults?.string(forKey: \"currentMood\") ?? \"neutral\",\n            moodEmoji: getMoodEmoji(defaults?.string(forKey: \"currentMood\") ?? \"neutral\"),\n            lastMessage: defaults?.string(forKey: \"lastMessage\") ?? \"Tap to chat...\",\n            isConnected: defaults?.bool(forKey: \"isConnected\") ?? false\n        )\n\n        // Update every 15 minutes\n        let nextUpdate = Calendar.current.date(byAdding: .minute, value: 15, to: Date())!\n        let timeline = Timeline(entries: [entry], policy: .after(nextUpdate))\n        completion(timeline)\n    }\n\n    private func getMoodEmoji(_ mood: String) -> String {\n        switch mood {\n        case \"happy\": return \"\ud83d\ude0a\"\n        case \"playful\": return \"\ud83d\ude0f\"\n        case \"flirty\": return \"\ud83d\ude08\"\n        case \"focused\": return \"\ud83d\udcbb\"\n        case \"aroused\": return \"\ud83d\udd25\"\n        default: return \"\ud83d\ude10\"\n        }\n    }\n}\n\n// MARK: - Small Widget\n\nstruct SAMWidgetSmall: View {\n    let entry: SAMWidgetEntry\n\n    var body: some View {\n        ZStack {\n            // Background gradient\n            LinearGradient(\n                colors: [.purple.opacity(0.6), .blue.opacity(0.4)],\n                startPoint: .topLeading,\n                endPoint: .bottomTrailing\n            )\n\n            VStack(alignment: .leading, spacing: 8) {\n                HStack {\n                    Text(entry.moodEmoji)\n                        .font(.title)\n                    Spacer()\n                    Circle()\n                        .fill(entry.isConnected ? Color.gr\n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:47:12.037610"}
{"instruction": "Show AtlasApp.swift implementation", "response": "```swift\nimport SwiftUI\nimport WidgetKit\n\n/// SAM iOS Companion App\n/// Your AI companion on your wrist and in your pocket\n@main\nstruct SAMApp: App {\n    @StateObject private var atlasService = SAMService.shared\n    @Environment(\\.scenePhase) private var scenePhase\n\n    var body: some Scene {\n        WindowGroup {\n            ContentView()\n                .environmentObject(atlasService)\n                .onAppear {\n                    atlasService.connect()\n                }\n                .onChange(of: scenePhase) { phase in\n                    switch phase {\n                    case .active:\n                        atlasService.connect()\n                    case .background:\n                        atlasService.enterBackground()\n                    case .inactive:\n                        break\n                    @unknown default:\n                        break\n                    }\n                }\n        }\n    }\n}\n\n// MARK: - SAM Service\n\nclass SAMService: ObservableObject {\n    static let shared = SAMService()\n\n    @Published var isConnected = false\n    @Published var currentMood: Mood = .neutral\n    @Published var lastMessage: String = \"\"\n    @Published var isThinking = false\n    @Published var arousalLevel: Float = 0\n\n    private var webSocket: URLSessionWebSocketTask?\n    private let session = URLSession(configuration: .default)\n    private let serverURL = \"ws://localhost:8765\" // Will be configurable\n\n    enum Mood: String, CaseIterable {\n        case neutral, happy, playful, flirty, focused, aroused\n\n        var emoji: String {\n            switch self {\n            case .neutral: return \"\ud83d\ude10\"\n            case .happy: return \"\ud83d\ude0a\"\n            case .playful: return \"\ud83d\ude0f\"\n            case .flirty: return \"\ud83d\ude08\"\n            case .focused: return \"\ud83d\udcbb\"\n            case .aroused: return \"\ud83d\udd25\"\n            }\n        }\n\n        var color: Color {\n            switch self {\n            case .neutral: return .gray\n            case .happy: return .yellow\n            case .playful: return .pink\n            case .flirty: return .purple\n            case .focused: return .blue\n            case .aroused: return .red\n            }\n        }\n    }\n\n    // MARK: - Connection\n\n    func connect() {\n        guard let url = URL(string: serverURL) else { return }\n\n        webSocket = session.webSocketTask(with: url)\n        webSocket?.resume()\n\n        isConnected = true\n        listenForMessages()\n\n        // Register as iOS client\n        send([\n            \"type\": \"register\",\n            \"client_type\": \"ios_companion\",\n            \"capabilities\": [\"notifications\", \"siri\", \"widget\", \"watch\"]\n        ])\n    }\n\n    func disconnect() {\n        webSocket?.cancel(with: .goingAway, reason: nil)\n        webSocket = nil\n        isConnected = false\n    }\n\n    func enterBackground() {\n        // Keep connection alive for notifications\n        // iOS will manage the socket lifecycle\n    }\n\n    // MARK: - Messaging\n\n    func send(_ message: [String: Any]) {\n        guard let data = try? JSON\n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:47:12.038318"}
{"instruction": "Show Package.swift implementation", "response": "```swift\n// swift-tools-version: 5.9\nimport PackageDescription\n\nlet package = Package(\n    name: \"FashionArchive\",\n    platforms: [\n        .macOS(.v14),\n        .iOS(.v17),\n        .tvOS(.v17)\n    ],\n    products: [\n        .library(\n            name: \"FashionArchive\",\n            targets: [\"FashionArchive\"]\n        )\n    ],\n    targets: [\n        .target(\n            name: \"FashionArchive\",\n            path: \"Sources\"\n        )\n    ]\n)\n\n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:47:15.184524"}
{"instruction": "Show Models.swift implementation", "response": "```swift\nimport Foundation\n\n// MARK: - Article Model\n\nstruct Article: Identifiable, Codable, Hashable {\n    let id: String\n    let source: String\n    let sourceName: String?\n    let url: String?\n    let title: String\n    let author: String?\n    let category: String?\n    let subcategory: String?\n    let publishDate: String?\n    let content: String?\n    let wordCount: Int?\n    let imageCount: Int?\n    let tags: String?\n\n    enum CodingKeys: String, CodingKey {\n        case id, source, url, title, author, category, subcategory, content, tags\n        case sourceName = \"source_name\"\n        case publishDate = \"publish_date\"\n        case wordCount = \"word_count\"\n        case imageCount = \"image_count\"\n    }\n\n    var formattedDate: String {\n        guard let date = publishDate else { return \"Unknown date\" }\n        return String(date.prefix(10))\n    }\n\n    var excerpt: String {\n        guard let content = content else { return \"\" }\n        return String(content.prefix(200)) + (content.count > 200 ? \"...\" : \"\")\n    }\n}\n\n// MARK: - Stats Model\n\nstruct ArchiveStats: Codable {\n    let totalArticles: Int\n    let totalWords: Int\n    let totalImages: Int\n    let bySource: [SourceStats]\n    let byYear: [String: Int]\n    let topCategories: [String: Int]\n\n    enum CodingKeys: String, CodingKey {\n        case totalArticles = \"total_articles\"\n        case totalWords = \"total_words\"\n        case totalImages = \"total_images\"\n        case bySource = \"by_source\"\n        case byYear = \"by_year\"\n        case topCategories = \"top_categories\"\n    }\n}\n\nstruct SourceStats: Codable, Identifiable {\n    let source: String\n    let name: String\n    let count: Int\n    let words: Int\n\n    var id: String { source }\n}\n\n// MARK: - Trend Model\n\nstruct TrendData: Codable {\n    let term: String\n    let by: String\n    let data: [TrendPoint]\n}\n\nstruct TrendPoint: Codable, Identifiable {\n    let period: String\n    let mentions: Int\n\n    var id: String { period }\n\n    var year: Int? {\n        Int(period)\n    }\n}\n\n// MARK: - Search Response\n\nstruct SearchResponse: Codable {\n    let query: String?\n    let count: Int\n    let articles: [Article]\n}\n\n// MARK: - SAM Context\n\nstruct SAMContext: Codable {\n    let topic: String\n    let articles: [SAMArticleContext]\n}\n\nstruct SAMArticleContext: Codable, Identifiable {\n    let title: String\n    let source: String\n    let date: String?\n    let excerpt: String\n\n    var id: String { title }\n}\n\n// MARK: - Chat Message\n\nstruct ChatMessage: Identifiable {\n    let id = UUID()\n    let role: Role\n    let content: String\n    let timestamp: Date\n\n    enum Role {\n        case user, assistant, system\n    }\n}\n\n// MARK: - API Response Wrapper\n\nstruct APIResponse<T: Codable>: Codable {\n    let data: T?\n    let error: String?\n}\n\n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:47:15.185696"}
{"instruction": "Show Views.swift implementation", "response": "```swift\nimport SwiftUI\nimport Charts\n\n// MARK: - Browse View\n\nstruct BrowseView: View {\n    @EnvironmentObject var archiveService: ArchiveService\n    @State private var selectedSource: String?\n    @State private var selectedCategory: String?\n    @State private var selectedArticle: Article?\n\n    var body: some View {\n        VStack {\n            // Filters\n            HStack {\n                Picker(\"Source\", selection: $selectedSource) {\n                    Text(\"All Sources\").tag(nil as String?)\n                    ForEach(archiveService.sources) { source in\n                        Text(source.name).tag(source.source as String?)\n                    }\n                }\n                .pickerStyle(.menu)\n\n                Picker(\"Category\", selection: $selectedCategory) {\n                    Text(\"All Categories\").tag(nil as String?)\n                    ForEach(Array(archiveService.categories.keys.sorted().prefix(20)), id: \\.self) { cat in\n                        Text(cat.capitalized).tag(cat as String?)\n                    }\n                }\n                .pickerStyle(.menu)\n\n                Spacer()\n\n                if let stats = archiveService.stats {\n                    Text(\"\\(stats.totalArticles.formatted()) articles\")\n                        .foregroundColor(.secondary)\n                }\n            }\n            .padding(.horizontal)\n\n            // Article List\n            List(archiveService.articles.isEmpty ? archiveService.searchResults : archiveService.articles, selection: $selectedArticle) { article in\n                ArticleRow(article: article)\n                    .tag(article)\n            }\n            .listStyle(.inset)\n        }\n        .navigationTitle(\"Browse\")\n        .sheet(item: $selectedArticle) { article in\n            ArticleDetailView(article: article)\n        }\n        .onChange(of: selectedSource) { _, _ in\n            Task {\n                await archiveService.loadArticles(source: selectedSource, category: selectedCategory)\n            }\n        }\n        .onChange(of: selectedCategory) { _, _ in\n            Task {\n                await archiveService.loadArticles(source: selectedSource, category: selectedCategory)\n            }\n        }\n        .task {\n            await archiveService.loadArticles()\n        }\n    }\n}\n\n// MARK: - Article Row\n\nstruct ArticleRow: View {\n    let article: Article\n\n    var body: some View {\n        VStack(alignment: .leading, spacing: 4) {\n            Text(article.title)\n                .font(.headline)\n                .lineLimit(2)\n\n            HStack {\n                Text(article.sourceName ?? article.source)\n                    .font(.caption)\n                    .foregroundColor(.blue)\n\n                Text(\"\u2022\")\n                    .foregroundColor(.secondary)\n\n                Text(article.formattedDate)\n                    .font(.caption)\n                    .foregroundColor(.secondary)\n\n                if let wordCount = article.wordCount {\n                    Text(\"\u2022\")\n             \n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:47:15.187194"}
{"instruction": "Show FashionArchiveApp.swift implementation", "response": "```swift\nimport SwiftUI\n\n@main\nstruct FashionArchiveApp: App {\n    @StateObject private var archiveService = ArchiveService()\n\n    var body: some Scene {\n        WindowGroup {\n            ContentView()\n                .environmentObject(archiveService)\n        }\n        #if os(macOS)\n        .commands {\n            CommandGroup(replacing: .newItem) {\n                Button(\"Search Articles\") {\n                    NSApp.sendAction(#selector(NSResponder.becomeFirstResponder), to: nil, from: nil)\n                }\n                .keyboardShortcut(\"f\", modifiers: [.command])\n            }\n        }\n\n        Settings {\n            SettingsView()\n                .environmentObject(archiveService)\n        }\n        #endif\n    }\n}\n\n// MARK: - Content View (Platform Adaptive)\n\nstruct ContentView: View {\n    @EnvironmentObject var archiveService: ArchiveService\n\n    var body: some View {\n        #if os(tvOS)\n        TVContentView()\n        #elseif os(macOS)\n        MacContentView()\n        #else\n        MobileContentView()\n        #endif\n    }\n}\n\n// MARK: - macOS Layout\n\n#if os(macOS)\nstruct MacContentView: View {\n    @EnvironmentObject var archiveService: ArchiveService\n    @State private var selectedTab: Tab = .browse\n    @State private var searchText = \"\"\n\n    enum Tab: Hashable {\n        case browse, analytics, sam, settings\n    }\n\n    var body: some View {\n        NavigationSplitView {\n            List(selection: $selectedTab) {\n                Section(\"Library\") {\n                    Label(\"Browse\", systemImage: \"books.vertical\")\n                        .tag(Tab.browse)\n                    Label(\"Analytics\", systemImage: \"chart.bar.xaxis\")\n                        .tag(Tab.analytics)\n                    Label(\"SAM\", systemImage: \"brain\")\n                        .tag(Tab.sam)\n                }\n\n                Section(\"Sources\") {\n                    ForEach(archiveService.sources, id: \\.source) { source in\n                        HStack {\n                            Text(source.name)\n                            Spacer()\n                            Text(\"\\(source.count)\")\n                                .foregroundColor(.secondary)\n                        }\n                    }\n                }\n            }\n            .listStyle(.sidebar)\n            .frame(minWidth: 200)\n        } detail: {\n            switch selectedTab {\n            case .browse:\n                BrowseView()\n            case .analytics:\n                AnalyticsView()\n            case .sam:\n                SAMChatView()\n            case .settings:\n                SettingsView()\n            }\n        }\n        .searchable(text: $searchText, prompt: \"Search articles...\")\n        .onSubmit(of: .search) {\n            archiveService.search(query: searchText)\n        }\n        .task {\n            await archiveService.loadStats()\n        }\n    }\n}\n#endif\n\n// MARK: - iOS/iPadOS Layout\n\n#if os(iOS)\nstruct MobileContentView: View {\n    @EnvironmentObject var archiveService: ArchiveService\n    @St\n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:47:15.188133"}
{"instruction": "Show ArchiveService.swift implementation", "response": "```swift\nimport Foundation\nimport SwiftUI\n#if canImport(AVFoundation)\nimport AVFoundation\n#endif\n\n// MARK: - Archive Service\n\n@MainActor\nclass ArchiveService: ObservableObject {\n    // MARK: - Published Properties\n\n    @Published var stats: ArchiveStats?\n    @Published var articles: [Article] = []\n    @Published var searchResults: [Article] = []\n    @Published var sources: [SourceStats] = []\n    @Published var categories: [String: Int] = [:]\n    @Published var currentTrend: TrendData?\n    @Published var isLoading = false\n    @Published var errorMessage: String?\n    @Published var chatMessages: [ChatMessage] = []\n\n    // MARK: - Configuration\n\n    @AppStorage(\"apiBaseURL\") var apiBaseURL = \"http://localhost:8420\"\n\n    // MARK: - Speech\n\n    #if os(macOS)\n    private let speechSynthesizer = NSSpeechSynthesizer()\n    #elseif os(iOS) || os(tvOS)\n    private let speechSynthesizer = AVSpeechSynthesizer()\n    #endif\n\n    // MARK: - API Methods\n\n    private func apiURL(_ path: String) -> URL? {\n        URL(string: \"\\(apiBaseURL)\\(path)\")\n    }\n\n    private func fetch<T: Codable>(_ path: String) async throws -> T {\n        guard let url = apiURL(path) else {\n            throw URLError(.badURL)\n        }\n\n        let (data, _) = try await URLSession.shared.data(from: url)\n        return try JSONDecoder().decode(T.self, from: data)\n    }\n\n    private func post<T: Codable, R: Codable>(_ path: String, body: T) async throws -> R {\n        guard let url = apiURL(path) else {\n            throw URLError(.badURL)\n        }\n\n        var request = URLRequest(url: url)\n        request.httpMethod = \"POST\"\n        request.setValue(\"application/json\", forHTTPHeaderField: \"Content-Type\")\n        request.httpBody = try JSONEncoder().encode(body)\n\n        let (data, _) = try await URLSession.shared.data(for: request)\n        return try JSONDecoder().decode(R.self, from: data)\n    }\n\n    // MARK: - Load Data\n\n    func loadStats() async {\n        isLoading = true\n        defer { isLoading = false }\n\n        do {\n            stats = try await fetch(\"/stats\")\n            sources = stats?.bySource ?? []\n            categories = stats?.topCategories ?? [:]\n        } catch {\n            errorMessage = \"Failed to load stats: \\(error.localizedDescription)\"\n        }\n    }\n\n    func loadArticles(source: String? = nil, category: String? = nil, limit: Int = 50) async {\n        isLoading = true\n        defer { isLoading = false }\n\n        var path = \"/articles?limit=\\(limit)\"\n        if let source = source {\n            path += \"&source=\\(source)\"\n        }\n        if let category = category {\n            path += \"&category=\\(category.addingPercentEncoding(withAllowedCharacters: .urlQueryAllowed) ?? category)\"\n        }\n\n        do {\n            let response: SearchResponse = try await fetch(path)\n            articles = response.articles\n        } catch {\n            errorMessage = \"Failed to load articles: \\(error.localizedDescription)\"\n        }\n    }\n\n    func search(query: String, source: S\n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:47:15.189135"}
{"instruction": "Show SAMControlCenterApp.swift implementation", "response": "```swift\nimport SwiftUI\nimport AppKit\n\n@main\nstruct SAMControlCenterApp: App {\n    @NSApplicationDelegateAdaptor(AppDelegate.self) var appDelegate\n    @StateObject private var samState = SAMState()\n\n    init() {\n        // Share state\n        AppDelegate.samState = samState\n    }\n\n    var body: some Scene {\n        // Menu Bar Icon (brain in top bar)\n        MenuBarExtra {\n            VStack(alignment: .leading, spacing: 8) {\n                HStack {\n                    Image(systemName: \"brain.fill\")\n                        .foregroundStyle(.cyan)\n                    Text(\"SAM Control Center\")\n                        .fontWeight(.medium)\n                }\n                .padding(.bottom, 4)\n\n                Divider()\n\n                Button(\"Open Window\") {\n                    AppDelegate.shared?.openMainWindow()\n                }\n\n                Button(\"Quit\") {\n                    NSApp.terminate(nil)\n                }\n            }\n            .padding(8)\n        } label: {\n            Image(systemName: \"brain.fill\")\n        }\n    }\n}\n\n@MainActor\nclass AppDelegate: NSObject, NSApplicationDelegate {\n    static var shared: AppDelegate?\n    static var samState: SAMState?\n    var mainWindow: NSWindow?\n\n    func applicationDidFinishLaunching(_ notification: Notification) {\n        AppDelegate.shared = self\n        // Make this a regular app (not accessory/background) so windows show\n        NSApp.setActivationPolicy(.regular)\n        // Create and show window immediately\n        DispatchQueue.main.async {\n            self.openMainWindow()\n        }\n    }\n\n    func openMainWindow() {\n        if mainWindow == nil {\n            let contentView = ContentView()\n                .environmentObject(AppDelegate.samState ?? SAMState())\n                .frame(minWidth: 700, minHeight: 550)\n\n            mainWindow = NSWindow(\n                contentRect: NSRect(x: 0, y: 0, width: 750, height: 600),\n                styleMask: [.titled, .closable, .miniaturizable, .resizable],\n                backing: .buffered,\n                defer: false\n            )\n            mainWindow?.title = \"SAM Control Center\"\n            mainWindow?.contentView = NSHostingView(rootView: contentView)\n            mainWindow?.center()\n        }\n        mainWindow?.makeKeyAndOrderFront(nil)\n        NSApp.activate(ignoringOtherApps: true)\n    }\n\n    func applicationShouldHandleReopen(_ sender: NSApplication, hasVisibleWindows flag: Bool) -> Bool {\n        openMainWindow()\n        return true\n    }\n}\n\n// MARK: - Voice Models\n\nstruct VoiceInfo: Identifiable, Codable, Equatable {\n    let id: String\n    let name: String\n    let language: String?\n    let isCustom: Bool\n\n    enum CodingKeys: String, CodingKey {\n        case id, name, language\n        case isCustom = \"is_custom\"\n    }\n\n    init(id: String, name: String, language: String? = nil, isCustom: Bool = false) {\n        self.id = id\n        self.name = name\n        self.language = language\n        self.isCustom = isCustom\n    }\n}\n\n// MARK: -\n```", "category": "codebase_swift", "timestamp": "2026-01-26T03:47:15.380055"}
