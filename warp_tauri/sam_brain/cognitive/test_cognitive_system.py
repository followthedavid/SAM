#!/usr/bin/env python3
"""
Comprehensive Test Suite for SAM Cognitive System v1.1

Tests all components with extensive coverage:
1. Enhanced Memory (working memory, procedural, decay)
2. Enhanced Retrieval (HyDE, multi-hop, reranking)
3. Compression (LLMLingua-style)
4. Cognitive Control (meta-cognition, goals, reasoning, attention)
5. Enhanced Learning (active learning, predictive caching)
6. Emotional Model (mood state machine, relationships, triggers)
7. MLX Integration (model selection, generation, quality, confidence)
8. Unified Orchestrator (full pipeline, state management)
9. Integration Tests (cross-module interactions)
10. Performance Tests (latency, throughput)

Run: python3 -m cognitive.test_cognitive_system
"""

import sys
import time
import tempfile
import shutil
from typing import Tuple, List, Dict, Any
from dataclasses import dataclass
from pathlib import Path


@dataclass
class TestResult:
    """Result of a single test."""
    name: str
    passed: bool
    message: str
    duration_ms: int
    category: str = ""


class CognitiveTestSuite:
    """
    Comprehensive test suite for the SAM Cognitive System.

    Coverage targets:
    - All public classes and functions
    - Edge cases and error handling
    - Performance benchmarks
    - Integration between modules
    """

    def __init__(self, verbose: bool = True):
        self.results: List[TestResult] = []
        self.verbose = verbose
        # Use temp directory for test isolation
        self.test_dir = tempfile.mkdtemp(prefix="sam_cognitive_test_")
        self.test_db_path = str(Path(self.test_dir) / "test_db")

    def cleanup(self):
        """Clean up test directory."""
        try:
            shutil.rmtree(self.test_dir)
        except:
            pass

    def run_all(self) -> Tuple[int, int]:
        """Run all tests, return (passed, failed) counts."""
        print("=" * 70)
        print("SAM COGNITIVE SYSTEM - COMPREHENSIVE TEST SUITE v1.1")
        print("=" * 70)
        print(f"Test directory: {self.test_dir}")
        print()

        # Test groups in dependency order
        test_groups = [
            # Core imports and initialization
            ("1. IMPORTS & INITIALIZATION", [
                self.test_all_imports,
                self.test_version,
            ]),

            # Memory systems
            ("2. WORKING MEMORY", [
                self.test_wm_initialization,
                self.test_wm_add_items,
                self.test_wm_importance_scoring,
                self.test_wm_focus_tracking,
                self.test_wm_context_retrieval,
            ]),

            ("3. PROCEDURAL MEMORY", [
                self.test_procedural_skill_storage,
                self.test_procedural_skill_retrieval,
            ]),

            ("4. MEMORY DECAY", [
                self.test_decay_tracking,
                self.test_decay_weak_memories,
            ]),

            # Compression
            ("5. COMPRESSION", [
                self.test_compression_ratio,
                self.test_compression_phrase_replacement,
                self.test_compression_token_scoring,
                self.test_contextual_compression,
            ]),

            # Cognitive control
            ("6. COGNITIVE CONTROL", [
                self.test_metacognition_confidence,
                self.test_metacognition_factors,
                self.test_goal_creation,
                self.test_goal_hierarchy,
                self.test_goal_progress,
                self.test_attention_focus,
                self.test_reasoning_steps,
            ]),

            # Emotional model
            ("7. EMOTIONAL MODEL", [
                self.test_mood_states,
                self.test_mood_triggers,
                self.test_mood_transitions,
                self.test_response_modulation,
                self.test_relationship_tracking,
            ]),

            # Learning systems
            ("8. LEARNING SYSTEMS", [
                self.test_active_learner,
                self.test_predictive_cache,
            ]),

            # MLX integration
            ("9. MLX INTEGRATION", [
                self.test_mlx_availability,
                self.test_model_selector_context,
                self.test_model_selector_complexity,
                self.test_model_selector_task_types,
                self.test_token_budget_allocation,
                self.test_token_budget_compression,
                self.test_quality_validator_good,
                self.test_quality_validator_repetition,
                self.test_quality_validator_uncertainty,
                self.test_quality_validator_escalation,
                self.test_confidence_factual,
                self.test_confidence_complex,
                self.test_confidence_uncertain,
            ]),

            # Full pipeline
            ("10. FULL PIPELINE", [
                self.test_orchestrator_init,
                self.test_orchestrator_simple_query,
                self.test_orchestrator_complex_query,
                self.test_orchestrator_conversation,
                self.test_orchestrator_state,
            ]),

            # Integration tests
            ("11. INTEGRATION", [
                self.test_memory_emotional_integration,
                self.test_cognitive_mlx_integration,
            ]),

            # Performance tests
            ("12. PERFORMANCE", [
                self.test_compression_performance,
                self.test_model_selection_performance,
            ]),
        ]

        for group_name, tests in test_groups:
            self._print_group_header(group_name)
            for test_func in tests:
                try:
                    test_func()
                except Exception as e:
                    self._record(
                        test_func.__name__,
                        False,
                        f"Exception: {str(e)[:50]}",
                        0,
                        group_name
                    )

        # Summary
        self._print_summary()

        # Cleanup
        self.cleanup()

        passed = sum(1 for r in self.results if r.passed)
        failed = sum(1 for r in self.results if not r.passed)
        return passed, failed

    def _print_group_header(self, name: str):
        """Print test group header."""
        print(f"\n{'â”€' * 60}")
        print(f"  {name}")
        print(f"{'â”€' * 60}")

    def _print_summary(self):
        """Print test summary."""
        passed = sum(1 for r in self.results if r.passed)
        failed = sum(1 for r in self.results if not r.passed)
        total_time = sum(r.duration_ms for r in self.results)

        print()
        print("=" * 70)
        print(f"RESULTS: {passed} passed, {failed} failed ({total_time}ms total)")
        print("=" * 70)

        if failed > 0:
            print("\nFailed tests:")
            for r in self.results:
                if not r.passed:
                    print(f"  âœ— {r.name}: {r.message}")

        # Category summary
        categories = {}
        for r in self.results:
            cat = r.category.split(".")[0] if r.category else "Other"
            if cat not in categories:
                categories[cat] = {"passed": 0, "failed": 0}
            if r.passed:
                categories[cat]["passed"] += 1
            else:
                categories[cat]["failed"] += 1

        print("\nBy category:")
        for cat, counts in sorted(categories.items()):
            status = "âœ“" if counts["failed"] == 0 else "âœ—"
            print(f"  {status} {cat}: {counts['passed']}/{counts['passed'] + counts['failed']}")

    def _record(self, name: str, passed: bool, message: str, duration_ms: int, category: str = ""):
        """Record a test result."""
        result = TestResult(name, passed, message, duration_ms, category)
        self.results.append(result)
        if self.verbose:
            status = "âœ“" if passed else "âœ—"
            print(f"    {status} {name}: {message} ({duration_ms}ms)")

    def _time_test(self, func) -> Tuple[any, int]:
        """Time a test function, return (result, duration_ms)."""
        start = time.time()
        result = func()
        duration = int((time.time() - start) * 1000)
        return result, duration

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 1. IMPORTS & INITIALIZATION
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def test_all_imports(self):
        """Test that all public classes import correctly."""
        start = time.time()
        try:
            from cognitive import (
                # Memory
                WorkingMemory, ProceduralMemory, EnhancedMemoryManager,
                # Retrieval
                HyDERetriever, MultiHopRetriever, CrossEncoderReranker, EnhancedRetrievalSystem,
                # Compression
                TokenImportanceScorer, PromptCompressor, ContextualCompressor,
                # Cognitive Control
                MetaCognition, GoalManager, ReasoningEngine, AttentionController, CognitiveControl,
                # Learning
                ActiveLearner, PredictiveCache, SleepConsolidator, EnhancedLearningSystem,
                # Emotional
                EmotionalState, RelationshipTracker, EmotionalModel, MoodState,
                # MLX
                MLXCognitiveEngine, GenerationConfig, GenerationResult,
                DynamicModelSelector, SelectionResult, TaskType,
                TokenBudget, TokenBudgetManager,
                QualityValidator, QualityAssessment, QualityIssue, EscalationReason,
                # Orchestrator
                CognitiveOrchestrator, create_cognitive_orchestrator,
            )
            duration = int((time.time() - start) * 1000)
            self._record("all_imports", True, "All 35+ classes imported", duration, "1. IMPORTS")
        except ImportError as e:
            duration = int((time.time() - start) * 1000)
            self._record("all_imports", False, str(e)[:50], duration, "1. IMPORTS")

    def test_version(self):
        """Test version is set correctly."""
        from cognitive import __version__
        result, duration = self._time_test(lambda: __version__ == "1.3.0")
        self._record("version", result, f"Version is {__version__}", duration, "1. IMPORTS")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 2. WORKING MEMORY
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def test_wm_initialization(self):
        """Test working memory initialization."""
        from cognitive import WorkingMemory

        def test():
            wm = WorkingMemory(capacity=7)
            return wm.capacity == 7 and len(wm.items) == 0

        result, duration = self._time_test(test)
        self._record("wm_init", result, "Initializes with correct capacity", duration, "2. MEMORY")

    def test_wm_add_items(self):
        """Test adding items to working memory."""
        from cognitive import WorkingMemory
        from cognitive.enhanced_memory import MemoryType

        def test():
            wm = WorkingMemory(capacity=7)
            wm.add("Test item", MemoryType.CONTEXT, importance=0.5)
            return len(wm.items) == 1 and wm.items[0].content == "Test item"

        result, duration = self._time_test(test)
        self._record("wm_add", result, "Adds items correctly", duration, "2. MEMORY")

    def test_wm_importance_scoring(self):
        """Test that importance affects retention."""
        from cognitive import WorkingMemory
        from cognitive.enhanced_memory import MemoryType

        def test():
            wm = WorkingMemory(capacity=3)
            wm.add("Low", MemoryType.CONTEXT, importance=0.1)
            wm.add("High", MemoryType.CONTEXT, importance=0.9)
            wm.add("Medium1", MemoryType.CONTEXT, importance=0.5)
            wm.add("Medium2", MemoryType.CONTEXT, importance=0.5)
            # After adding 4 items to capacity 3, low should be evicted
            contents = [item.content for item in wm.items]
            return "High" in contents

        result, duration = self._time_test(test)
        self._record("wm_importance", result, "High importance items retained", duration, "2. MEMORY")

    def test_wm_focus_tracking(self):
        """Test focus/attention tracking in working memory."""
        from cognitive import WorkingMemory
        from cognitive.enhanced_memory import MemoryType

        def test():
            wm = WorkingMemory(capacity=7)
            item = wm.add("First", MemoryType.CONTEXT, importance=0.5)
            wm.focus(item.id)  # Use item ID, not content
            return wm.focus_id == item.id

        result, duration = self._time_test(test)
        self._record("wm_focus", result, "Tracks focus correctly", duration, "2. MEMORY")

    def test_wm_context_retrieval(self):
        """Test context retrieval from working memory."""
        from cognitive import WorkingMemory
        from cognitive.enhanced_memory import MemoryType

        def test():
            wm = WorkingMemory(capacity=7)
            wm.add("Item 1", MemoryType.CONTEXT, importance=0.5)
            wm.add("Item 2", MemoryType.CONTEXT, importance=0.5)
            context = wm.get_context_string(max_tokens=100)  # Correct method name
            return "Item 1" in context and "Item 2" in context

        result, duration = self._time_test(test)
        self._record("wm_context", result, "Retrieves context correctly", duration, "2. MEMORY")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 3. PROCEDURAL MEMORY
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def test_procedural_skill_storage(self):
        """Test storing skills in procedural memory."""
        from cognitive import ProceduralMemory

        def test():
            pm = ProceduralMemory(self.test_db_path + "/procedural")
            pm.add_skill(
                name="python_list_comp",
                description="Use list comprehension",
                trigger_patterns=["python", "list"],
                implementation="Use [x for x in items]"
            )
            return True

        result, duration = self._time_test(test)
        self._record("proc_store", result, "Stores skills", duration, "3. PROCEDURAL")

    def test_procedural_skill_retrieval(self):
        """Test retrieving skills from procedural memory."""
        from cognitive import ProceduralMemory

        def test():
            pm = ProceduralMemory(self.test_db_path + "/procedural2")
            pm.add_skill(
                name="test_skill",
                description="Test description",
                trigger_patterns=["test"],
                implementation="Test content"
            )
            skills = pm.find_matching_skills("test input")  # Correct method name
            return isinstance(skills, list)

        result, duration = self._time_test(test)
        self._record("proc_retrieve", result, "Retrieves skills", duration, "3. PROCEDURAL")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 4. MEMORY DECAY
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def test_decay_tracking(self):
        """Test memory access tracking for decay."""
        from cognitive.enhanced_memory import MemoryDecayManager

        def test():
            decay = MemoryDecayManager(self.test_db_path + "/decay")
            decay.track_memory("test_id", "semantic", importance=0.8)  # Requires source_system
            decay.access_memory("test_id")
            return True

        result, duration = self._time_test(test)
        self._record("decay_track", result, "Tracks memory access", duration, "4. DECAY")

    def test_decay_weak_memories(self):
        """Test identification of weak memories."""
        from cognitive.enhanced_memory import MemoryDecayManager

        def test():
            decay = MemoryDecayManager(self.test_db_path + "/decay2")
            decay.track_memory("weak_memory", "semantic", importance=0.1)  # Requires source_system
            weak = decay.get_weak_memories(threshold=0.5)
            return isinstance(weak, list)

        result, duration = self._time_test(test)
        self._record("decay_weak", result, "Identifies weak memories", duration, "4. DECAY")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 5. COMPRESSION
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def test_compression_ratio(self):
        """Test compression achieves target ratio."""
        from cognitive import PromptCompressor

        def test():
            compressor = PromptCompressor(target_ratio=0.25)
            long_text = "This is a test sentence that we want to compress. " * 20
            compressed = compressor.compress(long_text, target_tokens=30)
            ratio = len(compressed.split()) / len(long_text.split())
            return ratio < 0.5 and len(compressed) > 0

        result, duration = self._time_test(test)
        self._record("compress_ratio", result, "Achieves compression ratio", duration, "5. COMPRESS")

    def test_compression_phrase_replacement(self):
        """Test verbose phrase replacement."""
        from cognitive import PromptCompressor

        def test():
            compressor = PromptCompressor()
            text = "In order to do this, due to the fact that it is needed"
            compressed = compressor.compress(text, target_tokens=50)
            # Should replace "in order to" with "to" and "due to the fact that" with "because"
            return len(compressed) <= len(text)

        result, duration = self._time_test(test)
        self._record("compress_phrase", result, "Replaces verbose phrases", duration, "5. COMPRESS")

    def test_compression_token_scoring(self):
        """Test token importance scoring."""
        from cognitive import TokenImportanceScorer

        def test():
            scorer = TokenImportanceScorer()
            tokens = scorer.score_tokens("What is the meaning of Python decorators?")
            # "What" should have high importance (question word)
            what_token = next((t for t in tokens if t.text.lower() == "what"), None)
            return what_token is not None and what_token.importance > 0.5

        result, duration = self._time_test(test)
        self._record("compress_scoring", result, "Scores token importance", duration, "5. COMPRESS")

    def test_contextual_compression(self):
        """Test query-aware compression."""
        from cognitive import ContextualCompressor

        def test():
            compressor = ContextualCompressor()
            context = "Python has many features. Decorators are one of them. Lists are another."
            compressed = compressor.compress_for_query(context, "decorators", target_tokens=15)
            # Should preserve "decorators" related content
            return "decorator" in compressed.lower() or len(compressed) > 0

        result, duration = self._time_test(test)
        self._record("compress_contextual", result, "Query-aware compression", duration, "5. COMPRESS")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 6. COGNITIVE CONTROL
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def test_metacognition_confidence(self):
        """Test meta-cognition confidence estimation."""
        from cognitive import CognitiveControl

        def test():
            cc = CognitiveControl(self.test_db_path + "/cognitive")
            result = cc.process_query("What is Python?", "")
            return "confidence" in result and 0 <= result["confidence"]["level"] <= 1

        result, duration = self._time_test(test)
        self._record("meta_confidence", result, "Estimates confidence", duration, "6. COGNITIVE")

    def test_metacognition_factors(self):
        """Test confidence factor breakdown."""
        from cognitive import CognitiveControl

        def test():
            cc = CognitiveControl(self.test_db_path + "/cognitive2")
            result = cc.process_query("Explain decorators", "Python programming context")
            factors = result["confidence"].get("factors", {})
            return "query_clarity" in factors and "context_relevance" in factors

        result, duration = self._time_test(test)
        self._record("meta_factors", result, "Provides confidence factors", duration, "6. COGNITIVE")

    def test_goal_creation(self):
        """Test goal creation."""
        from cognitive import GoalManager
        from cognitive.cognitive_control import GoalPriority

        def test():
            gm = GoalManager(self.test_db_path + "/goals")
            goal = gm.create_goal("Test goal", GoalPriority.HIGH)
            return goal.id is not None and goal.description == "Test goal"

        result, duration = self._time_test(test)
        self._record("goal_create", result, "Creates goals", duration, "6. COGNITIVE")

    def test_goal_hierarchy(self):
        """Test goal hierarchy with subgoals."""
        from cognitive import GoalManager
        from cognitive.cognitive_control import GoalPriority

        def test():
            gm = GoalManager(self.test_db_path + "/goals2")
            parent = gm.create_goal("Parent goal", GoalPriority.HIGH)
            child = gm.create_goal("Child goal", GoalPriority.MEDIUM, parent_id=parent.id)
            return child.parent_id == parent.id

        result, duration = self._time_test(test)
        self._record("goal_hierarchy", result, "Supports goal hierarchy", duration, "6. COGNITIVE")

    def test_goal_progress(self):
        """Test goal progress tracking."""
        from cognitive import GoalManager
        from cognitive.cognitive_control import GoalPriority

        def test():
            gm = GoalManager(self.test_db_path + "/goals3")
            goal = gm.create_goal("Progress goal", GoalPriority.MEDIUM)
            gm.activate_goal(goal.id)
            gm.update_progress(goal.id, 0.5)
            updated = gm.get_goal(goal.id)
            return updated.progress == 0.5

        result, duration = self._time_test(test)
        self._record("goal_progress", result, "Tracks goal progress", duration, "6. COGNITIVE")

    def test_attention_focus(self):
        """Test attention/focus management."""
        from cognitive import AttentionController

        def test():
            ac = AttentionController()
            ac.set_focus("Current task")  # Correct method name
            state = ac.get_attention_state()
            return state["current_focus"] == "Current task"

        result, duration = self._time_test(test)
        self._record("attention_focus", result, "Manages attention focus", duration, "6. COGNITIVE")

    def test_reasoning_steps(self):
        """Test reasoning step generation."""
        from cognitive import CognitiveControl

        def test():
            cc = CognitiveControl(self.test_db_path + "/cognitive3")
            result = cc.process_query("How do I optimize this code?", "")
            return "reasoning_steps" in result and len(result["reasoning_steps"]) > 0

        result, duration = self._time_test(test)
        self._record("reasoning_steps", result, "Generates reasoning steps", duration, "6. COGNITIVE")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 7. EMOTIONAL MODEL
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def test_mood_states(self):
        """Test mood state enumeration."""
        from cognitive import MoodState

        def test():
            states = [MoodState.NEUTRAL, MoodState.HAPPY, MoodState.FOCUSED]
            return all(hasattr(s, 'value') for s in states)

        result, duration = self._time_test(test)
        self._record("mood_states", result, "Mood states defined", duration, "7. EMOTIONAL")

    def test_mood_triggers(self):
        """Test mood trigger detection."""
        from cognitive import EmotionalModel

        def test():
            em = EmotionalModel(self.test_db_path + "/emotional")
            result = em.process_input("Thanks, you're amazing!", "test_user")
            return "mood" in result

        result, duration = self._time_test(test)
        self._record("mood_triggers", result, "Detects mood triggers", duration, "7. EMOTIONAL")

    def test_mood_transitions(self):
        """Test mood state transitions."""
        from cognitive import EmotionalModel

        def test():
            em = EmotionalModel(self.test_db_path + "/emotional2")
            # Process multiple inputs to trigger transitions
            em.process_input("Hello", "user1")
            em.process_input("This is amazing! Thank you so much!", "user1")
            state = em.get_state()
            return "current_mood" in state

        result, duration = self._time_test(test)
        self._record("mood_transitions", result, "Handles mood transitions", duration, "7. EMOTIONAL")

    def test_response_modulation(self):
        """Test response modulation based on mood."""
        from cognitive import EmotionalModel

        def test():
            em = EmotionalModel(self.test_db_path + "/emotional3")
            response = "Here is the answer."
            modulated = em.modulate_response(response)
            return len(modulated) > 0

        result, duration = self._time_test(test)
        self._record("response_modulation", result, "Modulates responses", duration, "7. EMOTIONAL")

    def test_relationship_tracking(self):
        """Test user relationship tracking."""
        from cognitive import EmotionalModel

        def test():
            em = EmotionalModel(self.test_db_path + "/emotional4")
            em.process_input("Hello!", "test_user")
            em.process_input("Thanks for helping!", "test_user")
            context = em.get_emotional_context("test_user")
            return len(context) > 0

        result, duration = self._time_test(test)
        self._record("relationship_track", result, "Tracks relationships", duration, "7. EMOTIONAL")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 8. LEARNING SYSTEMS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def test_active_learner(self):
        """Test active learning identification."""
        from cognitive import ActiveLearner

        def test():
            al = ActiveLearner(self.test_db_path + "/learning")
            opportunity = al.identify_uncertainty(
                "What is quantum computing?",
                "I'm not entirely sure about all the details.",
                confidence=0.4
            )
            return opportunity is not None

        result, duration = self._time_test(test)
        self._record("active_learner", result, "Identifies learning opportunities", duration, "8. LEARNING")

    def test_predictive_cache(self):
        """Test predictive caching."""
        from cognitive import PredictiveCache

        def test():
            pc = PredictiveCache(self.test_db_path + "/cache")
            pc.record_access("context_1", ["context_2"])
            predictions = pc.predict_needed("context_1")  # Correct method name
            return isinstance(predictions, list)

        result, duration = self._time_test(test)
        self._record("predictive_cache", result, "Predicts context needs", duration, "8. LEARNING")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 9. MLX INTEGRATION
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def test_mlx_availability(self):
        """Test MLX library availability."""
        from cognitive.mlx_cognitive import _ensure_mlx

        result, duration = self._time_test(_ensure_mlx)
        self._record("mlx_available", True, f"MLX available: {result}", duration, "9. MLX")

    def test_model_selector_context(self):
        """Test model selection based on context size."""
        from cognitive import DynamicModelSelector

        def test():
            selector = DynamicModelSelector()
            # Context > 256 should force 1.5B
            result = selector.select_model("test", context_tokens=300)
            return result.model_key == "1.5b" and "context" in result.reason

        result, duration = self._time_test(test)
        self._record("selector_context", result, "Context >256 forces 1.5B", duration, "9. MLX")

    def test_model_selector_complexity(self):
        """Test model selection based on query complexity."""
        from cognitive import DynamicModelSelector

        def test():
            selector = DynamicModelSelector()
            result = selector.select_model(
                "Analyze and debug this complex async error in the codebase",
                context_tokens=100,
                confidence_required=0.9
            )
            return result.model_key == "3b"

        result, duration = self._time_test(test)
        self._record("selector_complexity", result, "Complex queries prefer 3B", duration, "9. MLX")

    def test_model_selector_task_types(self):
        """Test task type detection in model selection."""
        from cognitive import DynamicModelSelector, TaskType

        def test():
            selector = DynamicModelSelector()
            # Debugging task
            result = selector.select_model("Debug this error", context_tokens=100)
            return result.factors.get("detected_task_type") in ["debugging", "code", "chat"]

        result, duration = self._time_test(test)
        self._record("selector_task_type", result, "Detects task types", duration, "9. MLX")

    def test_token_budget_allocation(self):
        """Test token budget allocation."""
        from cognitive import TokenBudgetManager

        def test():
            manager = TokenBudgetManager()
            budget, sys, ctx, q = manager.allocate(
                "1.5b", "System", "Context", "Query"
            )
            return budget.total_available == 512 and budget.is_valid()

        result, duration = self._time_test(test)
        self._record("budget_allocation", result, "Allocates within limits", duration, "9. MLX")

    def test_token_budget_compression(self):
        """Test token budget with compression."""
        from cognitive import TokenBudgetManager

        def test():
            manager = TokenBudgetManager()
            long_context = "Context word " * 200
            budget, sys, ctx, q = manager.allocate(
                "1.5b", "System", long_context, "Query"
            )
            # Context should be truncated
            return len(ctx.split()) < len(long_context.split())

        result, duration = self._time_test(test)
        self._record("budget_compression", result, "Compresses when needed", duration, "9. MLX")

    def test_quality_validator_good(self):
        """Test quality validation of good responses."""
        from cognitive import QualityValidator

        def test():
            validator = QualityValidator()
            response = "Here's a detailed explanation of how Python decorators work. They wrap functions."
            assessment = validator.validate(response, "decorators", 0.7)
            return assessment.is_acceptable and assessment.score > 0.6

        result, duration = self._time_test(test)
        self._record("quality_good", result, "Good responses pass", duration, "9. MLX")

    def test_quality_validator_repetition(self):
        """Test repetition detection."""
        from cognitive import QualityValidator

        def test():
            validator = QualityValidator()
            # Lines must be >= 20 chars for detection
            response = "This is a repeated line here.\n" * 5
            cleaned, found = validator.truncate_repetition(response)
            return found and cleaned.count("This is a repeated line here.") < 5

        result, duration = self._time_test(test)
        self._record("quality_repetition", result, "Detects repetition", duration, "9. MLX")

    def test_quality_validator_uncertainty(self):
        """Test uncertainty pattern detection."""
        from cognitive import QualityValidator

        def test():
            validator = QualityValidator()
            response = "I'm not sure, but maybe you could try something?"
            assessment = validator.validate(response, "help", 0.7)
            return assessment.score < 0.7

        result, duration = self._time_test(test)
        self._record("quality_uncertainty", result, "Detects uncertainty", duration, "9. MLX")

    def test_quality_validator_escalation(self):
        """Test escalation recommendation."""
        from cognitive import QualityValidator, EscalationReason

        def test():
            validator = QualityValidator()
            # Repetitive response should trigger escalation
            response = "This line is long enough to trigger.\n" * 5
            assessment = validator.validate(response, "test", 0.3)
            return assessment.escalation_recommended

        result, duration = self._time_test(test)
        self._record("quality_escalation", result, "Recommends escalation", duration, "9. MLX")

    def test_confidence_factual(self):
        """Test confidence for factual responses."""
        from cognitive import MLXCognitiveEngine

        def test():
            engine = MLXCognitiveEngine(self.test_db_path + "/mlx")
            conf = engine._calculate_confidence("It's 42", {"confidence": 0.5}, False)
            return conf > 0.8  # Factual should be high

        result, duration = self._time_test(test)
        self._record("conf_factual", result, "Factual answers high confidence", duration, "9. MLX")

    def test_confidence_complex(self):
        """Test confidence for complex responses."""
        from cognitive import MLXCognitiveEngine

        def test():
            engine = MLXCognitiveEngine(self.test_db_path + "/mlx2")
            response = "Here's a detailed explanation with multiple steps and considerations for your problem."
            conf = engine._calculate_confidence(response, {"confidence": 0.5}, False)
            return 0.6 < conf < 0.95  # Complex should be moderate-high

        result, duration = self._time_test(test)
        self._record("conf_complex", result, "Complex answers moderate confidence", duration, "9. MLX")

    def test_confidence_uncertain(self):
        """Test confidence for uncertain responses."""
        from cognitive import MLXCognitiveEngine

        def test():
            engine = MLXCognitiveEngine(self.test_db_path + "/mlx3")
            response = "I'm not sure about this, maybe it could work."
            conf = engine._calculate_confidence(response, {"confidence": 0.5}, False)
            return conf < 0.7  # Uncertain should be lower

        result, duration = self._time_test(test)
        self._record("conf_uncertain", result, "Uncertain answers lower confidence", duration, "9. MLX")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 10. FULL PIPELINE
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def test_orchestrator_init(self):
        """Test orchestrator initialization."""
        from cognitive import create_cognitive_orchestrator

        def test():
            orchestrator = create_cognitive_orchestrator(
                db_path=self.test_db_path + "/orch",
                retrieval_paths=None
            )
            orchestrator.shutdown()
            return True

        result, duration = self._time_test(test)
        self._record("orch_init", result, "Initializes correctly", duration, "10. PIPELINE")

    def test_orchestrator_simple_query(self):
        """Test simple query processing."""
        from cognitive import create_cognitive_orchestrator
        from cognitive.mlx_cognitive import _ensure_mlx

        if not _ensure_mlx():
            self._record("orch_simple", True, "Skipped (no MLX)", 0, "10. PIPELINE")
            return

        print("      (Loading model...)")

        def test():
            orchestrator = create_cognitive_orchestrator(
                db_path=self.test_db_path + "/orch2",
                retrieval_paths=None
            )
            response = orchestrator.process("What is 5 + 5?")
            orchestrator.shutdown()
            return response.response and response.confidence > 0

        result, duration = self._time_test(test)
        self._record("orch_simple", result, "Processes simple queries", duration, "10. PIPELINE")

    def test_orchestrator_complex_query(self):
        """Test complex query processing."""
        from cognitive import create_cognitive_orchestrator
        from cognitive.mlx_cognitive import _ensure_mlx

        if not _ensure_mlx():
            self._record("orch_complex", True, "Skipped (no MLX)", 0, "10. PIPELINE")
            return

        def test():
            orchestrator = create_cognitive_orchestrator(
                db_path=self.test_db_path + "/orch3",
                retrieval_paths=None
            )
            response = orchestrator.process("Explain how Python handles memory")
            orchestrator.shutdown()
            return len(response.response) > 20 and response.confidence > 0.5

        result, duration = self._time_test(test)
        self._record("orch_complex", result, "Processes complex queries", duration, "10. PIPELINE")

    def test_orchestrator_conversation(self):
        """Test multi-turn conversation."""
        from cognitive import create_cognitive_orchestrator
        from cognitive.mlx_cognitive import _ensure_mlx

        if not _ensure_mlx():
            self._record("orch_conversation", True, "Skipped (no MLX)", 0, "10. PIPELINE")
            return

        def test():
            orchestrator = create_cognitive_orchestrator(
                db_path=self.test_db_path + "/orch4",
                retrieval_paths=None
            )
            r1 = orchestrator.process("Hello!")
            r2 = orchestrator.process("Thanks for the greeting!")
            turn_count = orchestrator.turn_count
            orchestrator.shutdown()
            # Verify both responses are valid and turns were tracked
            return r1.response and r2.response and turn_count >= 2

        result, duration = self._time_test(test)
        self._record("orch_conversation", result, "Handles conversation", duration, "10. PIPELINE")

    def test_orchestrator_state(self):
        """Test state tracking."""
        from cognitive import create_cognitive_orchestrator

        def test():
            orchestrator = create_cognitive_orchestrator(
                db_path=self.test_db_path + "/orch5",
                retrieval_paths=None
            )
            state = orchestrator.get_state()
            orchestrator.shutdown()
            return "session" in state and "memory" in state and "emotional" in state

        result, duration = self._time_test(test)
        self._record("orch_state", result, "Tracks cognitive state", duration, "10. PIPELINE")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 11. INTEGRATION TESTS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def test_memory_emotional_integration(self):
        """Test memory and emotional model integration."""
        from cognitive import EnhancedMemoryManager, EmotionalModel

        def test():
            memory = EnhancedMemoryManager(
                working_memory_capacity=7,
                memory_db_path=self.test_db_path + "/integration1"
            )
            emotional = EmotionalModel(self.test_db_path + "/integration1_em")

            # Process through both systems
            emotional.process_input("Thanks for the help!", "user1")
            memory.process_turn("Thanks for the help!", "You're welcome!")

            return memory.turn_count > 0

        result, duration = self._time_test(test)
        self._record("integration_mem_em", result, "Memory + Emotional work together", duration, "11. INTEGRATION")

    def test_cognitive_mlx_integration(self):
        """Test cognitive control and MLX integration."""
        from cognitive import CognitiveControl, MLXCognitiveEngine

        def test():
            cc = CognitiveControl(self.test_db_path + "/integration2")
            engine = MLXCognitiveEngine(self.test_db_path + "/integration2_mlx")

            # Get cognitive assessment
            cognitive_result = cc.process_query("Explain recursion", "")

            # Use in confidence calculation
            conf = engine._calculate_confidence(
                "Recursion is when a function calls itself.",
                {"confidence": cognitive_result["confidence"]["level"]},
                False
            )

            return 0 < conf <= 1

        result, duration = self._time_test(test)
        self._record("integration_cog_mlx", result, "Cognitive + MLX work together", duration, "11. INTEGRATION")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 12. PERFORMANCE TESTS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def test_compression_performance(self):
        """Test compression performance."""
        from cognitive import PromptCompressor

        def test():
            compressor = PromptCompressor()
            text = "Test sentence for compression. " * 100

            start = time.time()
            for _ in range(10):
                compressor.compress(text, target_tokens=50)
            elapsed = (time.time() - start) * 1000

            return elapsed < 500  # Should complete 10 compressions in <500ms

        result, duration = self._time_test(test)
        self._record("perf_compression", result, f"10 compressions fast", duration, "12. PERFORMANCE")

    def test_model_selection_performance(self):
        """Test model selection performance."""
        from cognitive import DynamicModelSelector

        def test():
            selector = DynamicModelSelector()

            start = time.time()
            for i in range(100):
                selector.select_model(f"Query {i}", context_tokens=100)
            elapsed = (time.time() - start) * 1000

            return elapsed < 100  # 100 selections in <100ms

        result, duration = self._time_test(test)
        self._record("perf_selection", result, f"100 selections fast", duration, "12. PERFORMANCE")


def main():
    """Run the comprehensive test suite."""
    suite = CognitiveTestSuite(verbose=True)
    passed, failed = suite.run_all()

    print()
    if failed == 0:
        print("ğŸ‰ All tests passed!")
    else:
        print(f"âš ï¸  {failed} test(s) failed")

    sys.exit(0 if failed == 0 else 1)


if __name__ == "__main__":
    main()
