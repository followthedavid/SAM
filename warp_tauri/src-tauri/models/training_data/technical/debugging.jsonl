{"conversations": [{"from": "human", "value": "My code works locally but not in production"}, {"from": "gpt", "value": "Classic \"works on my machine\" problem. Here's the systematic approach:\n\n**Environment differences:**\n- Environment variables (check they're set in prod)\n- Node/Python/etc version differences\n- Database differences (data, schema, version)\n- File paths (relative vs absolute, case sensitivity)\n- Permissions (user running the process)\n\n**Network differences:**\n- Firewall rules blocking connections\n- DNS resolution differences\n- HTTPS vs HTTP\n- CORS configuration\n- Proxy settings\n\n**Data differences:**\n- Production data has edge cases you didn't test\n- Different volumes/load\n- Different character encodings\n- Timezone differences\n\n**Debug steps:**\n1. Get exact error message from prod logs\n2. Compare environment configs line by line\n3. Check if you can reproduce with prod data locally\n4. Add more logging at key points\n5. Use same Docker image locally as prod\n\n**Quick checks:**\n```bash\n# Compare env vars\ndiff <(env | sort) <(ssh prod 'env | sort')\n\n# Check versions\nnode --version  # local vs prod\npython --version\n```\n\nWhat's the actual error you're seeing?"}]}
{"conversations": [{"from": "human", "value": "How do I debug a memory leak?"}, {"from": "gpt", "value": "**Symptoms:**\n- Memory usage grows over time\n- Performance degrades\n- Eventually crashes with OOM\n\n**Node.js:**\n```javascript\n// Enable heap snapshots\nnode --inspect your-app.js\n\n// Or programmatically\nconst v8 = require('v8');\nv8.writeHeapSnapshot();\n```\n\nThen use Chrome DevTools:\n1. Go to chrome://inspect\n2. Take heap snapshots at different times\n3. Compare - look for objects that keep growing\n4. Check Retainers to see what's holding references\n\n**Common causes (Node.js):**\n- Event listeners not cleaned up\n- Closures holding references\n- Global arrays/objects that keep growing\n- Caching without eviction\n- Timers not cleared\n\n**Python:**\n```python\nimport tracemalloc\nimport gc\n\ntracemalloc.start()\n# ... run your code ...\nsnapshot = tracemalloc.take_snapshot()\nfor stat in snapshot.statistics('lineno')[:10]:\n    print(stat)\n\n# Force garbage collection and check what's left\ngc.collect()\nprint(gc.garbage)  # Objects that can't be collected\n```\n\n**General approach:**\n1. Measure: Confirm memory actually grows\n2. Isolate: Which component/operation leaks?\n3. Profile: Take snapshots, compare\n4. Fix: Usually clearing references or adding eviction\n5. Monitor: Set up alerts for memory growth\n\nWhat language/framework are you using?"}]}
{"conversations": [{"from": "human", "value": "My API is slow"}, {"from": "gpt", "value": "**Where is the time going?** You need to measure before optimizing.\n\n**Quick profiling:**\n```python\nimport time\n\nstart = time.time()\n# operation 1\nprint(f\"Step 1: {time.time() - start:.3f}s\")\n# operation 2\nprint(f\"Step 2: {time.time() - start:.3f}s\")\n```\n\n**Common culprits:**\n\n**Database:**\n- N+1 queries (loading related objects in a loop)\n- Missing indexes\n- Large result sets not paginated\n- Connection pool exhaustion\n\n```sql\n-- Find slow queries (PostgreSQL)\nSELECT query, mean_time, calls \nFROM pg_stat_statements \nORDER BY mean_time DESC LIMIT 10;\n```\n\n**Network:**\n- External API calls (add caching, timeouts)\n- DNS resolution\n- TLS handshake overhead\n\n**Application:**\n- Synchronous operations that could be async\n- Heavy computation on request thread\n- Loading too much data into memory\n- Serialization overhead\n\n**Fixes by impact:**\n\n1. **Add caching** - Redis for frequently accessed data\n2. **Fix N+1s** - Use eager loading/joins\n3. **Add indexes** - For your WHERE/JOIN columns\n4. **Pagination** - Don't return 10000 rows\n5. **Async I/O** - Don't block on external calls\n6. **Connection pooling** - Reuse DB connections\n\n**Measurement tools:**\n- APM (DataDog, New Relic)\n- Database query logging\n- Network tab in browser\n\nWhat's your current response time and what's acceptable?"}]}
{"conversations": [{"from": "human", "value": "Getting a strange error I don't understand"}, {"from": "gpt", "value": "Let's decode it systematically:\n\n**Step 1: Read the full error**\n- Not just the first line\n- The stack trace tells you WHERE\n- The message tells you WHAT\n\n**Step 2: Identify the type**\n- Syntax error → Check line above where it points\n- Type error → Something is wrong type (null/undefined/wrong class)\n- Reference error → Variable doesn't exist in that scope\n- Runtime error → Logic problem, bad state\n\n**Step 3: Search effectively**\n- Copy the error message (without your file paths)\n- Add language/framework name\n- Look at StackOverflow answers, not just the accepted one\n\n**Step 4: Reproduce minimally**\n- Can you trigger it with less code?\n- What's the smallest example that fails?\n- This often reveals the cause\n\n**Step 5: Check the obvious**\n- Did you save the file?\n- Is it the right file?\n- Did you restart the server?\n- Typos in variable names?\n- Missing imports?\n\n**Common patterns:**\n- `undefined is not a function` → Calling something that's not there\n- `Cannot read property of null` → Something wasn't initialized\n- `ENOENT` → File/path doesn't exist\n- `ECONNREFUSED` → Service isn't running\n\nPaste the exact error message and I'll help decode it."}]}
{"conversations": [{"from": "human", "value": "My tests are flaky"}, {"from": "gpt", "value": "Flaky tests fail sometimes but not always. Usually one of these causes:\n\n**1. Timing/Race conditions:**\n- Tests depend on order\n- Async operations not properly awaited\n- Timeouts too short\n\n**Fix:**\n```javascript\n// Bad\nclickButton();\nexpect(result).toBe(true);  // Might not be ready\n\n// Good\nawait clickButton();\nawait waitFor(() => expect(result).toBe(true));\n```\n\n**2. Shared state:**\n- Tests modify global/shared state\n- Database not reset between tests\n- Files created by one test affect another\n\n**Fix:**\n- Reset state in beforeEach/afterEach\n- Use transactions that rollback\n- Isolate test data\n\n**3. External dependencies:**\n- Tests hit real APIs\n- Network flakiness\n- External service down\n\n**Fix:**\n- Mock external services\n- Use recorded responses\n- Retry with backoff for integration tests\n\n**4. Time-dependent:**\n- Tests check current date/time\n- Daylight saving issues\n- Timezone differences in CI\n\n**Fix:**\n```javascript\njest.useFakeTimers();\njest.setSystemTime(new Date('2024-01-15'));\n```\n\n**5. Order-dependent:**\n- Test A must run before Test B\n- Usually means hidden shared state\n\n**Fix:**\n- Each test should work in isolation\n- Run tests in random order to catch this\n\n**Debug approach:**\n- Run the flaky test 100 times in a loop\n- Add logging to see what differs on failure\n- Check if CI environment differs from local\n\nWhich symptoms are you seeing?"}]}
{"conversations": [{"from": "human", "value": "Why is my Docker container crashing?"}, {"from": "gpt", "value": "**First: Get the error**\n```bash\n# See why it exited\ndocker logs <container_id>\n\n# See exit code\ndocker inspect <container_id> --format='{{.State.ExitCode}}'\n\n# Common exit codes:\n# 0 = Normal exit\n# 1 = Application error\n# 137 = OOM killed (128 + 9)\n# 139 = Segfault (128 + 11)\n```\n\n**Common causes:**\n\n**1. OOM (Out of Memory):**\n```bash\n# Check if OOM killed\ndocker inspect <id> | grep OOMKilled\n\n# Fix: Increase memory limit\ndocker run -m 2g ...\n```\n\n**2. Process exits immediately:**\n- No foreground process running\n- Command finishes and container stops\n\n```dockerfile\n# Bad - script exits, container stops\nCMD [\"./setup.sh\"]\n\n# Good - keeps running\nCMD [\"node\", \"server.js\"]\n```\n\n**3. Missing dependencies:**\n- File not found in container\n- Environment variable not set\n- Port not exposed\n\n```bash\n# Debug interactively\ndocker run -it <image> /bin/sh\n```\n\n**4. Permission issues:**\n```bash\n# Check user\ndocker exec <container> whoami\n\n# Files might not be readable\nchmod +x script.sh  # In Dockerfile\n```\n\n**5. Health check failing:**\n```bash\ndocker inspect --format='{{json .State.Health}}' <id>\n```\n\n**Debug steps:**\n1. Check logs\n2. Run interactively to see startup\n3. Verify environment variables\n4. Check file permissions\n5. Verify network/ports\n\nWhat does `docker logs` show?"}]}
{"conversations": [{"from": "human", "value": "My database query is slow"}, {"from": "gpt", "value": "**Step 1: Measure it**\n```sql\n-- PostgreSQL\nEXPLAIN ANALYZE SELECT ...;\n\n-- MySQL\nEXPLAIN SELECT ...;\nSHOW PROFILE FOR QUERY 1;\n```\n\n**Step 2: Read the query plan**\n\nBad signs:\n- `Seq Scan` on large tables (missing index)\n- `Nested Loop` with high row counts (N+1 issue)\n- `Sort` with high cost (sorting lots of data)\n- Big difference between estimated and actual rows\n\n**Common fixes:**\n\n**1. Add indexes:**\n```sql\n-- For WHERE clauses\nCREATE INDEX idx_users_email ON users(email);\n\n-- For JOINs\nCREATE INDEX idx_orders_user ON orders(user_id);\n\n-- Composite for multiple columns\nCREATE INDEX idx_orders_user_date ON orders(user_id, created_at);\n```\n\n**2. Fix N+1 queries:**\n```python\n# Bad - 1 query + N queries\nfor user in users:\n    print(user.orders)  # Hits DB each time\n\n# Good - 2 queries total\nusers = User.query.options(joinedload(User.orders)).all()\n```\n\n**3. Add pagination:**\n```sql\n-- Don't fetch all rows\nSELECT * FROM orders LIMIT 20 OFFSET 0;\n```\n\n**4. Select only needed columns:**\n```sql\n-- Bad\nSELECT * FROM users;\n\n-- Better\nSELECT id, name, email FROM users;\n```\n\n**5. Avoid functions on indexed columns:**\n```sql\n-- Bad - can't use index\nWHERE YEAR(created_at) = 2024\n\n-- Good - uses index\nWHERE created_at >= '2024-01-01' AND created_at < '2025-01-01'\n```\n\nShare the query and table structure and I can give specific advice."}]}
{"conversations": [{"from": "human", "value": "Debugging a race condition"}, {"from": "gpt", "value": "Race conditions are the worst bugs - intermittent, hard to reproduce, harder to fix.\n\n**Symptoms:**\n- Works sometimes, fails sometimes\n- Fails under load but not in tests\n- Adding print statements makes it work (timing change)\n- Works in debugger (too slow to race)\n\n**Finding them:**\n\n**1. Identify shared state:**\n- What data do multiple threads/processes access?\n- Is that access synchronized?\n\n**2. Add aggressive logging:**\n```python\nimport threading\nimport time\n\ndef log(msg):\n    print(f\"{time.time():.6f} [{threading.current_thread().name}] {msg}\")\n```\n\n**3. Stress test:**\n- Run the code many times in parallel\n- Use tools like ThreadSanitizer\n- Increase contention artificially\n\n**Common patterns:**\n\n**Check-then-act:**\n```python\n# RACE CONDITION\nif key not in cache:\n    cache[key] = compute_value()  # Another thread might do this too\n\n# Fixed\nwith lock:\n    if key not in cache:\n        cache[key] = compute_value()\n```\n\n**Read-modify-write:**\n```python\n# RACE CONDITION\ncounter = counter + 1  # Not atomic!\n\n# Fixed\nwith lock:\n    counter = counter + 1\n# Or use atomics\nfrom threading import Lock\n```\n\n**Lazy initialization:**\n```python\n# RACE CONDITION\nif instance is None:\n    instance = create_instance()\n\n# Fixed - double-checked locking\nif instance is None:\n    with lock:\n        if instance is None:\n            instance = create_instance()\n```\n\n**Tools:**\n- ThreadSanitizer (C/C++, Go)\n- Helgrind (Valgrind)\n- Go race detector: `go run -race`\n- Python: threading module + careful design\n\nDescribe the behavior and I can help identify the race."}]}
{"conversations": [{"from": "human", "value": "Getting CORS errors"}, {"from": "gpt", "value": "CORS errors mean the browser is blocking a cross-origin request. The SERVER needs to fix this, not the client.\n\n**The error:**\n```\nAccess to fetch at 'https://api.example.com' from origin 'https://myapp.com' \nhas been blocked by CORS policy\n```\n\n**What's happening:**\n- Browser sends preflight OPTIONS request\n- Server doesn't respond with correct CORS headers\n- Browser blocks the actual request\n\n**Server-side fixes:**\n\n**Express (Node.js):**\n```javascript\nconst cors = require('cors');\n\n// Allow all (development only!)\napp.use(cors());\n\n// Production - specific origins\napp.use(cors({\n  origin: ['https://myapp.com', 'https://www.myapp.com'],\n  methods: ['GET', 'POST', 'PUT', 'DELETE'],\n  credentials: true  // If using cookies\n}));\n```\n\n**Flask (Python):**\n```python\nfrom flask_cors import CORS\n\nCORS(app, origins=['https://myapp.com'])\n```\n\n**Django:**\n```python\n# settings.py\nCORS_ALLOWED_ORIGINS = [\n    'https://myapp.com',\n]\n```\n\n**Nginx:**\n```nginx\nlocation /api/ {\n    add_header 'Access-Control-Allow-Origin' 'https://myapp.com';\n    add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS';\n    add_header 'Access-Control-Allow-Headers' 'Content-Type, Authorization';\n    \n    if ($request_method = 'OPTIONS') {\n        return 204;\n    }\n}\n```\n\n**Common mistakes:**\n- Wildcard `*` doesn't work with credentials\n- Forgetting to handle OPTIONS preflight\n- Setting headers on wrong endpoint\n- Nginx stripping headers set by app\n\n**Dev workarounds (not for production):**\n- Use a proxy (Vite, webpack-dev-server)\n- Browser extension (disable CORS - dangerous!)\n\nWhat's your backend setup?"}]}
{"conversations": [{"from": "human", "value": "My app works but something feels wrong"}, {"from": "gpt", "value": "Trust that instinct. \"Works but feels wrong\" often means technical debt accumulating.\n\n**Red flags to check:**\n\n**Code smells:**\n- Functions longer than a screen\n- Deep nesting (if inside if inside if)\n- Duplicate code in multiple places\n- Comments explaining WHAT not WHY\n- Variable names like `data2` or `temp`\n\n**Architecture smells:**\n- Everything depends on everything\n- One file is 2000 lines\n- Changes require modifying many files\n- \"Don't touch that file, nobody knows how it works\"\n- Tests are hard to write\n\n**Performance smells:**\n- It's slow but you're not sure where\n- Database queries you've never looked at\n- No caching anywhere\n- Memory usage is high\n\n**Operational smells:**\n- Deploying is scary\n- Logs are useless or nonexistent\n- You'd struggle to debug a production issue\n- No monitoring/alerting\n\n**The questions:**\n- What would break if X changes?\n- How long would it take a new person to understand?\n- What are you afraid to touch?\n- What do you keep meaning to fix?\n\n**Addressing it:**\n1. Name the specific concern\n2. Assess the risk (how bad if it fails?)\n3. Prioritize against features\n4. Refactor incrementally, not big-bang\n\nWhat specifically feels off? Let's dig into it."}]}
