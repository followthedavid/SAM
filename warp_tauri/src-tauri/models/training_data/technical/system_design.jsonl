{"conversations": [{"from": "human", "value": "Design a URL shortener"}, {"from": "gpt", "value": "**Requirements clarification:**\n- Write-heavy or read-heavy? (Read - each URL read millions of times)\n- Custom URLs allowed?\n- Analytics needed?\n- Expiration?\n\n**Scale estimates:**\n- 100M URLs created/month\n- 10:1 read:write ratio = 1B redirects/month\n- 5 years = 6B URLs\n- Assuming 500 bytes per record = 3TB storage\n\n**Core design:**\n\n```\n┌─────────┐     ┌──────────────┐     ┌─────────┐\n│ Client  │────▶│ Load Balancer │────▶│ Web Tier │\n└─────────┘     └──────────────┘     └────┬────┘\n                                          │\n                    ┌─────────────────────┼─────────────────────┐\n                    ▼                     ▼                     ▼\n              ┌──────────┐         ┌──────────┐         ┌──────────┐\n              │  Cache   │         │ Database │         │ Counter  │\n              │ (Redis)  │         │ (NoSQL)  │         │ Service  │\n              └──────────┘         └──────────┘         └──────────┘\n```\n\n**Short URL generation:**\nBase62 encoding (a-zA-Z0-9) gives 62^7 = 3.5 trillion combinations for 7 characters.\n\nOption 1: Counter + Base62 (simple, predictable)\nOption 2: MD5 hash + first 7 chars (collisions possible)\nOption 3: Pre-generated keys in key DB (scalable)\n\n**Database schema:**\n```sql\nCREATE TABLE urls (\n    short_key VARCHAR(7) PRIMARY KEY,\n    original_url TEXT NOT NULL,\n    created_at TIMESTAMP,\n    expires_at TIMESTAMP,\n    user_id BIGINT\n);\n```\n\n**Read path:**\n1. Check Redis cache\n2. If miss, query DB\n3. Populate cache\n4. Return 301/302 redirect\n\n**Write path:**\n1. Generate short key\n2. Check for collision\n3. Write to DB\n4. Return short URL\n\nWant to dive deeper into any component?"}]}
{"conversations": [{"from": "human", "value": "How would you design Twitter?"}, {"from": "gpt", "value": "Twitter is a deceptively complex system. Let's break it down.\n\n**Core features:**\n- Post tweets (140/280 chars)\n- Follow users\n- Timeline (home feed)\n- Notifications\n- Search\n\n**Scale:**\n- 300M users, 500M tweets/day\n- Read-heavy (100:1 ratio)\n- Celebrity accounts = millions of followers\n\n**The hard problem: Fan-out**\n\n**Push model (Fan-out on write):**\nWhen user tweets, push to all followers' timelines.\n- Pro: Fast reads\n- Con: Expensive writes for celebrities (millions of pushes)\n\n**Pull model (Fan-out on read):**\nWhen user reads timeline, pull from all followees.\n- Pro: Cheap writes\n- Con: Slow reads (many queries)\n\n**Hybrid (Twitter's approach):**\n- Regular users: Push model\n- Celebrities: Pull model at read time\n\n**Architecture:**\n```\n┌────────────────────────────────────────────────┐\n│                  API Gateway                    │\n└─────────────────────┬──────────────────────────┘\n                      │\n    ┌─────────────────┼─────────────────┐\n    ▼                 ▼                 ▼\n┌────────┐      ┌──────────┐      ┌──────────┐\n│ Tweet  │      │ Timeline │      │ Search   │\n│Service │      │ Service  │      │ Service  │\n└───┬────┘      └────┬─────┘      └────┬─────┘\n    │                │                 │\n    ▼                ▼                 ▼\n┌────────┐      ┌──────────┐      ┌──────────┐\n│Tweet DB│      │Redis/Cache│      │Elastic   │\n│(Sharded)│     │(Timelines)│      │search    │\n└────────┘      └──────────┘      └──────────┘\n```\n\n**Data models:**\n```\nTweets: id, user_id, content, timestamp, media_ids\nUsers: id, username, profile\nFollows: follower_id, followee_id\nTimeline: user_id -> [tweet_ids] (Redis sorted set)\n```\n\nWant to go deeper on any subsystem?"}]}
{"conversations": [{"from": "human", "value": "Design a distributed cache"}, {"from": "gpt", "value": "**Requirements:**\n- Fast reads/writes (sub-millisecond)\n- High availability\n- Horizontal scaling\n- Consistent hashing for distribution\n\n**Architecture:**\n\n```\n┌─────────────────────────────────────────────┐\n│              Client Library                  │\n│   (Consistent hashing, connection pooling)   │\n└──────────────────┬──────────────────────────┘\n                   │\n         ┌─────────┼─────────┐\n         ▼         ▼         ▼\n    ┌─────────┐┌─────────┐┌─────────┐\n    │ Node 1  ││ Node 2  ││ Node 3  │\n    │ (0-33%) ││(34-66%) ││(67-100%)│\n    └─────────┘└─────────┘└─────────┘\n```\n\n**Consistent Hashing:**\n```python\nimport hashlib\nfrom bisect import bisect_right\n\nclass ConsistentHash:\n    def __init__(self, nodes, replicas=150):\n        self.replicas = replicas\n        self.ring = []\n        self.node_map = {}\n        \n        for node in nodes:\n            self.add_node(node)\n    \n    def _hash(self, key):\n        return int(hashlib.md5(key.encode()).hexdigest(), 16)\n    \n    def add_node(self, node):\n        for i in range(self.replicas):\n            virtual_key = f\"{node}:{i}\"\n            h = self._hash(virtual_key)\n            self.ring.append(h)\n            self.node_map[h] = node\n        self.ring.sort()\n    \n    def get_node(self, key):\n        h = self._hash(key)\n        idx = bisect_right(self.ring, h) % len(self.ring)\n        return self.node_map[self.ring[idx]]\n```\n\n**Cache eviction policies:**\n- LRU (Least Recently Used) - good general purpose\n- LFU (Least Frequently Used) - frequency-biased\n- TTL-based - time-based expiration\n\n**Replication for HA:**\n- Primary-replica with async replication\n- Trade-off: consistency vs. availability\n\n**Cache invalidation strategies:**\n1. Write-through: Update cache on write\n2. Write-behind: Async cache update\n3. Cache-aside: Application manages cache\n\nWhich aspect interests you most?"}]}
{"conversations": [{"from": "human", "value": "Design a rate limiter"}, {"from": "gpt", "value": "**Algorithms:**\n\n**1. Token Bucket (most common):**\n- Bucket holds N tokens\n- Requests take 1 token\n- Tokens refill at R/second\n- Allows bursts up to bucket size\n\n```python\nclass TokenBucket:\n    def __init__(self, capacity, refill_rate):\n        self.capacity = capacity\n        self.tokens = capacity\n        self.refill_rate = refill_rate\n        self.last_refill = time.time()\n    \n    def allow(self):\n        now = time.time()\n        # Refill tokens\n        elapsed = now - self.last_refill\n        self.tokens = min(self.capacity, \n                         self.tokens + elapsed * self.refill_rate)\n        self.last_refill = now\n        \n        if self.tokens >= 1:\n            self.tokens -= 1\n            return True\n        return False\n```\n\n**2. Sliding Window:**\n- Track requests in rolling time window\n- More precise than fixed windows\n\n**3. Fixed Window Counter:**\n- Count requests per time window\n- Simple but allows burst at window boundary\n\n**Distributed rate limiting:**\n\n```\n┌─────────┐     ┌──────────────┐     ┌─────────────┐\n│ Request │────▶│ Rate Limiter │────▶│   Service   │\n└─────────┘     └──────┬───────┘     └─────────────┘\n                       │\n                       ▼\n                  ┌─────────┐\n                  │  Redis  │\n                  │ (shared)│\n                  └─────────┘\n```\n\n**Redis implementation:**\n```lua\n-- Sliding window log in Redis\nlocal key = KEYS[1]\nlocal window = tonumber(ARGV[1])\nlocal limit = tonumber(ARGV[2])\nlocal now = tonumber(ARGV[3])\n\n-- Remove old entries\nredis.call('ZREMRANGEBYSCORE', key, 0, now - window)\n\n-- Count current\nlocal count = redis.call('ZCARD', key)\n\nif count < limit then\n    redis.call('ZADD', key, now, now)\n    redis.call('EXPIRE', key, window)\n    return 1\nend\nreturn 0\n```\n\n**Headers to return:**\n- X-RateLimit-Limit: Total allowed\n- X-RateLimit-Remaining: Left in window\n- X-RateLimit-Reset: When window resets\n- Retry-After: Seconds until retry (on 429)\n\nWhat's your use case?"}]}
{"conversations": [{"from": "human", "value": "Design a notification system"}, {"from": "gpt", "value": "**Requirements:**\n- Multiple channels: push, email, SMS, in-app\n- High volume (millions/day)\n- Template management\n- User preferences\n- Delivery tracking\n\n**Architecture:**\n\n```\n┌─────────────┐\n│  Services   │──────┐\n└─────────────┘      │\n                     ▼\n              ┌──────────────┐     ┌─────────────┐\n              │ Notification │────▶│   Message   │\n              │   Service    │     │   Queue     │\n              └──────────────┘     └──────┬──────┘\n                                          │\n                    ┌─────────────────────┼─────────────────────┐\n                    ▼                     ▼                     ▼\n              ┌──────────┐         ┌──────────┐         ┌──────────┐\n              │  Push    │         │  Email   │         │   SMS    │\n              │ Worker   │         │ Worker   │         │ Worker   │\n              └────┬─────┘         └────┬─────┘         └────┬─────┘\n                   │                    │                    │\n                   ▼                    ▼                    ▼\n              ┌──────────┐         ┌──────────┐         ┌──────────┐\n              │ APNs/FCM │         │ SendGrid │         │ Twilio   │\n              └──────────┘         └──────────┘         └──────────┘\n```\n\n**Data models:**\n```sql\n-- Templates\nCREATE TABLE templates (\n    id UUID PRIMARY KEY,\n    name VARCHAR(100),\n    channel VARCHAR(20),\n    subject_template TEXT,\n    body_template TEXT\n);\n\n-- User preferences\nCREATE TABLE notification_preferences (\n    user_id BIGINT,\n    channel VARCHAR(20),\n    notification_type VARCHAR(50),\n    enabled BOOLEAN,\n    PRIMARY KEY (user_id, channel, notification_type)\n);\n\n-- Notification log\nCREATE TABLE notifications (\n    id UUID PRIMARY KEY,\n    user_id BIGINT,\n    channel VARCHAR(20),\n    status VARCHAR(20),\n    sent_at TIMESTAMP,\n    delivered_at TIMESTAMP,\n    error TEXT\n);\n```\n\n**Flow:**\n1. Service calls notification API\n2. Check user preferences\n3. Render template with data\n4. Enqueue to appropriate channel queue\n5. Worker processes and sends\n6. Track delivery/failure\n\n**Reliability:**\n- Idempotency keys to prevent duplicates\n- Retry with exponential backoff\n- Dead letter queue for failures\n- Rate limiting per user/channel\n\nWhat's your scale?"}]}
{"conversations": [{"from": "human", "value": "How do microservices communicate?"}, {"from": "gpt", "value": "**Synchronous (Request/Response):**\n\n**REST:**\n- HTTP/JSON\n- Simple, well-understood\n- Tight coupling to availability\n```\nGET /users/123\n```\n\n**gRPC:**\n- HTTP/2, Protocol Buffers\n- Faster, type-safe\n- Better for internal services\n```protobuf\nservice UserService {\n  rpc GetUser(UserRequest) returns (User);\n}\n```\n\n**Asynchronous (Event-Driven):**\n\n**Message Queues (RabbitMQ, SQS):**\n- Point-to-point\n- Work distribution\n```\nProducer → Queue → Consumer\n```\n\n**Event Streaming (Kafka):**\n- Pub/sub\n- Event sourcing\n- Replay capability\n```\nProducer → Topic → Consumer Group\n```\n\n**Comparison:**\n\n| Pattern | Coupling | Latency | Reliability |\n|---------|----------|---------|-------------|\n| REST | High | Low | Caller handles |\n| gRPC | High | Lower | Caller handles |\n| Queue | Low | Higher | Queue handles |\n| Events | Lowest | Variable | Infrastructure |\n\n**Service Discovery:**\n```\n┌─────────┐     ┌───────────────┐     ┌─────────┐\n│Service A│────▶│Service Registry│◀────│Service B│\n└─────────┘     │  (Consul/K8s)  │     └─────────┘\n                └───────────────┘\n```\n\n**Best practices:**\n- Use async for operations that don't need immediate response\n- Circuit breakers for sync calls\n- Idempotency everywhere\n- Contract testing between services\n\nWhat's your architecture looking like?"}]}
{"conversations": [{"from": "human", "value": "How do you handle database scaling?"}, {"from": "gpt", "value": "**Vertical scaling (scale up):**\n- Bigger machine\n- Simple but limited\n- Good first step\n\n**Horizontal scaling (scale out):**\n\n**1. Read Replicas:**\n```\n┌────────┐     ┌──────────┐\n│ Writes │────▶│  Primary │\n└────────┘     └────┬─────┘\n                    │ Replication\n         ┌──────────┼──────────┐\n         ▼          ▼          ▼\n    ┌─────────┐┌─────────┐┌─────────┐\n    │Replica 1││Replica 2││Replica 3│\n    └─────────┘└─────────┘└─────────┘\n         ▲          ▲          ▲\n         └──────────┼──────────┘\n                    │\n              ┌─────────┐\n              │  Reads  │\n              └─────────┘\n```\n\n**2. Sharding (partitioning):**\n\nStrategies:\n- **Hash-based**: `shard = hash(user_id) % num_shards`\n- **Range-based**: Users A-M on shard 1, N-Z on shard 2\n- **Directory-based**: Lookup table maps key to shard\n\n```\n┌─────────────────────────────────┐\n│         Router/Proxy            │\n└───────────────┬─────────────────┘\n                │\n    ┌───────────┼───────────┐\n    ▼           ▼           ▼\n┌─────────┐┌─────────┐┌─────────┐\n│Shard 0  ││Shard 1  ││Shard 2  │\n│(0-33%)  ││(34-66%) ││(67-100%)│\n└─────────┘└─────────┘└─────────┘\n```\n\n**3. Caching layer:**\n```\nApp → Cache (Redis) → Database\n```\n\n**Sharding challenges:**\n- Cross-shard queries (expensive)\n- Rebalancing when adding shards\n- Joins across shards\n- Maintaining referential integrity\n\n**When to shard:**\n- Only when you MUST\n- Exhaust vertical scaling first\n- Exhaust read replicas first\n- Consider if you can avoid it with better data modeling\n\nWhat's your current scale looking like?"}]}
{"conversations": [{"from": "human", "value": "Design a chat application"}, {"from": "gpt", "value": "**Requirements:**\n- Real-time messaging\n- 1:1 and group chats\n- Online presence\n- Read receipts\n- Message history\n- File sharing\n\n**Architecture:**\n\n```\n┌─────────┐     ┌──────────────┐     ┌─────────────────┐\n│ Client  │◀───▶│  WebSocket   │◀───▶│  Chat Service   │\n│  (App)  │     │   Gateway    │     │                 │\n└─────────┘     └──────────────┘     └────────┬────────┘\n                                              │\n                    ┌─────────────────────────┼─────────────────────────┐\n                    ▼                         ▼                         ▼\n              ┌──────────┐             ┌──────────┐             ┌──────────┐\n              │  Redis   │             │ Message  │             │  Media   │\n              │(Presence │             │   DB     │             │  Store   │\n              │ Pub/Sub) │             │(Cassandra)│            │  (S3)    │\n              └──────────┘             └──────────┘             └──────────┘\n```\n\n**WebSocket connection:**\n```javascript\n// Client\nconst ws = new WebSocket('wss://chat.example.com');\n\nws.onmessage = (event) => {\n  const msg = JSON.parse(event.data);\n  handleMessage(msg);\n};\n\nfunction sendMessage(chatId, content) {\n  ws.send(JSON.stringify({\n    type: 'message',\n    chatId,\n    content,\n    timestamp: Date.now()\n  }));\n}\n```\n\n**Message delivery:**\n1. Client sends message via WebSocket\n2. Server persists to DB\n3. Server publishes to Redis channel\n4. All connected servers subscribe to relevant channels\n5. Each server pushes to connected clients\n\n**Data model (Cassandra):**\n```sql\nCREATE TABLE messages (\n    chat_id UUID,\n    message_id TIMEUUID,\n    sender_id BIGINT,\n    content TEXT,\n    created_at TIMESTAMP,\n    PRIMARY KEY (chat_id, message_id)\n) WITH CLUSTERING ORDER BY (message_id DESC);\n```\n\n**Presence:**\n- Heartbeat every 30s\n- Redis SET with TTL\n- Pub/sub for status changes\n\n**Scaling WebSockets:**\n- Sticky sessions to maintain connections\n- Redis pub/sub for cross-server messaging\n- Connection limits per server\n\nWhat scale are you targeting?"}]}
{"conversations": [{"from": "human", "value": "What are the trade-offs of SQL vs NoSQL?"}, {"from": "gpt", "value": "**SQL (Relational):**\n\nPros:\n- ACID transactions\n- Complex queries, joins\n- Data integrity (foreign keys)\n- Mature, well-understood\n- Great for structured data with relationships\n\nCons:\n- Harder to scale horizontally\n- Schema changes can be painful\n- Not ideal for hierarchical/nested data\n\nBest for: Financial systems, e-commerce, CMS, anything needing transactions and relationships.\n\n**NoSQL categories:**\n\n**Document (MongoDB, CouchDB):**\n- Flexible schema\n- Nested objects natural\n- Good for content, catalogs, user profiles\n\n**Key-Value (Redis, DynamoDB):**\n- Fastest reads/writes\n- Simple data model\n- Good for caching, sessions, real-time data\n\n**Column-Family (Cassandra, HBase):**\n- Write-heavy workloads\n- Time-series data\n- Scales massively\n\n**Graph (Neo4j):**\n- Relationship-heavy queries\n- Social networks, recommendations\n- Fraud detection\n\n**Decision framework:**\n\n| Factor | SQL | NoSQL |\n|--------|-----|-------|\n| Transactions | Strong | Varies |\n| Schema | Fixed | Flexible |\n| Scale | Vertical first | Horizontal |\n| Queries | Complex joins | Simple lookups |\n| Consistency | Strong | Eventually |\n\n**The reality:**\n- Most systems use both\n- SQL for core business data\n- NoSQL for specific use cases (cache, logs, sessions)\n- Start with SQL unless you have specific NoSQL requirements\n\nWhat's your use case?"}]}
