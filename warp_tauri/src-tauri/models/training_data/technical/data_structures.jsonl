{"conversations": [{"from": "human", "value": "Explain hash tables"}, {"from": "gpt", "value": "**Hash tables** map keys to values in O(1) average time.\n\n**How it works:**\n1. Key goes through hash function â†’ integer index\n2. Index determines bucket in array\n3. Value stored at that bucket\n\n**Hash function:**\n```python\ndef simple_hash(key, size):\n    return sum(ord(c) for c in str(key)) % size\n```\n\n**Collision handling:**\n\n**Chaining:** Each bucket is a linked list\n```python\nclass HashTable:\n    def __init__(self, size=1000):\n        self.buckets = [[] for _ in range(size)]\n        self.size = size\n    \n    def put(self, key, value):\n        bucket = self.buckets[hash(key) % self.size]\n        for i, (k, v) in enumerate(bucket):\n            if k == key:\n                bucket[i] = (key, value)\n                return\n        bucket.append((key, value))\n    \n    def get(self, key):\n        bucket = self.buckets[hash(key) % self.size]\n        for k, v in bucket:\n            if k == key:\n                return v\n        raise KeyError(key)\n```\n\n**Open addressing:** Find next empty slot\n- Linear probing: check index+1, index+2...\n- Quadratic probing: check index+1Â², index+2Â²...\n\n**Time complexity:**\n- Average: O(1) insert, lookup, delete\n- Worst case: O(n) when many collisions\n\n**Load factor:** items/buckets. When too high, resize.\n\n**Real-world:** Python dict, JavaScript objects, Java HashMap"}]}
{"conversations": [{"from": "human", "value": "Explain trees and when to use them"}, {"from": "gpt", "value": "**Binary Tree:**\n```python\nclass Node:\n    def __init__(self, val):\n        self.val = val\n        self.left = None\n        self.right = None\n```\n\n**Binary Search Tree (BST):**\n- Left subtree < node < right subtree\n- O(log n) search/insert/delete when balanced\n- Worst case O(n) when degenerate (looks like linked list)\n\n```python\nclass BST:\n    def insert(self, root, val):\n        if not root:\n            return Node(val)\n        if val < root.val:\n            root.left = self.insert(root.left, val)\n        else:\n            root.right = self.insert(root.right, val)\n        return root\n    \n    def search(self, root, val):\n        if not root or root.val == val:\n            return root\n        if val < root.val:\n            return self.search(root.left, val)\n        return self.search(root.right, val)\n```\n\n**Self-balancing trees:**\n- AVL: Strict balance, faster lookups\n- Red-Black: Less strict, faster insertions\n- B-Tree: Many children, optimized for disk\n\n**Use cases:**\n- BST: Ordered data with fast operations\n- Heap: Priority queues, scheduling\n- Trie: String prefix operations, autocomplete\n- B-Tree: Databases, file systems\n- Segment tree: Range queries\n\n**Traversals:**\n```python\ndef inorder(node):  # left, root, right - sorted order for BST\n    if node:\n        inorder(node.left)\n        print(node.val)\n        inorder(node.right)\n\ndef preorder(node):  # root, left, right - copy tree\ndef postorder(node):  # left, right, root - delete tree\n```\n\nWhich specific tree are you interested in?"}]}
{"conversations": [{"from": "human", "value": "Explain graphs"}, {"from": "gpt", "value": "**Graph basics:**\n- Vertices (nodes) + edges (connections)\n- Directed or undirected\n- Weighted or unweighted\n- Cyclic or acyclic\n\n**Representations:**\n\n**Adjacency List** (most common):\n```python\ngraph = {\n    'A': ['B', 'C'],\n    'B': ['A', 'D'],\n    'C': ['A', 'D'],\n    'D': ['B', 'C']\n}\n```\n- Space: O(V + E)\n- Good for sparse graphs\n\n**Adjacency Matrix:**\n```python\n#     A  B  C  D\n# A [[0, 1, 1, 0],\n# B  [1, 0, 0, 1],\n# C  [1, 0, 0, 1],\n# D  [0, 1, 1, 0]]\n```\n- Space: O(VÂ²)\n- Good for dense graphs, fast edge lookup\n\n**Traversals:**\n\n**BFS** (level by level, use queue):\n```python\nfrom collections import deque\n\ndef bfs(graph, start):\n    visited = set([start])\n    queue = deque([start])\n    while queue:\n        node = queue.popleft()\n        print(node)\n        for neighbor in graph[node]:\n            if neighbor not in visited:\n                visited.add(neighbor)\n                queue.append(neighbor)\n```\n- Shortest path in unweighted graphs\n\n**DFS** (go deep, use stack/recursion):\n```python\ndef dfs(graph, node, visited=None):\n    if visited is None:\n        visited = set()\n    visited.add(node)\n    print(node)\n    for neighbor in graph[node]:\n        if neighbor not in visited:\n            dfs(graph, neighbor, visited)\n```\n- Cycle detection, topological sort\n\n**Algorithms:**\n- Dijkstra: Shortest path (weighted)\n- Bellman-Ford: Negative weights\n- Floyd-Warshall: All pairs shortest\n- Kruskal/Prim: Minimum spanning tree\n\nWhat's your use case?"}]}
{"conversations": [{"from": "human", "value": "When should I use which data structure?"}, {"from": "gpt", "value": "**Quick reference:**\n\n**Need fast lookup by key?**\nâ†’ Hash table (dict/map)\n\n**Need ordered data?**\nâ†’ Array (sorted) or BST\n\n**Need fast insert/delete at ends?**\nâ†’ Deque or linked list\n\n**Need fast insert/delete anywhere?**\nâ†’ Linked list\n\n**Need to track min/max efficiently?**\nâ†’ Heap\n\n**Need FIFO (queue)?**\nâ†’ Queue (deque)\n\n**Need LIFO (stack)?**\nâ†’ Stack (list/array)\n\n**Need range queries?**\nâ†’ Segment tree or Fenwick tree\n\n**Need prefix matching?**\nâ†’ Trie\n\n**Need relationships/connections?**\nâ†’ Graph\n\n**Detailed breakdown:**\n\n| Structure | Lookup | Insert | Delete | Use case |\n|-----------|--------|--------|--------|----------|\n| Array | O(1) index, O(n) value | O(n) | O(n) | Fixed size, random access |\n| Linked List | O(n) | O(1)* | O(1)* | Frequent insert/delete |\n| Hash Table | O(1)** | O(1)** | O(1)** | Key-value storage |\n| BST | O(log n)** | O(log n)** | O(log n)** | Ordered operations |\n| Heap | O(1) min/max | O(log n) | O(log n) | Priority queue |\n| Trie | O(m) | O(m) | O(m) | String prefix ops |\n\n* With reference to node\n** Average case\n\n**Questions to ask:**\n1. What operations are most frequent?\n2. What's the expected data size?\n3. Do I need ordering?\n4. What's the access pattern?"}]}
{"conversations": [{"from": "human", "value": "Explain dynamic programming"}, {"from": "gpt", "value": "**Core idea:** Solve complex problems by breaking into overlapping subproblems, storing results to avoid recomputation.\n\n**When to use DP:**\n1. Optimal substructure (optimal solution contains optimal sub-solutions)\n2. Overlapping subproblems (same subproblems solved multiple times)\n\n**Two approaches:**\n\n**Top-down (memoization):**\n```python\ndef fib(n, memo={}):\n    if n in memo:\n        return memo[n]\n    if n <= 1:\n        return n\n    memo[n] = fib(n-1, memo) + fib(n-2, memo)\n    return memo[n]\n```\n\n**Bottom-up (tabulation):**\n```python\ndef fib(n):\n    if n <= 1:\n        return n\n    dp = [0] * (n + 1)\n    dp[1] = 1\n    for i in range(2, n + 1):\n        dp[i] = dp[i-1] + dp[i-2]\n    return dp[n]\n```\n\n**Space optimized:**\n```python\ndef fib(n):\n    if n <= 1:\n        return n\n    prev, curr = 0, 1\n    for _ in range(2, n + 1):\n        prev, curr = curr, prev + curr\n    return curr\n```\n\n**Classic DP problems:**\n\n**Coin change:**\n```python\ndef coin_change(coins, amount):\n    dp = [float('inf')] * (amount + 1)\n    dp[0] = 0\n    for coin in coins:\n        for x in range(coin, amount + 1):\n            dp[x] = min(dp[x], dp[x - coin] + 1)\n    return dp[amount] if dp[amount] != float('inf') else -1\n```\n\n**Longest common subsequence:**\n```python\ndef lcs(s1, s2):\n    m, n = len(s1), len(s2)\n    dp = [[0] * (n + 1) for _ in range(m + 1)]\n    for i in range(1, m + 1):\n        for j in range(1, n + 1):\n            if s1[i-1] == s2[j-1]:\n                dp[i][j] = dp[i-1][j-1] + 1\n            else:\n                dp[i][j] = max(dp[i-1][j], dp[i][j-1])\n    return dp[m][n]\n```\n\n**Pattern recognition:**\n1. Can I express solution in terms of smaller inputs?\n2. What are the base cases?\n3. What's the recurrence relation?\n4. What's the state? (parameters that change)\n\nWhich DP problem are you working on?"}]}
{"conversations": [{"from": "human", "value": "Explain Big O notation"}, {"from": "gpt", "value": "**Big O** describes how an algorithm's time/space grows with input size.\n\n**Common complexities (best to worst):**\n\n```\nO(1)        Constant     Hash lookup, array index\nO(log n)    Logarithmic  Binary search\nO(n)        Linear       Simple loop\nO(n log n)  Linearithmic Good sorting algorithms\nO(nÂ²)       Quadratic    Nested loops\nO(2â¿)       Exponential  Recursive subsets\nO(n!)       Factorial    Permutations\n```\n\n**How to analyze:**\n\n```python\n# O(1) - constant\ndef get_first(arr):\n    return arr[0]\n\n# O(n) - linear\ndef find(arr, target):\n    for x in arr:        # runs n times\n        if x == target:\n            return True\n    return False\n\n# O(nÂ²) - quadratic\ndef has_duplicates(arr):\n    for i in range(len(arr)):      # n times\n        for j in range(len(arr)):  # n times each\n            if i != j and arr[i] == arr[j]:\n                return True\n    return False\n\n# O(log n) - logarithmic\ndef binary_search(arr, target):\n    lo, hi = 0, len(arr) - 1\n    while lo <= hi:\n        mid = (lo + hi) // 2\n        if arr[mid] == target:\n            return mid\n        elif arr[mid] < target:\n            lo = mid + 1    # halves search space\n        else:\n            hi = mid - 1\n    return -1\n```\n\n**Rules:**\n1. Drop constants: O(2n) â†’ O(n)\n2. Drop lower terms: O(nÂ² + n) â†’ O(nÂ²)\n3. Worst case matters (usually)\n4. Sequential = add: O(A) + O(B)\n5. Nested = multiply: O(A) * O(B)\n\n**Space complexity:**\n- Same notation for memory usage\n- Consider: variables, data structures, recursion stack\n\n**Practical comparison (n = 1,000,000):**\n```\nO(1):       1 operation\nO(log n):   20 operations\nO(n):       1,000,000 operations\nO(n log n): 20,000,000 operations\nO(nÂ²):      1,000,000,000,000 operations (ðŸ’€)\n```\n\nWhat algorithm are you trying to analyze?"}]}
{"conversations": [{"from": "human", "value": "How do I implement a queue?"}, {"from": "gpt", "value": "**FIFO (First In, First Out)**\n\n**Simple using deque (recommended):**\n```python\nfrom collections import deque\n\nq = deque()\nq.append(1)      # enqueue\nq.append(2)\nfirst = q.popleft()  # dequeue - O(1)\n```\n\n**Using list (not recommended - O(n) pop):**\n```python\nq = []\nq.append(1)\nfirst = q.pop(0)  # O(n) - shifts all elements!\n```\n\n**Custom implementation:**\n```python\nclass Queue:\n    def __init__(self):\n        self.items = deque()\n    \n    def enqueue(self, item):\n        self.items.append(item)\n    \n    def dequeue(self):\n        if self.is_empty():\n            raise IndexError(\"Queue is empty\")\n        return self.items.popleft()\n    \n    def peek(self):\n        if self.is_empty():\n            raise IndexError(\"Queue is empty\")\n        return self.items[0]\n    \n    def is_empty(self):\n        return len(self.items) == 0\n    \n    def __len__(self):\n        return len(self.items)\n```\n\n**Circular queue (fixed size):**\n```python\nclass CircularQueue:\n    def __init__(self, capacity):\n        self.capacity = capacity\n        self.queue = [None] * capacity\n        self.head = 0\n        self.tail = 0\n        self.size = 0\n    \n    def enqueue(self, item):\n        if self.size == self.capacity:\n            raise OverflowError(\"Queue is full\")\n        self.queue[self.tail] = item\n        self.tail = (self.tail + 1) % self.capacity\n        self.size += 1\n    \n    def dequeue(self):\n        if self.size == 0:\n            raise IndexError(\"Queue is empty\")\n        item = self.queue[self.head]\n        self.head = (self.head + 1) % self.capacity\n        self.size -= 1\n        return item\n```\n\n**Priority queue:**\n```python\nimport heapq\n\npq = []\nheapq.heappush(pq, (priority, item))\nlowest = heapq.heappop(pq)\n```\n\nWhat's your use case?"}]}
{"conversations": [{"from": "human", "value": "How do I implement a stack?"}, {"from": "gpt", "value": "**LIFO (Last In, First Out)**\n\n**Simple using list (recommended for Python):**\n```python\nstack = []\nstack.append(1)   # push\nstack.append(2)\nstack.append(3)\ntop = stack.pop() # pop - returns 3\npeek = stack[-1]  # peek without remove\n```\n\n**Custom implementation:**\n```python\nclass Stack:\n    def __init__(self):\n        self.items = []\n    \n    def push(self, item):\n        self.items.append(item)\n    \n    def pop(self):\n        if self.is_empty():\n            raise IndexError(\"Stack is empty\")\n        return self.items.pop()\n    \n    def peek(self):\n        if self.is_empty():\n            raise IndexError(\"Stack is empty\")\n        return self.items[-1]\n    \n    def is_empty(self):\n        return len(self.items) == 0\n    \n    def __len__(self):\n        return len(self.items)\n```\n\n**Using linked list:**\n```python\nclass Node:\n    def __init__(self, val):\n        self.val = val\n        self.next = None\n\nclass LinkedStack:\n    def __init__(self):\n        self.top = None\n        self.size = 0\n    \n    def push(self, val):\n        node = Node(val)\n        node.next = self.top\n        self.top = node\n        self.size += 1\n    \n    def pop(self):\n        if not self.top:\n            raise IndexError(\"Stack is empty\")\n        val = self.top.val\n        self.top = self.top.next\n        self.size -= 1\n        return val\n```\n\n**Common use cases:**\n- Function call stack (recursion)\n- Undo/redo functionality\n- Expression evaluation\n- Backtracking algorithms\n- Browser history\n\n**Classic stack problem - valid parentheses:**\n```python\ndef is_valid(s):\n    stack = []\n    pairs = {')': '(', ']': '[', '}': '{'}\n    for char in s:\n        if char in '([{':\n            stack.append(char)\n        elif char in ')]}':\n            if not stack or stack.pop() != pairs[char]:\n                return False\n    return len(stack) == 0\n```"}]}
{"conversations": [{"from": "human", "value": "Explain linked lists"}, {"from": "gpt", "value": "**Node-based structure where each element points to the next.**\n\n**Singly linked list:**\n```python\nclass Node:\n    def __init__(self, val):\n        self.val = val\n        self.next = None\n\nclass LinkedList:\n    def __init__(self):\n        self.head = None\n    \n    def append(self, val):\n        if not self.head:\n            self.head = Node(val)\n            return\n        curr = self.head\n        while curr.next:\n            curr = curr.next\n        curr.next = Node(val)\n    \n    def prepend(self, val):\n        node = Node(val)\n        node.next = self.head\n        self.head = node\n    \n    def delete(self, val):\n        if not self.head:\n            return\n        if self.head.val == val:\n            self.head = self.head.next\n            return\n        curr = self.head\n        while curr.next and curr.next.val != val:\n            curr = curr.next\n        if curr.next:\n            curr.next = curr.next.next\n    \n    def find(self, val):\n        curr = self.head\n        while curr:\n            if curr.val == val:\n                return curr\n            curr = curr.next\n        return None\n```\n\n**Doubly linked list:**\n```python\nclass DNode:\n    def __init__(self, val):\n        self.val = val\n        self.prev = None\n        self.next = None\n```\n- Can traverse both directions\n- More memory per node\n- Easier deletion\n\n**Common operations:**\n- Reverse: O(n)\n- Find middle: fast/slow pointer\n- Detect cycle: Floyd's algorithm\n- Merge two sorted: O(n + m)\n\n**Reverse a linked list:**\n```python\ndef reverse(head):\n    prev = None\n    curr = head\n    while curr:\n        next_temp = curr.next\n        curr.next = prev\n        prev = curr\n        curr = next_temp\n    return prev\n```\n\n**When to use:**\n- Frequent insertions/deletions\n- Don't need random access\n- LRU cache implementation\n\n**When NOT to use:**\n- Need index access\n- Memory is constrained\n- Cache locality matters"}]}
{"conversations": [{"from": "human", "value": "Explain sorting algorithms"}, {"from": "gpt", "value": "**Quick reference:**\n\n| Algorithm | Best | Average | Worst | Space | Stable |\n|-----------|------|---------|-------|-------|--------|\n| Bubble | O(n) | O(nÂ²) | O(nÂ²) | O(1) | Yes |\n| Selection | O(nÂ²) | O(nÂ²) | O(nÂ²) | O(1) | No |\n| Insertion | O(n) | O(nÂ²) | O(nÂ²) | O(1) | Yes |\n| Merge | O(n log n) | O(n log n) | O(n log n) | O(n) | Yes |\n| Quick | O(n log n) | O(n log n) | O(nÂ²) | O(log n) | No |\n| Heap | O(n log n) | O(n log n) | O(n log n) | O(1) | No |\n\n**Quick sort (most common):**\n```python\ndef quicksort(arr):\n    if len(arr) <= 1:\n        return arr\n    pivot = arr[len(arr) // 2]\n    left = [x for x in arr if x < pivot]\n    middle = [x for x in arr if x == pivot]\n    right = [x for x in arr if x > pivot]\n    return quicksort(left) + middle + quicksort(right)\n```\n\n**Merge sort (stable, predictable):**\n```python\ndef mergesort(arr):\n    if len(arr) <= 1:\n        return arr\n    mid = len(arr) // 2\n    left = mergesort(arr[:mid])\n    right = mergesort(arr[mid:])\n    return merge(left, right)\n\ndef merge(left, right):\n    result = []\n    i = j = 0\n    while i < len(left) and j < len(right):\n        if left[i] <= right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n    result.extend(left[i:])\n    result.extend(right[j:])\n    return result\n```\n\n**Heap sort (in-place, not stable):**\n```python\nimport heapq\n\ndef heapsort(arr):\n    heapq.heapify(arr)\n    return [heapq.heappop(arr) for _ in range(len(arr))]\n```\n\n**Practical advice:**\n- Just use `sorted()` or `.sort()` in production\n- Python uses Timsort (hybrid merge+insertion)\n- Know these for interviews, not real code\n\nWhich one do you want to understand deeper?"}]}
