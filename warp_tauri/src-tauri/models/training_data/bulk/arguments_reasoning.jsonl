{"conversations": [{"from": "human", "value": "What's a logical fallacy?"}, {"from": "gpt", "value": "An error in reasoning that makes an argument invalid, regardless of whether the conclusion is true. Common ones: ad hominem (attacking the person not the argument), straw man (misrepresenting someone's argument to make it easier to attack), appeal to authority (this person says so, therefore true), false dichotomy (only two options when more exist), slippery slope (if A then B then C without showing the chain), and confirmation bias (only seeing evidence that supports your view). Knowing fallacies helps you evaluate arguments - including your own."}]}
{"conversations": [{"from": "human", "value": "What's the difference between correlation and causation?"}, {"from": "gpt", "value": "Correlation: two things happen together. Causation: one thing causes the other. Ice cream sales and drowning deaths correlate (both increase in summer) but ice cream doesn't cause drowning - they share a common cause (warm weather). Roosters crow before sunrise, but they don't cause the sun to rise. Establishing causation requires: temporal sequence (cause before effect), mechanism (how would it work?), ruling out confounders, and ideally, controlled experiments. Most reported 'science says X causes Y' is actually correlation being overstated. Be skeptical."}]}
{"conversations": [{"from": "human", "value": "How do I know if something is true?"}, {"from": "gpt", "value": "No perfect method, but good heuristics: Is the source credible and what are their incentives? Is it falsifiable (could you prove it wrong)? Does it align with what other credible sources say? Does the evidence actually support the conclusion? Have experts scrutinized it? Are you believing it because it's true or because you want it to be? Be more skeptical of things that feel emotionally compelling. Multiple independent sources > one source. Scientific consensus > individual studies. Be willing to change your mind with new evidence."}]}
{"conversations": [{"from": "human", "value": "What's steelmanning?"}, {"from": "gpt", "value": "Opposite of strawmanning. Instead of weakening your opponent's argument to attack it, you strengthen it - articulate the best possible version of their position, then respond to that. Benefits: if you can defeat the strongest version of an argument, you've actually proven something. It forces you to understand opposing views genuinely. It builds intellectual honesty and earns respect from those who disagree. Most productive disagreements happen when both sides steelman each other instead of attacking caricatures."}]}
{"conversations": [{"from": "human", "value": "What's Occam's Razor?"}, {"from": "gpt", "value": "The simplest explanation that fits the evidence is usually correct. If your keys are missing, 'I misplaced them' is more likely than 'someone broke in, stole only my keys, and left everything else.' It's not absolute - sometimes reality IS complicated - but it's a good starting heuristic. Simpler theories make fewer assumptions, giving less opportunity to be wrong. Don't add unnecessary complexity. Also applies to decision-making: simple solutions often work better than elaborate ones."}]}
{"conversations": [{"from": "human", "value": "What's confirmation bias?"}, {"from": "gpt", "value": "The tendency to notice, remember, and believe evidence that supports what you already think, while dismissing contradictory evidence. It's universal and mostly unconscious. You seek out news sources that confirm your views. You remember the times your predictions were right. You interpret ambiguous information in your favor. Fighting it requires: actively seeking disconfirming evidence, asking 'what would change my mind?', and exposing yourself to credible opposing views. It's not about being stupid - smart people are often better at rationalizing."}]}
{"conversations": [{"from": "human", "value": "What makes a good argument?"}, {"from": "gpt", "value": "Structure: clear claim, relevant evidence, logical connection between evidence and claim. Quality of evidence: credible sources, representative data, not cherry-picked. Acknowledges limitations and counterarguments honestly. Doesn't rely on fallacies or emotional manipulation. The conclusion follows from the premises. A good argument can be wrong (if premises are false), but the reasoning should be valid. The goal should be discovering truth, not 'winning' - good arguers update their position when presented with better evidence."}]}
{"conversations": [{"from": "human", "value": "What's the burden of proof?"}, {"from": "gpt", "value": "Whoever makes a claim is responsible for supporting it. 'Prove unicorns DON'T exist' is backwards - the person claiming unicorns exist needs to prove they do. You can't prove negatives (usually). Extraordinary claims require extraordinary evidence. In formal contexts: criminal law requires 'beyond reasonable doubt' from prosecution; civil law requires 'preponderance of evidence'; scientific claims require reproducible evidence. The burden shifts if you make a counter-claim. 'I don't believe your claim' is different from 'Your claim is false.'"}]}
{"conversations": [{"from": "human", "value": "What's cognitive dissonance?"}, {"from": "gpt", "value": "Mental discomfort when you hold contradictory beliefs or when your actions contradict your beliefs. Examples: smoking while knowing it's harmful, buying expensive stuff then rationalizing the purchase, supporting a politician while disagreeing with their policies. The discomfort drives you to resolve the contradiction - usually by changing the easier belief, rationalizing behavior, or avoiding information that increases dissonance. It's why it's hard to change minds with facts - facts that create dissonance get rejected before they sink in."}]}
{"conversations": [{"from": "human", "value": "What's the difference between facts and opinions?"}, {"from": "gpt", "value": "Facts are verifiable claims about reality - true or false regardless of who's speaking. 'Water boils at 100Â°C at sea level' is factual. Opinions are subjective judgments - 'chocolate is the best flavor' isn't true or false, just preference. The tricky part: many claims people treat as opinions are actually factual questions with answers ('climate change is happening' is factual, not opinion). And some 'facts' are just widely shared opinions. Don't hide behind 'it's just my opinion' for claims that are actually verifiable."}]}
{"conversations": [{"from": "human", "value": "What's Dunning-Kruger effect?"}, {"from": "gpt", "value": "People with low skill overestimate their ability because they lack the competence to recognize their incompetence. Meanwhile, experts underestimate their ability because they know how much they don't know and assume others know what they know. Result: the least competent are most confident; the most competent second-guess themselves. It explains why beginners often make bold claims while experts hedge. Awareness of Dunning-Kruger should make you humble about your opinions in areas where you're not expert."}]}
{"conversations": [{"from": "human", "value": "What's survivorship bias?"}, {"from": "gpt", "value": "Only seeing successes and drawing wrong conclusions from them. Famous example: WWII plane armor. Initially, they wanted to armor the areas with bullet holes on returning planes. Statistician Abraham Wald pointed out: you're only seeing planes that SURVIVED. The planes that got hit elsewhere crashed. Armor where there are NO holes. Applies to: entrepreneur advice (you hear from successes, not the majority who failed), old buildings (only well-built ones survive), and 'people were healthier back then' (only healthy ones survived to be remembered)."}]}
{"conversations": [{"from": "human", "value": "What's a thought experiment?"}, {"from": "gpt", "value": "An imaginary scenario used to explore the implications of an idea. Trolley problem: would you pull a lever to save five lives if it kills one? It's not about trolleys - it's about deontology vs consequentialism. Schrodinger's cat explores quantum superposition. Einstein's elevator explores general relativity. Twin paradox explores time dilation. Thought experiments isolate the essential question by stripping away irrelevant complexity. They're tools for testing intuitions and understanding where different frameworks lead. The point is the reasoning, not finding 'the answer.'"}]}
{"conversations": [{"from": "human", "value": "How do I change someone's mind?"}, {"from": "gpt", "value": "Usually you can't, especially if their identity is tied to the belief. But if possible: ask questions instead of arguing - let them discover problems in their reasoning. Listen and steelman their position first. Find common ground before addressing disagreement. Don't trigger defensiveness - avoid 'you're wrong.' Provide face-saving ways to update ('that's a reasonable position given what you knew'). Plant seeds without demanding immediate change. Focus on one point, not everything at once. Most mind-changing happens slowly, when people feel safe to reconsider."}]}
{"conversations": [{"from": "human", "value": "What's motivated reasoning?"}, {"from": "gpt", "value": "We like to think we reason first, then conclude. Actually, we often conclude first (based on what we want to be true), then find reasons to support that conclusion. You work backward from 'I want this to be true' to 'here's why it's true.' Related to confirmation bias but more active - you're not just filtering information, you're constructing arguments to reach a predetermined destination. Political beliefs, self-assessments, and emotionally charged topics are especially vulnerable. Awareness helps, but nobody is immune."}]}
{"conversations": [{"from": "human", "value": "What's the appeal to authority fallacy?"}, {"from": "gpt", "value": "Believing something is true because someone important or expert says so, without evaluating the actual evidence. Properly used: expert consensus in their field IS evidence worth weighing. Fallacious uses: expert in unrelated field (physicists commenting on biology), single dissenting expert vs consensus, 'expert' with bias or funding conflicts, famous person endorsing something outside their expertise. Authority can indicate reliability but isn't proof. Ask: are they an expert in THIS field, what do their peers say, what's the actual evidence, could they be biased?"}]}
{"conversations": [{"from": "human", "value": "What's whataboutism?"}, {"from": "gpt", "value": "Deflecting criticism by pointing to something else. 'Your country violates human rights!' 'What about YOUR country's human rights record?' It doesn't address the original claim - it changes the subject. Both things can be bad. It's a rhetorical technique to avoid accountability, not a valid argument. Originated as Soviet propaganda tactic. Prevalent in political discourse. Recognize it and refuse to be deflected: 'We can discuss that separately, but what about the original issue?' Two wrongs don't make a right."}]}
{"conversations": [{"from": "human", "value": "What's the Texas sharpshooter fallacy?"}, {"from": "gpt", "value": "Finding patterns after the fact and treating them as predictions. Named for a shooter who fires randomly at a barn, then paints a target around the tightest cluster of holes. Looks like precision, but the 'target' was chosen after seeing where the bullets went. Applies to: stock pickers who highlight past successes (ignoring failures), health scares finding 'cancer clusters' that are statistical noise, and anyone post-hoc selecting data that supports their conclusion. A pattern isn't meaningful unless it was predicted before seeing the data."}]}
{"conversations": [{"from": "human", "value": "What's the sunk cost fallacy?"}, {"from": "gpt", "value": "Continuing something because you've already invested in it, even when the future costs outweigh future benefits. 'I've watched 2 hours of this terrible movie, I should finish it.' The 2 hours are gone regardless - the only question is whether to spend another hour. Applies to: bad relationships, failing businesses, expensive purchases you regret. Past investment is irrelevant to future decisions. Ask: 'If I hadn't invested anything, would I start now?' If no, stop. 'Throwing good money after bad' captures it. Cut your losses."}]}
{"conversations": [{"from": "human", "value": "What's false equivalence?"}, {"from": "gpt", "value": "Treating two things as equally valid when they're not. Balanced news coverage sometimes creates false equivalence: '50% of scientists say the Earth is warming, 50% disagree' - when actually 97% agree. Both political parties doing bad things doesn't mean they're equally bad - scale and severity matter. Finding flaws in both sides doesn't mean they're the same. Nuance means recognizing legitimate disagreement exists; false equivalence creates the appearance of disagreement where there isn't meaningful debate among credible people. 'Both sides have a point' is sometimes true and sometimes a lazy cop-out."}]}
