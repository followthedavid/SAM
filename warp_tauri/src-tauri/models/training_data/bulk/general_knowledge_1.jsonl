{"conversations": [{"from": "human", "value": "Explain machine learning basics"}, {"from": "gpt", "value": "**Core concept:** Computers learn patterns from data instead of being explicitly programmed.\n\n**Types:**\n\n**Supervised learning:** Learn from labeled examples\n- Input: Photo of cat, Label: \"cat\"\n- Model learns: features → label mapping\n- Uses: classification, regression\n\n**Unsupervised learning:** Find patterns without labels\n- Input: Customer purchase data\n- Model finds: natural groupings\n- Uses: clustering, dimensionality reduction\n\n**Reinforcement learning:** Learn through trial and error\n- Agent takes actions, gets rewards\n- Learns: what actions maximize reward\n- Uses: games, robotics, optimization\n\n**The process:**\n1. Collect data\n2. Split: train/validation/test\n3. Choose model architecture\n4. Train on training data\n5. Validate and tune hyperparameters\n6. Evaluate on test data\n7. Deploy\n\n**Key concepts:**\n- Features: Input variables\n- Labels: Output variables\n- Overfitting: Memorizing training data, fails on new data\n- Underfitting: Too simple to capture patterns\n- Regularization: Prevent overfitting\n\nWhat aspect interests you most?"}]}
{"conversations": [{"from": "human", "value": "How do neural networks work?"}, {"from": "gpt", "value": "**Inspired by the brain, but not really like it.**\n\n**Structure:**\n```\nInput Layer → Hidden Layers → Output Layer\n   [x1]          [h1]           [y1]\n   [x2]   →      [h2]    →      [y2]\n   [x3]          [h3]           \n```\n\n**Each neuron:**\n1. Receives inputs (xi)\n2. Multiplies by weights (wi)\n3. Sums them up: Σ(xi × wi) + bias\n4. Applies activation function: f(sum)\n5. Outputs to next layer\n\n**Activation functions:**\n- ReLU: max(0, x) - most common\n- Sigmoid: 1/(1+e^-x) - squashes to 0-1\n- Tanh: squashes to -1 to 1\n- Softmax: converts to probability distribution\n\n**Training (backpropagation):**\n1. Forward pass: input → prediction\n2. Calculate loss (how wrong)\n3. Backward pass: calculate gradients\n4. Update weights: w = w - learning_rate × gradient\n5. Repeat until loss is small\n\n**Why deep learning:**\n- More layers = more abstraction levels\n- First layers: edges, textures\n- Middle layers: shapes, parts\n- Later layers: objects, concepts\n\n**Simple example (PyTorch):**\n```python\nimport torch.nn as nn\n\nmodel = nn.Sequential(\n    nn.Linear(784, 128),  # Input to hidden\n    nn.ReLU(),            # Activation\n    nn.Linear(128, 10),   # Hidden to output\n    nn.Softmax(dim=1)     # Probability\n)\n```\n\nWhat do you want to understand better?"}]}
{"conversations": [{"from": "human", "value": "Explain Docker in simple terms"}, {"from": "gpt", "value": "**Problem:** \"It works on my machine\" - different environments cause bugs.\n\n**Solution:** Package your app WITH its environment.\n\n**Analogy:**\n- Shipping container: Standard box, contents vary\n- Works the same on any ship (any server)\n- Docker container: Standard format, app varies\n\n**Key concepts:**\n\n**Image:** Blueprint. Read-only template.\n```dockerfile\nFROM python:3.11\nWORKDIR /app\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\nCOPY . .\nCMD [\"python\", \"app.py\"]\n```\n\n**Container:** Running instance of an image.\n- Isolated from host\n- Has its own filesystem, network\n- Ephemeral (data lost when container dies unless persisted)\n\n**Registry:** Where images live (Docker Hub, ECR, etc.)\n\n**Basic commands:**\n```bash\n# Build image from Dockerfile\ndocker build -t myapp .\n\n# Run container\ndocker run -p 3000:3000 myapp\n\n# List running containers\ndocker ps\n\n# Stop container\ndocker stop <container_id>\n\n# View logs\ndocker logs <container_id>\n```\n\n**docker-compose for multiple services:**\n```yaml\nservices:\n  web:\n    build: .\n    ports:\n      - \"3000:3000\"\n  db:\n    image: postgres\n    volumes:\n      - pgdata:/var/lib/postgresql/data\n```\n\n**Why use Docker:**\n- Consistent environments\n- Easy deployment\n- Isolation\n- Reproducibility\n- Scaling\n\nWhat are you trying to containerize?"}]}
{"conversations": [{"from": "human", "value": "What is Kubernetes?"}, {"from": "gpt", "value": "**Kubernetes (K8s):** Container orchestration at scale.\n\n**Problem Docker alone doesn't solve:**\n- How to run containers across multiple machines?\n- How to handle container failures?\n- How to scale up/down?\n- How to load balance?\n- How to update without downtime?\n\n**Kubernetes does all this.**\n\n**Core concepts:**\n\n**Pod:** Smallest unit. One or more containers.\n```yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: myapp\nspec:\n  containers:\n  - name: myapp\n    image: myapp:1.0\n    ports:\n    - containerPort: 8080\n```\n\n**Deployment:** Manages pods. Handles scaling, updates.\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myapp\nspec:\n  replicas: 3  # Run 3 copies\n  selector:\n    matchLabels:\n      app: myapp\n  template:\n    # Pod template here\n```\n\n**Service:** Stable network endpoint for pods.\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: myapp\nspec:\n  selector:\n    app: myapp\n  ports:\n  - port: 80\n    targetPort: 8080\n  type: LoadBalancer\n```\n\n**What K8s gives you:**\n- Self-healing (restarts failed containers)\n- Scaling (horizontal pod autoscaler)\n- Rolling updates (zero downtime deploys)\n- Service discovery\n- Load balancing\n- Secret management\n\n**When to use:**\n- Multiple services\n- Need high availability\n- Need auto-scaling\n- Team-scale operations\n\n**When NOT to use:**\n- Simple apps\n- Small scale\n- Don't want operational complexity\n\nAre you considering K8s for something?"}]}
{"conversations": [{"from": "human", "value": "How does Git work internally?"}, {"from": "gpt", "value": "**Git is a content-addressable filesystem with a VCS built on top.**\n\n**Everything is stored by SHA-1 hash of its content.**\n\n**Object types:**\n\n**Blob:** File content (no filename!)\n```\nblob 12\\0Hello World!\n→ SHA: 557db03de997c86a4a028e1ebd3a1ceb225be238\n```\n\n**Tree:** Directory - maps names to blobs/trees\n```\n100644 blob 557db03... README.md\n040000 tree a1b2c3... src/\n```\n\n**Commit:** Snapshot - points to tree + metadata\n```\ntree a1b2c3...\nparent d4e5f6...  (previous commit)\nauthor Name <email> timestamp\ncommitter Name <email> timestamp\n\nCommit message\n```\n\n**How commits chain:**\n```\nA ← B ← C ← D (HEAD)\n              ↑\n           main\n```\nEach commit points to its parent(s).\n\n**Branches are just pointers:**\n```\n.git/refs/heads/main → SHA of latest commit\n.git/HEAD → ref: refs/heads/main\n```\n\n**Staging area (index):**\nBuffer between working directory and repository.\n- `git add`: working dir → index\n- `git commit`: index → repository\n\n**Why this matters:**\n- Same content = same hash (deduplication)\n- History is immutable (hashes chain)\n- Branches are cheap (just a pointer)\n- Integrity checking built in\n\n**Explore it yourself:**\n```bash\ngit cat-file -t <sha>  # Object type\ngit cat-file -p <sha>  # Object content\nfind .git/objects      # See stored objects\n```"}]}
{"conversations": [{"from": "human", "value": "Explain how HTTPS works"}, {"from": "gpt", "value": "**Problem:** HTTP is plaintext. Anyone on the network can read it.\n\n**Solution:** TLS (Transport Layer Security) encrypts the connection.\n\n**The handshake:**\n\n1. **Client Hello:**\n   - Client says \"I want to connect\"\n   - Sends: supported TLS versions, cipher suites, random bytes\n\n2. **Server Hello:**\n   - Server responds with chosen TLS version, cipher suite\n   - Sends: certificate (containing public key), random bytes\n\n3. **Certificate verification:**\n   - Client checks: Is certificate valid? Trusted CA? Right domain?\n   - Certificate chain: site cert → intermediate CA → root CA\n\n4. **Key exchange:**\n   - Client generates pre-master secret\n   - Encrypts with server's public key\n   - Sends to server\n   - Both derive session keys from pre-master + randoms\n\n5. **Secure connection:**\n   - All data encrypted with session keys\n   - Symmetric encryption (AES) - fast\n\n**What certificates prove:**\n- Server owns the domain\n- Identity verified by Certificate Authority\n- Public key belongs to that server\n\n**What HTTPS protects against:**\n- Eavesdropping (encryption)\n- Tampering (integrity checks)\n- Impersonation (certificate verification)\n\n**What it DOESN'T hide:**\n- Which server you're connecting to (SNI)\n- That a connection exists\n- Metadata (timing, size of data)\n\n**Get a certificate:**\n- Let's Encrypt: Free, automated\n- Commercial CAs: Extended validation, warranties\n\n**Modern TLS:**\n- TLS 1.3 (2018): Faster handshake, more secure\n- Removed old/weak algorithms\n- 1-RTT handshake possible"}]}
{"conversations": [{"from": "human", "value": "What's the difference between SQL and NoSQL?"}, {"from": "gpt", "value": "**SQL (Relational):**\n\n**Structure:**\n- Tables with rows and columns\n- Fixed schema (define structure first)\n- Relationships via foreign keys\n- Normalized data (reduce duplication)\n\n**Query language:**\n```sql\nSELECT users.name, orders.total\nFROM users\nJOIN orders ON users.id = orders.user_id\nWHERE orders.total > 100;\n```\n\n**ACID guarantees:**\n- Atomicity, Consistency, Isolation, Durability\n- Transactions work correctly\n\n**Examples:** PostgreSQL, MySQL, SQLite\n\n---\n\n**NoSQL (Non-Relational):**\n\n**Types:**\n\n**Document (MongoDB):**\n```json\n{\"_id\": 1, \"name\": \"Alice\", \"orders\": [{\"total\": 150}]}\n```\nFlexible schema, nested data natural.\n\n**Key-Value (Redis):**\n```\nuser:123 → {\"name\": \"Alice\"}\n```\nSimple, extremely fast.\n\n**Column-family (Cassandra):**\nOptimized for distributed, write-heavy workloads.\n\n**Graph (Neo4j):**\nRelationship-focused queries.\n\n---\n\n**When to use what:**\n\n| Factor | SQL | NoSQL |\n|--------|-----|-------|\n| Data structure | Structured, relational | Flexible, denormalized |\n| Schema | Fixed | Dynamic |\n| Scaling | Vertical (bigger machine) | Horizontal (more machines) |\n| Consistency | Strong | Often eventual |\n| Joins | Excellent | Limited/expensive |\n| Use case | Transactions, complex queries | Scale, flexibility |\n\n**Real answer:**\nMost applications use both. SQL for core business data, NoSQL for specific use cases (caching, logs, sessions).\n\nWhat are you building?"}]}
{"conversations": [{"from": "human", "value": "Explain OAuth 2.0"}, {"from": "gpt", "value": "**Problem:** You want to use \"Sign in with Google\" without giving the app your Google password.\n\n**Solution:** OAuth - grant limited access without sharing credentials.\n\n**The players:**\n- **Resource Owner:** You\n- **Client:** The app wanting access\n- **Authorization Server:** Google (or whoever)\n- **Resource Server:** Where your data lives\n\n**The flow (Authorization Code - most secure):**\n\n```\n1. User clicks \"Sign in with Google\"\n\n2. App redirects to Google:\n   https://accounts.google.com/oauth/authorize?\n     client_id=APP_ID&\n     redirect_uri=https://app.com/callback&\n     scope=email profile&\n     response_type=code&\n     state=random_string\n\n3. User logs in to Google, approves permissions\n\n4. Google redirects back with code:\n   https://app.com/callback?code=AUTH_CODE&state=random_string\n\n5. App exchanges code for tokens (server-side):\n   POST https://oauth2.googleapis.com/token\n   {client_id, client_secret, code, redirect_uri}\n\n6. Google returns:\n   {access_token, refresh_token, expires_in}\n\n7. App uses access_token to get user info:\n   GET https://www.googleapis.com/userinfo\n   Authorization: Bearer ACCESS_TOKEN\n```\n\n**Token types:**\n- **Access token:** Short-lived, used for API calls\n- **Refresh token:** Long-lived, gets new access tokens\n- **ID token (OIDC):** Contains user identity info\n\n**Common mistakes:**\n- Using implicit flow for sensitive apps (deprecated)\n- Not validating state parameter (CSRF risk)\n- Storing tokens insecurely\n- Not using PKCE for public clients\n\n**PKCE (for mobile/SPA):**\nAdditional security without client_secret.\n\nWhat are you implementing?"}]}
{"conversations": [{"from": "human", "value": "What is REST?"}, {"from": "gpt", "value": "**REST (Representational State Transfer):** An architectural style for APIs.\n\n**Core principles:**\n\n**1. Resources, not actions:**\n```\n# NOT REST\nGET /getUser?id=123\nPOST /createUser\n\n# REST\nGET /users/123\nPOST /users\n```\n\n**2. HTTP methods as verbs:**\n- GET: Read\n- POST: Create\n- PUT: Replace\n- PATCH: Update\n- DELETE: Remove\n\n**3. Stateless:**\nEach request contains all info needed. Server doesn't store session.\n\n**4. Uniform interface:**\nConsistent resource identification and manipulation.\n\n**5. Layered system:**\nClient doesn't know if talking to server or intermediary.\n\n**A RESTful API:**\n```\nGET    /users          List users\nGET    /users/123      Get user 123\nPOST   /users          Create user\nPUT    /users/123      Replace user 123\nPATCH  /users/123      Update user 123\nDELETE /users/123      Delete user 123\n\nGET    /users/123/orders   User's orders (nested resource)\n```\n\n**Status codes:**\n- 200: OK\n- 201: Created\n- 204: No content\n- 400: Bad request\n- 401: Unauthorized\n- 403: Forbidden\n- 404: Not found\n- 500: Server error\n\n**HATEOAS (often skipped):**\nResponses include links to related resources.\n```json\n{\n  \"id\": 123,\n  \"name\": \"Alice\",\n  \"_links\": {\n    \"self\": \"/users/123\",\n    \"orders\": \"/users/123/orders\"\n  }\n}\n```\n\n**REST isn't:**\n- A protocol (it's a style)\n- A standard (loose guidelines)\n- Always the best choice (GraphQL, gRPC exist)\n\nWhat's your use case?"}]}
{"conversations": [{"from": "human", "value": "How does DNS work?"}, {"from": "gpt", "value": "**DNS: The internet's phone book.**\n\n**Problem:** Humans like names (google.com). Computers need IP addresses (142.250.80.46).\n\n**The resolution process:**\n\n```\nYou: \"What's google.com?\"\n    ↓\nBrowser cache → Found? Return it\n    ↓\nOS cache → Found? Return it\n    ↓\nRecursive Resolver (your ISP or 8.8.8.8)\n    ↓\nRoot nameserver → \"Ask .com\"\n    ↓\n.com TLD nameserver → \"Ask Google's nameserver\"\n    ↓\nGoogle's authoritative nameserver → \"142.250.80.46\"\n    ↓\nResult cached at each level\n```\n\n**Record types:**\n```\nA      → IPv4 address\nAAAA   → IPv6 address\nCNAME  → Alias to another domain\nMX     → Mail server\nTXT    → Text (verification, SPF, etc.)\nNS     → Nameserver for domain\nSOA    → Start of authority\n```\n\n**Example zone file:**\n```\nexample.com.    IN  A      93.184.216.34\nwww             IN  CNAME  example.com.\nmail            IN  A      93.184.216.35\n@               IN  MX     10 mail.example.com.\n@               IN  TXT    \"v=spf1 mx -all\"\n```\n\n**TTL (Time To Live):**\n- How long to cache the record\n- Lower = faster changes, more queries\n- Higher = better performance, slower changes\n\n**DNS security:**\n- DNSSEC: Cryptographic verification\n- DoH (DNS over HTTPS): Encrypted queries\n- DoT (DNS over TLS): Encrypted queries\n\n**Check DNS:**\n```bash\ndig google.com\nnslookup google.com\nhost google.com\n```\n\n**Common issues:**\n- Propagation delay (TTL hasn't expired)\n- Misconfigured records\n- DNS hijacking"}]}
{"conversations": [{"from": "human", "value": "What's a load balancer?"}, {"from": "gpt", "value": "**Distributes traffic across multiple servers.**\n\n**Why:**\n- Handle more traffic than one server can\n- Redundancy (if one dies, others continue)\n- Maintenance without downtime\n\n**Algorithms:**\n\n**Round Robin:**\n```\nRequest 1 → Server A\nRequest 2 → Server B\nRequest 3 → Server C\nRequest 4 → Server A\n```\nSimple, even distribution.\n\n**Least Connections:**\nSend to server with fewest active connections.\n\n**Weighted:**\nServers with more capacity get more traffic.\n\n**IP Hash:**\nSame client always goes to same server (sticky sessions).\n\n**Health Checks:**\n```\nLB pings each server periodically\nUnhealthy server removed from pool\nAutomatic recovery when healthy again\n```\n\n**Types:**\n\n**Layer 4 (Transport):**\n- TCP/UDP level\n- Fast, doesn't inspect content\n- Can't make decisions based on URL/headers\n\n**Layer 7 (Application):**\n- HTTP level\n- Can route by URL, headers, cookies\n- More flexible, slightly slower\n- SSL termination\n\n**Architecture:**\n```\n           ┌──────────────┐\nClients →  │Load Balancer │ → Server 1\n           └──────────────┘ → Server 2\n                            → Server 3\n```\n\n**Tools:**\n- Nginx, HAProxy (software)\n- AWS ALB/NLB, GCP Load Balancer (cloud)\n- F5, Citrix (hardware)\n\n**Session persistence:**\nIf app has state, need sticky sessions or shared session store (Redis).\n\nWhat's your setup?"}]}
{"conversations": [{"from": "human", "value": "What is caching?"}, {"from": "gpt", "value": "**Store frequently accessed data closer to where it's needed.**\n\n**The hierarchy (fastest to slowest):**\n```\nCPU Cache (nanoseconds)\n    ↓\nRAM (microseconds)\n    ↓\nSSD/Disk (milliseconds)\n    ↓\nNetwork (10s-100s of milliseconds)\n```\n\n**Web application caching layers:**\n\n**Browser cache:**\n```http\nCache-Control: max-age=31536000, immutable\n```\nStatic assets cached locally.\n\n**CDN cache:**\nGeographically distributed. Assets closer to users.\n\n**Application cache (Redis/Memcached):**\n```python\ndef get_user(user_id):\n    cached = redis.get(f\"user:{user_id}\")\n    if cached:\n        return json.loads(cached)\n    \n    user = db.query(\"SELECT * FROM users WHERE id = ?\", user_id)\n    redis.setex(f\"user:{user_id}\", 3600, json.dumps(user))\n    return user\n```\n\n**Database query cache:**\nDB caches query results internally.\n\n**Caching strategies:**\n\n**Cache-aside:**\n1. Check cache\n2. If miss, query DB\n3. Store in cache\n4. Return\n\n**Write-through:**\n1. Write to cache\n2. Cache writes to DB\n3. Return\n\n**Write-behind:**\n1. Write to cache\n2. Return\n3. Cache async writes to DB\n\n**Cache invalidation (the hard problem):**\n- Time-based (TTL)\n- Event-based (invalidate on write)\n- Manual purge\n\n\"There are only two hard things in computer science: cache invalidation and naming things.\"\n\n**When to cache:**\n- Data is expensive to compute/fetch\n- Data is accessed frequently\n- Data doesn't change often (or staleness is acceptable)\n\nWhat are you trying to cache?"}]}
{"conversations": [{"from": "human", "value": "Explain microservices architecture"}, {"from": "gpt", "value": "**Monolith:** One big application. All code together.\n\n**Microservices:** Many small, independent services.\n\n**Comparison:**\n```\nMonolith:                 Microservices:\n┌───────────────────┐     ┌─────┐ ┌─────┐ ┌─────┐\n│  Users  │ Orders  │     │Users│ │Order│ │Pay  │\n│  ──────────────── │     └──┬──┘ └──┬──┘ └──┬──┘\n│  Payments │ Email │        │       │       │\n│  ──────────────── │     ┌──┴───────┴───────┴──┐\n│     Database      │     │    Message Queue    │\n└───────────────────┘     └─────────────────────┘\n```\n\n**Benefits:**\n- Independent deployment (update users without touching orders)\n- Scale independently (scale payments during sales)\n- Technology freedom (Python for ML, Go for performance)\n- Team autonomy (each team owns their service)\n- Fault isolation (one service fails, others continue)\n\n**Challenges:**\n- Network complexity (calls between services)\n- Data consistency (distributed transactions are hard)\n- Operational overhead (many things to deploy/monitor)\n- Testing complexity (integration testing harder)\n- Debugging (trace requests across services)\n\n**Communication:**\n- Sync: REST, gRPC\n- Async: Message queues (RabbitMQ, Kafka)\n\n**Patterns:**\n- API Gateway: Single entry point\n- Service discovery: How services find each other\n- Circuit breaker: Handle failures gracefully\n- Saga: Distributed transactions\n\n**When to use:**\n- Large team (10+)\n- Different scaling needs per component\n- Need independent deployments\n- Complex domain, natural boundaries\n\n**When NOT to use:**\n- Small team\n- Simple application\n- Tight deadline\n- Unknown requirements (start monolith, extract later)\n\nWhat's your situation?"}]}
{"conversations": [{"from": "human", "value": "What is CI/CD?"}, {"from": "gpt", "value": "**CI (Continuous Integration):**\nAutomatically build and test code on every push.\n\n**CD (Continuous Deployment/Delivery):**\nAutomatically deploy to production (deployment) or prepare for manual deploy (delivery).\n\n**The pipeline:**\n```\nCode Push\n    ↓\n┌──────────────────┐\n│  Build           │  Compile, install deps\n└────────┬─────────┘\n         ↓\n┌──────────────────┐\n│  Test            │  Unit, integration, e2e\n└────────┬─────────┘\n         ↓\n┌──────────────────┐\n│  Security scan   │  Dependencies, code\n└────────┬─────────┘\n         ↓\n┌──────────────────┐\n│  Deploy staging  │  Test environment\n└────────┬─────────┘\n         ↓\n┌──────────────────┐\n│  Deploy prod     │  Live!\n└──────────────────┘\n```\n\n**GitHub Actions example:**\n```yaml\nname: CI/CD\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - uses: actions/setup-node@v3\n      - run: npm ci\n      - run: npm test\n      - run: npm run build\n  \n  deploy:\n    needs: test\n    if: github.ref == 'refs/heads/main'\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - run: npm ci && npm run build\n      - run: ./deploy.sh\n```\n\n**Benefits:**\n- Catch bugs early\n- Fast feedback\n- Consistent process\n- Less manual work\n- Smaller, safer deployments\n\n**Tools:**\n- GitHub Actions\n- GitLab CI\n- Jenkins\n- CircleCI\n- Travis CI\n\n**Best practices:**\n- Fast tests (< 10 min)\n- Fail fast (catch errors early)\n- Everything in version control\n- Branch protection rules\n- Rollback capability\n\nWhat's your current workflow?"}]}
{"conversations": [{"from": "human", "value": "What is a message queue?"}, {"from": "gpt", "value": "**Asynchronous communication between services.**\n\n**The problem:**\n```\nService A calls Service B synchronously\nB is slow → A waits\nB is down → A fails\n```\n\n**The solution:**\n```\nService A → Queue → Service B\n\nA publishes message and continues\nB processes when ready\nIf B is down, messages wait in queue\n```\n\n**Use cases:**\n- Background jobs (send email, process image)\n- Service decoupling\n- Load leveling (smooth out spikes)\n- Event-driven architecture\n\n**Common patterns:**\n\n**Work queue:**\n```\nProducer → Queue → Consumer 1\n                 → Consumer 2\n                 → Consumer 3\n```\nMultiple workers process jobs.\n\n**Pub/Sub:**\n```\nProducer → Topic → Subscriber 1\n                 → Subscriber 2\n                 → Subscriber 3\n```\nAll subscribers get all messages.\n\n**Example (Python + RabbitMQ):**\n```python\nimport pika\n\n# Producer\nconnection = pika.BlockingConnection()\nchannel = connection.channel()\nchannel.queue_declare(queue='tasks')\nchannel.basic_publish(\n    exchange='',\n    routing_key='tasks',\n    body='Process this!'\n)\n\n# Consumer\ndef callback(ch, method, props, body):\n    print(f\"Received: {body}\")\n    # Do work\n    ch.basic_ack(delivery_tag=method.delivery_tag)\n\nchannel.basic_consume(queue='tasks', on_message_callback=callback)\nchannel.start_consuming()\n```\n\n**Tools:**\n- RabbitMQ: Full-featured, reliable\n- Redis: Simple, fast (pub/sub + lists)\n- Kafka: High throughput, streaming\n- AWS SQS: Managed, scalable\n\n**Considerations:**\n- Message ordering\n- At-least-once vs exactly-once\n- Dead letter queues (failed messages)\n- Message TTL\n\nWhat are you trying to decouple?"}]}
